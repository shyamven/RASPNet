{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning Example on Radar Dataset (Central Kansas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "import scipy.io as sio\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import itertools\n",
    "import time\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import KFold\n",
    "from itertools import product\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the labels and creating train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "Training labels:\n",
      "[[ 8.3355 13.325  19.525 ]\n",
      " [18.156  17.388  32.775 ]\n",
      " [ 8.777  24.73   18.582 ]\n",
      " ...\n",
      " [15.785  15.992  29.641 ]\n",
      " [ 3.1736 10.716  12.27  ]\n",
      " [ 4.5552 21.035  14.234 ]]\n"
     ]
    }
   ],
   "source": [
    "def index(string):\n",
    "    s = re.findall(\"[0-9]\", string)\n",
    "    return int(''.join(s))\n",
    "\n",
    "scenario_idx = 29 # Bonneville Salt Flats\n",
    "names = os.listdir(f'num{scenario_idx}_NAMF_DATA_20_rng30_pulse1_1000_100k/')\n",
    "names = sorted(names, key=index)\n",
    "print(len(names))\n",
    "y = pd.read_csv(f'num{scenario_idx}_Ground_Truth_20_rng30_1000_100k_m.csv')\n",
    "col_names = y.columns[4:7]\n",
    "y = y[col_names].to_numpy()\n",
    "\n",
    "scenario_idx_test = 60 # Central Kansas\n",
    "names_test = os.listdir(f'num{scenario_idx_test}_NAMF_DATA_20_rng30_pulse1_1000_100k/')\n",
    "names_test = sorted(names_test, key=index)\n",
    "y_test = pd.read_csv(f'num{scenario_idx_test}_Ground_Truth_20_rng30_1000_100k_m.csv')\n",
    "col_names_test = y_test.columns[4:7]\n",
    "y_test = y_test[col_names_test].to_numpy()\n",
    "\n",
    "# Define fine-tuning name and labels\n",
    "few_shot_count = 64\n",
    "names_FS = names_test[:few_shot_count]\n",
    "y_FS = y_test[:few_shot_count]\n",
    "\n",
    "# Create training and testing datasets\n",
    "y_train = y[:int(0.9 * len(names))]\n",
    "y_test = y_test[int(0.9 * len(names_test)) - 1:]\n",
    "training_names = names[:int(0.9 * len(names))]\n",
    "test_names = names_test[int(0.9 * len(names_test)) - 1:]\n",
    "\n",
    "print('Training labels:')\n",
    "print(y_train)\n",
    "\n",
    "# Tensor Corners\n",
    "##################################################################################\n",
    "# num29: [10851, 215, -5.4], num60: [11073, 215, -5.3], num62: [11471, 215, -5.6]\n",
    "# num76: [11388, 215, -6.15], num35: [11381, 215, -0.95]\n",
    "##################################################################################\n",
    "\n",
    "# Training dataset global constants\n",
    "coord_tr = [10851, 215, -5.4]  # Tensor corner\n",
    "rng_res_tr = 59.9585 / 2        # Range resolution\n",
    "az_step_tr = 0.4                # Azimuth step size\n",
    "el_step_tr = 0.01               # Elevation step size\n",
    "\n",
    "# Test dataset global constants\n",
    "coord_ts = [11073, 215, -5.3]  # Tensor corner\n",
    "rng_res_ts = 59.9585 / 2        # Range resolution\n",
    "az_step_ts = 0.4                # Azimuth step size\n",
    "el_step_ts = 0.01               # Elevation step size\n",
    "\n",
    "def Drawing_Batch(names, label, bs, ind, directory, normalize=True):\n",
    "    x = []\n",
    "    labels = []\n",
    "    \n",
    "    for j in range(ind * bs, (ind + 1) * bs):\n",
    "        try:\n",
    "            temp = sio.loadmat(directory + names[j])['P']\n",
    "        except:\n",
    "            break\n",
    "        if normalize:\n",
    "            Anorm = temp - np.min(temp.flatten())\n",
    "            temp = np.divide(Anorm, np.max(Anorm.flatten()))\n",
    "        x.append(temp)\n",
    "        labels.append(label[j, :])\n",
    "        \n",
    "    x = torch.FloatTensor(np.array(x))\n",
    "    labels = torch.FloatTensor(np.array(labels))\n",
    "    return x, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90000\n",
      "10001\n"
     ]
    }
   ],
   "source": [
    "print(len(y_train))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a regression CNN and instantiating it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1               [-1, 32, 24]           2,048\n",
      "       BatchNorm1d-2               [-1, 32, 24]              64\n",
      "            Conv1d-3               [-1, 64, 10]           6,208\n",
      "       BatchNorm1d-4               [-1, 64, 10]             128\n",
      "            Linear-5                   [-1, 20]           6,420\n",
      "            Linear-6                    [-1, 2]              42\n",
      "               Net-7                    [-1, 2]               0\n",
      "================================================================\n",
      "Total params: 14,910\n",
      "Trainable params: 14,910\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.02\n",
      "Params size (MB): 0.06\n",
      "Estimated Total Size (MB): 0.08\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(21, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv1d(32, 64, 3, 1)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(32)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(64)\n",
    "        self.fc1 = nn.Linear(64 * 5, 20)  # Adjust input size based on the output of conv layers and max pooling\n",
    "        self.fc2_reg = nn.Linear(20, 2)  # Adjusted output size\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(self.batchnorm1(x))\n",
    "        x = F.max_pool1d(x, 2)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(self.batchnorm2(x))\n",
    "        x = F.max_pool1d(x, 2)\n",
    "        \n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        output_reg = self.fc2_reg(x)  # (bs, 2)\n",
    "        \n",
    "        return output_reg\n",
    "    \n",
    "from torchsummary import summary\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "model = Net()\n",
    "model = model.to(device)\n",
    "if device == 'cuda:0':\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    cudnn.benchmark = True\n",
    "print(summary(model,(21,26)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 128  # batch_size\n",
    "num_epoch = 50  # number of epochs\n",
    "PATH = './ckpt_model.pth'   # forsaving the model\n",
    "criterion = nn.MSELoss()\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Define a Loss function and optimizer; Using GPU or CPU\n",
    "model = Net()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "model = model.to(device)\n",
    "if device == 'cuda:0':\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    cudnn.benchmark = True\n",
    "    \n",
    "def Spher2Cart_1D(spherical):\n",
    "    cartesian = np.zeros(3)\n",
    "    hypotenuse = np.cos(np.radians(spherical[2]))*spherical[0]\n",
    "    cartesian[0] = np.cos(np.radians(spherical[1]))*hypotenuse\n",
    "    cartesian[1] = -np.sin(np.radians(spherical[1]))*hypotenuse\n",
    "    cartesian[2] = np.sin(np.radians(spherical[2]))*spherical[0]\n",
    "    return cartesian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evaluate the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/50\n",
      "----------\n",
      "[-8187.45955885  7784.83170223 -1008.20172776]\n",
      "[-8208.98872915  7739.2576875  -1006.80069973]\n",
      "[-8409.5341829   7694.47736292 -1005.10206359]\n",
      "[-8556.12846063  7498.93931165 -1003.22889385]\n",
      "Train Loss: 8.054857 ---- Test Loss: 10.554716\n",
      "Epoch 1/50\n",
      "----------\n",
      "[-8187.45955885  7784.83170223 -1008.20172776]\n",
      "[-8199.77093405  7751.82279998 -1006.97230854]\n",
      "[-8409.5341829   7694.47736292 -1005.10206359]\n",
      "[-8505.14223197  7553.80061218 -1003.05807124]\n",
      "Train Loss: 0.201115 ---- Test Loss: 6.945337\n",
      "Epoch 2/50\n",
      "----------\n",
      "[-8187.45955885  7784.83170223 -1008.20172776]\n",
      "[-8191.18866077  7763.90638139 -1007.15740655]\n",
      "[-8409.5341829   7694.47736292 -1005.10206359]\n",
      "[-8489.65447016  7574.3247008  -1003.2413048 ]\n",
      "Train Loss: 0.131613 ---- Test Loss: 5.670177\n",
      "Epoch 3/50\n",
      "----------\n",
      "[-8187.45955885  7784.83170223 -1008.20172776]\n",
      "[-8196.30833711  7756.63212896 -1007.04274062]\n",
      "[-8409.5341829   7694.47736292 -1005.10206359]\n",
      "[-8487.0403089   7573.82132881 -1003.03975617]\n",
      "Train Loss: 0.108559 ---- Test Loss: 5.563121\n",
      "Epoch 4/50\n",
      "----------\n",
      "[-8187.45955885  7784.83170223 -1008.20172776]\n",
      "[-8209.1608491   7735.76561195 -1006.59813029]\n",
      "[-8409.5341829   7694.47736292 -1005.10206359]\n",
      "[-8482.64477057  7572.45616658 -1002.67043367]\n",
      "Train Loss: 0.101137 ---- Test Loss: 5.451148\n",
      "Epoch 5/50\n",
      "----------\n",
      "[-8187.45955885  7784.83170223 -1008.20172776]\n",
      "[-8208.45247754  7737.38179806 -1006.65104775]\n",
      "[-8409.5341829   7694.47736292 -1005.10206359]\n",
      "[-8473.18081523  7577.45818246 -1002.34200804]\n",
      "Train Loss: 0.102910 ---- Test Loss: 5.284580\n",
      "Epoch 6/50\n",
      "----------\n",
      "[-8187.45955885  7784.83170223 -1008.20172776]\n",
      "[-8200.11351148  7749.67334963 -1006.86276332]\n",
      "[-8409.5341829   7694.47736292 -1005.10206359]\n",
      "[-8460.71261145  7584.84929333 -1001.95768039]\n",
      "Train Loss: 0.112618 ---- Test Loss: 4.597628\n",
      "Epoch 7/50\n",
      "----------\n",
      "[-8187.45955885  7784.83170223 -1008.20172776]\n",
      "[-8196.31923214  7763.58722749 -1007.47016924]\n",
      "[-8409.5341829   7694.47736292 -1005.10206359]\n",
      "[-8435.51817884  7618.9289513  -1002.31632978]\n",
      "Train Loss: 0.122653 ---- Test Loss: 3.875631\n",
      "Epoch 8/50\n",
      "----------\n",
      "[-8187.45955885  7784.83170223 -1008.20172776]\n",
      "[-8198.7731878   7766.5531095  -1007.81117084]\n",
      "[-8409.5341829   7694.47736292 -1005.10206359]\n",
      "[-8422.59999275  7642.15348348 -1002.84624126]\n",
      "Train Loss: 0.120539 ---- Test Loss: 3.362295\n",
      "Epoch 9/50\n",
      "----------\n",
      "[-8187.45955885  7784.83170223 -1008.20172776]\n",
      "[-8199.05937528  7768.108204   -1007.92515316]\n",
      "[-8409.5341829   7694.47736292 -1005.10206359]\n",
      "[-8424.07129052  7644.38593741 -1003.07460327]\n",
      "Train Loss: 0.109781 ---- Test Loss: 3.332174\n",
      "Epoch 10/50\n",
      "----------\n",
      "[-8187.45955885  7784.83170223 -1008.20172776]\n",
      "[-8199.21372568  7768.54491694 -1007.96195625]\n",
      "[-8409.5341829   7694.47736292 -1005.10206359]\n",
      "[-8424.03280826  7645.93289021 -1003.16376272]\n",
      "Train Loss: 0.098070 ---- Test Loss: 3.261282\n",
      "Epoch 11/50\n",
      "----------\n",
      "[-8187.45955885  7784.83170223 -1008.20172776]\n",
      "[-8200.0981127   7767.35076289 -1007.94596131]\n",
      "[-8409.5341829   7694.47736292 -1005.10206359]\n",
      "[-8425.77434566  7639.01064556 -1002.86739412]\n",
      "Train Loss: 0.092982 ---- Test Loss: 3.424396\n",
      "Epoch 12/50\n",
      "----------\n",
      "[-8187.45955885  7784.83170223 -1008.20172776]\n",
      "[-8200.75245359  7767.86946987 -1008.02018756]\n",
      "[-8409.5341829   7694.47736292 -1005.10206359]\n",
      "[-8420.65359801  7643.79141704 -1002.81621087]\n",
      "Train Loss: 0.092126 ---- Test Loss: 3.338493\n",
      "Epoch 13/50\n",
      "----------\n",
      "[-8187.45955885  7784.83170223 -1008.20172776]\n",
      "[-8198.46457224  7769.71623563 -1007.98532603]\n",
      "[-8409.5341829   7694.47736292 -1005.10206359]\n",
      "[-8416.72060852  7646.72511104 -1002.73338497]\n",
      "Train Loss: 0.090853 ---- Test Loss: 3.220623\n",
      "Epoch 14/50\n",
      "----------\n",
      "[-8187.45955885  7784.83170223 -1008.20172776]\n",
      "[-8197.02546017  7771.58050338 -1008.00657128]\n",
      "[-8409.5341829   7694.47736292 -1005.10206359]\n",
      "[-8414.76114902  7647.70965305 -1002.66389419]\n",
      "Train Loss: 0.088030 ---- Test Loss: 3.151805\n",
      "Epoch 15/50\n",
      "----------\n",
      "[-8187.45955885  7784.83170223 -1008.20172776]\n",
      "[-8197.01909081  7771.01362851 -1007.97135397]\n",
      "[-8409.5341829   7694.47736292 -1005.10206359]\n",
      "[-8413.92495272  7650.77437958 -1002.79111774]\n",
      "Train Loss: 0.085516 ---- Test Loss: 3.082523\n",
      "Epoch 16/50\n",
      "----------\n",
      "[-8187.45955885  7784.83170223 -1008.20172776]\n",
      "[-8196.526412    7771.64933657 -1007.97847977]\n",
      "[-8409.5341829   7694.47736292 -1005.10206359]\n",
      "[-8415.25205615  7648.63073332 -1002.75055488]\n",
      "Train Loss: 0.083899 ---- Test Loss: 3.154628\n",
      "Epoch 17/50\n",
      "----------\n",
      "[-8187.45955885  7784.83170223 -1008.20172776]\n",
      "[-8195.7720596   7772.9576765  -1008.00997154]\n",
      "[-8409.5341829   7694.47736292 -1005.10206359]\n",
      "[-8415.51380089  7652.0230052  -1002.96884649]\n",
      "Train Loss: 0.082176 ---- Test Loss: 3.074625\n",
      "Epoch 18/50\n",
      "----------\n",
      "[-8187.45955885  7784.83170223 -1008.20172776]\n",
      "[-8195.73981728  7773.22415812 -1008.02424855]\n",
      "[-8409.5341829   7694.47736292 -1005.10206359]\n",
      "[-8412.10920417  7660.38875017 -1003.2432787 ]\n",
      "Train Loss: 0.080331 ---- Test Loss: 2.928011\n",
      "Epoch 19/50\n",
      "----------\n",
      "[-8187.45955885  7784.83170223 -1008.20172776]\n",
      "[-8195.69608917  7772.69802557 -1007.98910748]\n",
      "[-8409.5341829   7694.47736292 -1005.10206359]\n",
      "[-8414.55463294  7655.54228001 -1003.11508075]\n",
      "Train Loss: 0.078450 ---- Test Loss: 3.007258\n",
      "Epoch 20/50\n",
      "----------\n",
      "[-8187.45955885  7784.83170223 -1008.20172776]\n",
      "[-8194.9545106   7773.77351037 -1008.00714053]\n",
      "[-8409.5341829   7694.47736292 -1005.10206359]\n",
      "[-8415.05749589  7656.16915761 -1003.18507882]\n",
      "Train Loss: 0.076210 ---- Test Loss: 2.930389\n",
      "Epoch 21/50\n",
      "----------\n",
      "[-8187.45955885  7784.83170223 -1008.20172776]\n",
      "[-8194.58703156  7773.72303093 -1007.98024851]\n",
      "[-8409.5341829   7694.47736292 -1005.10206359]\n",
      "[-8414.77430667  7657.38497049 -1003.23876084]\n",
      "Train Loss: 0.074442 ---- Test Loss: 2.875348\n",
      "Epoch 22/50\n",
      "----------\n",
      "[-8187.45955885  7784.83170223 -1008.20172776]\n",
      "[-8194.02105386  7774.34459684 -1007.98178346]\n",
      "[-8409.5341829   7694.47736292 -1005.10206359]\n",
      "[-8416.96782393  7654.43769461 -1003.20695495]\n",
      "Train Loss: 0.072917 ---- Test Loss: 2.915700\n",
      "Epoch 23/50\n",
      "----------\n",
      "[-8187.45955885  7784.83170223 -1008.20172776]\n",
      "[-8195.04701677  7772.92817376 -1007.96121419]\n",
      "[-8409.5341829   7694.47736292 -1005.10206359]\n",
      "[-8418.30840167  7654.13527793 -1003.27647335]\n",
      "Train Loss: 0.071587 ---- Test Loss: 2.873511\n",
      "Epoch 24/50\n",
      "----------\n",
      "[-8187.45955885  7784.83170223 -1008.20172776]\n",
      "[-8195.12250003  7773.01469436 -1007.97141496]\n",
      "[-8409.5341829   7694.47736292 -1005.10206359]\n",
      "[-8418.73278303  7653.29973558 -1003.25459974]\n",
      "Train Loss: 0.069889 ---- Test Loss: 2.842539\n",
      "Epoch 25/50\n",
      "----------\n",
      "[-8187.45955885  7784.83170223 -1008.20172776]\n",
      "[-8195.43679288  7772.42972554 -1007.95584188]\n",
      "[-8409.5341829   7694.47736292 -1005.10206359]\n",
      "[-8420.27061597  7651.54118572 -1003.25065194]\n",
      "Train Loss: 0.068495 ---- Test Loss: 2.851824\n",
      "Epoch 26/50\n",
      "----------\n",
      "[-8187.45955885  7784.83170223 -1008.20172776]\n",
      "[-8195.67156894  7772.17148728 -1007.95518623]\n",
      "[-8409.5341829   7694.47736292 -1005.10206359]\n",
      "[-8422.8057937   7648.21891313 -1003.21914741]\n",
      "Train Loss: 0.067017 ---- Test Loss: 2.887564\n",
      "Epoch 27/50\n",
      "----------\n",
      "[-8187.45955885  7784.83170223 -1008.20172776]\n",
      "[-8196.03855898  7772.04587848 -1007.97123707]\n",
      "[-8409.5341829   7694.47736292 -1005.10206359]\n",
      "[-8423.34055379  7647.95593341 -1003.23846952]\n",
      "Train Loss: 0.065747 ---- Test Loss: 2.914565\n",
      "Epoch 28/50\n",
      "----------\n",
      "[-8187.45955885  7784.83170223 -1008.20172776]\n",
      "[-8194.817854    7774.56958155 -1008.04718632]\n",
      "[-8409.5341829   7694.47736292 -1005.10206359]\n",
      "[-8427.57932688  7640.94928419 -1003.10012834]\n",
      "Train Loss: 0.064194 ---- Test Loss: 2.976960\n",
      "Epoch 29/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def main(training_names, test_names, bs, num_epoch, y_train, y_test, normalize=True):\n",
    "    best_error = 1e+20  # a dummy and very large number for saving the best discovered model\n",
    "    for epoch in range(num_epoch):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epoch))\n",
    "        print('-' * 10)\n",
    "        running_loss_train = 0\n",
    "        running_loss_test = 0\n",
    "\n",
    "        model.train()\n",
    "        for i in range(0, len(training_names) // bs):\n",
    "            x_train, labels = Drawing_Batch(training_names, y_train, bs, i, f'num{scenario_idx}_NAMF_DATA_20_rng30_pulse1_1000_100k/', normalize)\n",
    "            x_train = x_train.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(x_train)\n",
    "            loss = criterion(out, labels[:, 0:2])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss_train += loss.item()\n",
    "            \n",
    "        out = torch.cat((out, torch.unsqueeze(labels[:,2], dim=1)), dim=1)\n",
    "\n",
    "        # Training error display\n",
    "        true_train = Spher2Cart_1D(np.multiply(labels.cpu().data.numpy()[1], [rng_res_tr, az_step_tr, el_step_tr]) + coord_tr)\n",
    "        pred_train = Spher2Cart_1D(np.multiply(out.cpu().data.numpy()[1], [rng_res_tr, az_step_tr, el_step_tr]) + coord_tr)\n",
    "        print(true_train)\n",
    "        print(pred_train)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, len(test_names) // bs):\n",
    "                x_test, labels_test = Drawing_Batch(test_names, y_test, bs, i, f'num{scenario_idx_test}_NAMF_DATA_20_rng30_pulse1_1000_100k/', normalize)\n",
    "                x_test = x_test.to(device)\n",
    "                labels_test = labels_test.to(device)\n",
    "                out_test = model(x_test)\n",
    "                loss_test = criterion(out_test, labels_test[:, 0:2])\n",
    "                running_loss_test += loss_test.item()\n",
    "                \n",
    "        out_test = torch.cat((out_test, torch.unsqueeze(labels_test[:,2], dim=1)), dim=1)\n",
    "\n",
    "        # Test error display\n",
    "        true_test = Spher2Cart_1D(np.multiply(labels_test.cpu().data.numpy()[1], [rng_res_ts, az_step_ts, el_step_ts]) + coord_ts)\n",
    "        pred_test = Spher2Cart_1D(np.multiply(out_test.cpu().data.numpy()[1], [rng_res_ts, az_step_ts, el_step_ts]) + coord_ts)\n",
    "        print(true_test)\n",
    "        print(pred_test)\n",
    "\n",
    "        epoch_loss_train = running_loss_train * x_train.size(0) / len(training_names)\n",
    "        epoch_loss_test = running_loss_test * x_test.size(0) / len(test_names)\n",
    "\n",
    "        print('Train Loss: {:.6f} ---- Test Loss: {:.6f}'.format(epoch_loss_train, epoch_loss_test))\n",
    "        if epoch % 5 == 0:\n",
    "            if epoch_loss_test < best_error:\n",
    "                torch.save(model.state_dict(), PATH)\n",
    "                best_error = epoch_loss_test\n",
    "\n",
    "start = time.time()\n",
    "main(training_names, test_names, bs, num_epoch, y_train, y_test, normalize=True)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azimuth Estimation Error (deg) = 1.0840089544512346\n",
      "Localization Error (m) = 99.15726815648534\n"
     ]
    }
   ],
   "source": [
    "def Spher2Cart_2D(spherical):\n",
    "    cartesian = np.zeros((len(spherical), 3))\n",
    "    hypotenuse = np.multiply(np.cos(np.radians(spherical[:, 2])), spherical[:, 0])\n",
    "    cartesian[:, 0] = np.multiply(np.cos(np.radians(spherical[:, 1])), hypotenuse)\n",
    "    cartesian[:, 1] = np.multiply(-np.sin(np.radians(spherical[:, 1])), hypotenuse)\n",
    "    cartesian[:, 2] = np.multiply(np.sin(np.radians(spherical[:, 2])), spherical[:, 0])\n",
    "    return cartesian\n",
    "\n",
    "# Testing: (range, az, el)\n",
    "model.eval()\n",
    "out_test_reg = np.zeros((len(y_test), 3))\n",
    "labels_test_reg = np.zeros((len(y_test), 3))\n",
    "\n",
    "for i in range(0, len(y_test) // bs):\n",
    "    x_test, labels_test = Drawing_Batch(test_names, y_test, bs, i, f'num{scenario_idx_test}_NAMF_DATA_20_rng30_pulse1_1000_100k/', True)\n",
    "    x_test = x_test.to(device)\n",
    "    labels_test = labels_test.cpu().data.numpy()\n",
    "    labels_test_reg[bs * i: bs * i + bs] = (labels_test[:, 0:3])\n",
    "\n",
    "    cur_test_reg = model(x_test)\n",
    "    out_test_reg[bs * i: bs * i + bs, 0:2] = cur_test_reg.cpu().data.numpy()\n",
    "    out_test_reg[bs * i: bs * i + bs, 2] = labels_test_reg[bs * i: bs * i + bs, 2]\n",
    "\n",
    "# Calculate azimuth estimation error\n",
    "azim_tot = 0\n",
    "for i in range(len(out_test_reg)):\n",
    "    azim_tot += np.linalg.norm(out_test_reg[i, 1] - labels_test_reg[i, 1])\n",
    "\n",
    "azim_tot = azim_tot / len(out_test_reg)\n",
    "print(f'Azimuth Estimation Error (deg) = {azim_tot}')\n",
    "\n",
    "# Convert spherical coordinates to Cartesian coordinates\n",
    "new_data = Spher2Cart_2D(np.multiply(out_test_reg, [rng_res_ts, az_step_ts, el_step_ts]) + coord_ts)\n",
    "new_labels_data = Spher2Cart_2D(np.multiply(labels_test_reg, [rng_res_ts, az_step_ts, el_step_ts]) + coord_ts)\n",
    "\n",
    "# Calculate localization error\n",
    "sum_tot = 0\n",
    "for i in range(0, len(new_data) - (len(new_data) % bs), 1):\n",
    "    sum_tot += np.linalg.norm(new_data[i, :] - new_labels_data[i, :])\n",
    "\n",
    "sum_tot = sum_tot / (len(new_data) - (len(new_data) % bs))\n",
    "print(f'Localization Error (m) = {sum_tot}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning Regression CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.module.conv1.weight.requires_grad = False\n",
    "model.module.conv1.bias.requires_grad = False\n",
    "model.module.batchnorm1.weight.requires_grad = False\n",
    "model.module.batchnorm1.bias.requires_grad = False\n",
    "\n",
    "model.module.conv2.weight.requires_grad = False\n",
    "model.module.conv2.bias.requires_grad = False\n",
    "model.module.batchnorm2.weight.requires_grad = False\n",
    "model.module.batchnorm2.bias.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8277.83268109  7658.65198695 -1007.42637131]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8212.78333504  7629.19432455 -1010.66489415]\n",
      "Train Loss: 1.872207 ---- Test Loss: 2.408518\n",
      "Epoch 1/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8263.86391507  7684.67758597 -1008.09254961]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8207.39440844  7641.34778799 -1011.05532802]\n",
      "Train Loss: 1.362612 ---- Test Loss: 2.007727\n",
      "Epoch 2/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8250.33109672  7710.21173585 -1008.76366565]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8200.63541456  7653.72176265 -1011.37028635]\n",
      "Train Loss: 1.014777 ---- Test Loss: 1.759164\n",
      "Epoch 3/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8237.87645691  7734.39477264 -1009.42852875]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8194.50971398  7664.99880918 -1011.6608769 ]\n",
      "Train Loss: 0.823303 ---- Test Loss: 1.642658\n",
      "Epoch 4/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8227.37250616  7755.94081886 -1010.06396889]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8191.60244069  7672.20249463 -1011.91333624]\n",
      "Train Loss: 0.764580 ---- Test Loss: 1.613360\n",
      "Epoch 5/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8219.74020622  7773.33312171 -1010.63487492]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8191.32856999  7675.52690768 -1012.10023504]\n",
      "Train Loss: 0.791189 ---- Test Loss: 1.614556\n",
      "Epoch 6/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8215.54465     7785.41678796 -1011.10479759]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8193.3204808   7674.8860752  -1012.19179232]\n",
      "Train Loss: 0.843374 ---- Test Loss: 1.600963\n",
      "Epoch 7/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8214.70457392  7791.9384965  -1011.45117744]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8197.29792052  7670.66355196 -1012.19338149]\n",
      "Train Loss: 0.873940 ---- Test Loss: 1.553242\n",
      "Epoch 8/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8216.6768844   7793.46573157 -1011.67290022]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8202.68217963  7663.48962684 -1012.10622333]\n",
      "Train Loss: 0.863048 ---- Test Loss: 1.474334\n",
      "Epoch 9/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8220.78761335  7790.94417583 -1011.78440523]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8209.02914242  7654.22222007 -1011.95444812]\n",
      "Train Loss: 0.814269 ---- Test Loss: 1.378419\n",
      "Epoch 10/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8226.40744485  7785.38013048 -1011.80713259]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8215.83468612  7643.87888404 -1011.76785226]\n",
      "Train Loss: 0.743043 ---- Test Loss: 1.282168\n",
      "Epoch 11/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8232.9867054   7777.7207383  -1011.76409459]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8222.81672505  7632.90276093 -1011.55530074]\n",
      "Train Loss: 0.667353 ---- Test Loss: 1.199404\n",
      "Epoch 12/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8240.03360909  7768.83742316 -1011.67724524]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8229.6940833   7621.89297801 -1011.33507804]\n",
      "Train Loss: 0.602171 ---- Test Loss: 1.138590\n",
      "Epoch 13/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8247.0933271   7759.54521287 -1011.56720553]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8236.03065637  7611.41536511 -1011.11291701]\n",
      "Train Loss: 0.556750 ---- Test Loss: 1.101787\n",
      "Epoch 14/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8253.7429163   7750.60325918 -1011.45293783]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8241.69228848  7601.93788952 -1010.90831392]\n",
      "Train Loss: 0.533561 ---- Test Loss: 1.085161\n",
      "Epoch 15/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8259.60599466  7742.6908004  -1011.35126761]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8246.46918935  7593.93203609 -1010.73583965]\n",
      "Train Loss: 0.528823 ---- Test Loss: 1.080853\n",
      "Epoch 16/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8264.37910359  7736.3604314  -1011.27584045]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8250.33318146  7587.55712473 -1010.60297793]\n",
      "Train Loss: 0.534521 ---- Test Loss: 1.079910\n",
      "Epoch 17/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8267.85888975  7731.98892667 -1011.23602304]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8253.12086741  7583.09481584 -1010.51574146]\n",
      "Train Loss: 0.541435 ---- Test Loss: 1.075116\n",
      "Epoch 18/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8269.95597763  7729.74989271 -1011.23626726]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8254.83093761  7580.52964685 -1010.47283374]\n",
      "Train Loss: 0.542150 ---- Test Loss: 1.062823\n",
      "Epoch 19/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8270.68926927  7729.61840952 -1011.27610501]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8255.54417865  7579.69844901 -1010.46951418]\n",
      "Train Loss: 0.532953 ---- Test Loss: 1.043204\n",
      "Epoch 20/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8270.16599783  7731.40528762 -1011.35095725]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8255.37915226  7580.32431565 -1010.49671886]\n",
      "Train Loss: 0.514153 ---- Test Loss: 1.019267\n",
      "Epoch 21/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8268.55899551  7734.79684486 -1011.45304467]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8254.49579406  7582.0726982  -1010.5446855 ]\n",
      "Train Loss: 0.489120 ---- Test Loss: 0.995305\n",
      "Epoch 22/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8266.08457769  7739.396329   -1011.57241038]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8253.0822698   7584.56616292 -1010.60293814]\n",
      "Train Loss: 0.462673 ---- Test Loss: 0.975303\n",
      "Epoch 23/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8262.98937053  7744.75327033 -1011.69778483]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8251.34997936  7587.40508533 -1010.66117922]\n",
      "Train Loss: 0.439428 ---- Test Loss: 0.961726\n",
      "Epoch 24/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8259.53697231  7750.39239259 -1011.81742528]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8249.53915337  7590.1753033  -1010.71010091]\n",
      "Train Loss: 0.422498 ---- Test Loss: 0.954896\n",
      "Epoch 25/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8255.99721172  7755.84268923 -1011.92015886]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8247.92429753  7592.45232588 -1010.74199096]\n",
      "Train Loss: 0.412777 ---- Test Loss: 0.953092\n",
      "Epoch 26/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8252.63084939  7760.67094751 -1011.9964306 ]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8246.65794787  7594.01048133 -1010.75314985]\n",
      "Train Loss: 0.408969 ---- Test Loss: 0.953294\n",
      "Epoch 27/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8249.67122277  7764.51736815 -1012.03931088]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8245.92030717  7594.62994634 -1010.74206413]\n",
      "Train Loss: 0.408275 ---- Test Loss: 0.952305\n",
      "Epoch 28/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8247.30356411  7767.12764839 -1012.0451568 ]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8245.83500565  7594.19766517 -1010.71000336]\n",
      "Train Loss: 0.407498 ---- Test Loss: 0.947811\n",
      "Epoch 29/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8245.64595044  7768.37557783 -1012.01380556]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8246.45306782  7592.71230453 -1010.66027809]\n",
      "Train Loss: 0.404150 ---- Test Loss: 0.939031\n",
      "Epoch 30/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8244.74148074  7768.26558228 -1011.94825897]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8247.76661859  7590.25723849 -1010.59750183]\n",
      "Train Loss: 0.397185 ---- Test Loss: 0.926745\n",
      "Epoch 31/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8244.55596548  7766.9209819  -1011.85382875]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8249.6757298   7587.02933533 -1010.52713526]\n",
      "Train Loss: 0.387008 ---- Test Loss: 0.912864\n",
      "Epoch 32/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8244.99166171  7764.56523866 -1011.73787188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8252.03111809  7583.27647583 -1010.45447607]\n",
      "Train Loss: 0.375284 ---- Test Loss: 0.899627\n",
      "Epoch 33/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8245.89979097  7761.48996902 -1011.60862051]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8254.64749281  7579.27769592 -1010.3843059 ]\n",
      "Train Loss: 0.364044 ---- Test Loss: 0.888863\n",
      "Epoch 34/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8247.09941055  7758.02565731 -1011.47458657]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8257.31843076  7575.31791323 -1010.32031657]\n",
      "Train Loss: 0.354929 ---- Test Loss: 0.881388\n",
      "Epoch 35/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8248.39548403  7754.50902544 -1011.34371726]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8259.83751886  7571.66544367 -1010.26513702]\n",
      "Train Loss: 0.348715 ---- Test Loss: 0.876931\n",
      "Epoch 36/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8249.60035313  7751.25353147 -1011.22297783]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8262.02229372  7568.54443405 -1010.22025245]\n",
      "Train Loss: 0.345164 ---- Test Loss: 0.874356\n",
      "Epoch 37/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8250.55227075  7748.52157151 -1011.11786315]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8263.73174391  7566.11760499 -1010.18613654]\n",
      "Train Loss: 0.343235 ---- Test Loss: 0.872186\n",
      "Epoch 38/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8251.13125281  7746.50334141 -1011.03215347]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8264.88018517  7564.4713237  -1010.16228864]\n",
      "Train Loss: 0.341547 ---- Test Loss: 0.869132\n",
      "Epoch 39/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8251.26965086  7745.30109609 -1010.96766007]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8265.45074702  7563.61647004 -1010.148203  ]\n",
      "Train Loss: 0.339004 ---- Test Loss: 0.864544\n",
      "Epoch 40/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8250.96059794  7744.92997802 -1010.92484084]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8265.48733817  7563.4875685  -1010.14279108]\n",
      "Train Loss: 0.334999 ---- Test Loss: 0.858490\n",
      "Epoch 41/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8250.24959392  7745.31824302 -1010.90227121]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8265.08800722  7563.95652196 -1010.14477434]\n",
      "Train Loss: 0.329655 ---- Test Loss: 0.851629\n",
      "Epoch 42/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8249.22913263  7746.32163629 -1010.89716811]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8264.38886525  7564.85022834 -1010.15267785]\n",
      "Train Loss: 0.323638 ---- Test Loss: 0.844861\n",
      "Epoch 43/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8248.02498131  7747.7439336  -1010.90574111]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8263.54707298  7565.96834698 -1010.16476868]\n",
      "Train Loss: 0.317807 ---- Test Loss: 0.838959\n",
      "Epoch 44/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8246.7812117   7749.35815296 -1010.92350274]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8262.71910096  7567.10948514 -1010.17919577]\n",
      "Train Loss: 0.312858 ---- Test Loss: 0.834307\n",
      "Epoch 45/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8245.64302096  7750.9312879  -1010.94565518]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8262.04374956  7568.08375216 -1010.19362286]\n",
      "Train Loss: 0.309083 ---- Test Loss: 0.830819\n",
      "Epoch 46/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8244.74031716  7752.24835017 -1010.96749217]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8261.62551281  7568.73778224 -1010.2056495 ]\n",
      "Train Loss: 0.306309 ---- Test Loss: 0.828057\n",
      "Epoch 47/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8244.17221513  7753.13524361 -1010.9847959 ]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8261.52322917  7568.96964674 -1010.21297152]\n",
      "Train Loss: 0.304042 ---- Test Loss: 0.825460\n",
      "Epoch 48/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8243.99759627  7753.47454657 -1010.99419822]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8261.74825741  7568.73489692 -1010.21363389]\n",
      "Train Loss: 0.301707 ---- Test Loss: 0.822582\n",
      "Epoch 49/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8244.23025767  7753.21610149 -1010.99352154]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8262.2671956   7568.04846798 -1010.20632984]\n",
      "Train Loss: 0.298889 ---- Test Loss: 0.819243\n",
      "Epoch 50/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8244.83905938  7752.37946128 -1010.98194162]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8262.98965346  7566.98744499 -1010.1897539 ]\n",
      "Train Loss: 0.295514 ---- Test Loss: 0.815466\n",
      "Epoch 51/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8245.75672518  7751.0458225  -1010.96006393]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8263.83170095  7565.65913036 -1010.16487009]\n",
      "Train Loss: 0.291755 ---- Test Loss: 0.811550\n",
      "Epoch 52/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8246.890466    7749.34584838 -1010.92986254]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8264.70424681  7564.19481696 -1010.13375537]\n",
      "Train Loss: 0.287927 ---- Test Loss: 0.807831\n",
      "Epoch 53/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8248.13502684  7747.44168706 -1010.89442067]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8265.52309936  7562.73509905 -1010.09937117]\n",
      "Train Loss: 0.284379 ---- Test Loss: 0.804538\n",
      "Epoch 54/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8249.38326314  7745.50750229 -1010.85742193]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8266.21821274  7561.41182391 -1010.06507939]\n",
      "Train Loss: 0.281315 ---- Test Loss: 0.801719\n",
      "Epoch 55/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8250.53800633  7743.7085545  -1010.82264149]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8266.73772046  7560.33520589 -1010.03412899]\n",
      "Train Loss: 0.278732 ---- Test Loss: 0.799259\n",
      "Epoch 56/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8251.52026146  7742.18410571 -1010.79343731]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8267.05140495  7559.58165726 -1010.00915018]\n",
      "Train Loss: 0.276450 ---- Test Loss: 0.796961\n",
      "Epoch 57/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8252.27478943  7741.03388866 -1010.77229227]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8267.14957799  7559.18834652 -1009.9917527 ]\n",
      "Train Loss: 0.274213 ---- Test Loss: 0.794653\n",
      "Epoch 58/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8252.7739934   7740.30836621 -1010.76047831]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8267.04146491  7559.1513401  -1009.9823075 ]\n",
      "Train Loss: 0.271811 ---- Test Loss: 0.792255\n",
      "Epoch 59/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8253.01655696  7740.00810645 -1010.7579344 ]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8266.75164279  7559.42942874 -1009.97994299]\n",
      "Train Loss: 0.269162 ---- Test Loss: 0.789793\n",
      "Epoch 60/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8253.02596269  7740.08632987 -1010.7633275 ]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8266.31723788  7559.95065404 -1009.98275422]\n",
      "Train Loss: 0.266323 ---- Test Loss: 0.787361\n",
      "Epoch 61/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8252.84553121  7740.45829373 -1010.77430196]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8265.78375544  7560.62323539 -1009.98818796]\n",
      "Train Loss: 0.263447 ---- Test Loss: 0.785050\n",
      "Epoch 62/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8252.53177417  7741.01383428 -1010.78781017]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8265.2017602   7561.34687149 -1009.99350746]\n",
      "Train Loss: 0.260693 ---- Test Loss: 0.782890\n",
      "Epoch 63/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8252.14804959  7741.63308562 -1010.80065695]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8264.62250597  7562.02511105 -1009.99625322]\n",
      "Train Loss: 0.258154 ---- Test Loss: 0.780835\n",
      "Epoch 64/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8251.7569539   7742.20061221 -1010.80986593]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8264.11628309  7562.56738516 -1009.995587  ]\n",
      "Train Loss: 0.255878 ---- Test Loss: 0.778878\n",
      "Epoch 65/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8251.41463936  7742.6197087  -1010.8131832 ]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8263.71521934  7562.91876807 -1009.99029959]\n",
      "Train Loss: 0.253718 ---- Test Loss: 0.776900\n",
      "Epoch 66/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8251.16088293  7742.82396279 -1010.80913837]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8263.43656523  7563.05379264 -1009.97998535]\n",
      "Train Loss: 0.251556 ---- Test Loss: 0.774827\n",
      "Epoch 67/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8251.01679085  7742.78358579 -1010.79728372]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8263.28055034  7562.97894154 -1009.9650525 ]\n",
      "Train Loss: 0.249310 ---- Test Loss: 0.772657\n",
      "Epoch 68/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8250.98360792  7742.50574762 -1010.77813819]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8263.23224332  7562.72807915 -1009.94656903]\n",
      "Train Loss: 0.246959 ---- Test Loss: 0.770452\n",
      "Epoch 69/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8251.04434325  7742.03134545 -1010.75309587]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8263.26450537  7562.3560484  -1009.92606893]\n",
      "Train Loss: 0.244550 ---- Test Loss: 0.768307\n",
      "Epoch 70/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8251.16805745  7741.42620453 -1010.72416643]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8263.34002296  7561.93142413 -1009.90524535]\n",
      "Train Loss: 0.242160 ---- Test Loss: 0.766291\n",
      "Epoch 71/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8251.31406836  7740.77178816 -1010.69368012]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8263.41805611  7561.5248913  -1009.8856913 ]\n",
      "Train Loss: 0.239854 ---- Test Loss: 0.764423\n",
      "Epoch 72/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8251.43921841  7740.15155541 -1010.66392646]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8263.45870374  7561.20041127 -1009.86864554]\n",
      "Train Loss: 0.237660 ---- Test Loss: 0.762663\n",
      "Epoch 73/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8251.50357005  7739.6408115  -1010.63690496]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8263.42823768  7561.00757268 -1009.8548821 ]\n",
      "Train Loss: 0.235557 ---- Test Loss: 0.760930\n",
      "Epoch 74/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8251.47596601  7739.29643939 -1010.61406058]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8263.30399966  7560.97536372 -1009.84465772]\n",
      "Train Loss: 0.233496 ---- Test Loss: 0.759142\n",
      "Epoch 75/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8251.33802986  7739.15136886 -1010.59620737]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8263.05284924  7561.12015131 -1009.83676448]\n",
      "Train Loss: 0.231434 ---- Test Loss: 0.757149\n",
      "Epoch 76/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8251.08672652  7739.210585   -1010.58345216]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8262.68874902  7561.42357525 -1009.83101495]\n",
      "Train Loss: 0.229357 ---- Test Loss: 0.754977\n",
      "Epoch 77/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8250.7368883   7739.45226295 -1010.57542865]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8262.24240025  7561.84802701 -1009.82716396]\n",
      "Train Loss: 0.227247 ---- Test Loss: 0.752704\n",
      "Epoch 78/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8250.318032    7739.83283662 -1010.57139908]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8261.75496888  7562.34303695 -1009.82487904]\n",
      "Train Loss: 0.225138 ---- Test Loss: 0.750430\n",
      "Epoch 79/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8249.86878424  7740.29312469 -1010.57026449]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8261.27036278  7562.85336748 -1009.82371861]\n",
      "Train Loss: 0.223068 ---- Test Loss: 0.748240\n",
      "Epoch 80/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8249.4301659   7740.76958179 -1010.57081398]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8260.87397557  7563.31849042 -1009.8256762 ]\n",
      "Train Loss: 0.221053 ---- Test Loss: 0.746329\n",
      "Epoch 81/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8249.04028103  7741.20087931 -1010.57178067]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8260.60253261  7563.68872661 -1009.83016773]\n",
      "Train Loss: 0.219092 ---- Test Loss: 0.744730\n",
      "Epoch 82/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8248.72332067  7741.53803652 -1010.57174505]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8260.43763231  7563.94439677 -1009.83476967]\n",
      "Train Loss: 0.217154 ---- Test Loss: 0.743290\n",
      "Epoch 83/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8248.48549832  7741.74990371 -1010.56920622]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8260.34330729  7564.08410963 -1009.83700452]\n",
      "Train Loss: 0.215222 ---- Test Loss: 0.741826\n",
      "Epoch 84/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8248.31756025  7741.82696728 -1010.56297871]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8260.27701083  7564.12370477 -1009.83500714]\n",
      "Train Loss: 0.213288 ---- Test Loss: 0.740178\n",
      "Epoch 85/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8248.20043027  7741.78107239 -1010.55254356]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8260.20183361  7564.09126372 -1009.828033  ]\n",
      "Train Loss: 0.211349 ---- Test Loss: 0.738257\n",
      "Epoch 86/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8248.11036913  7741.64117543 -1010.53812464]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8260.09350967  7564.02260418 -1009.81664948]\n",
      "Train Loss: 0.209416 ---- Test Loss: 0.736065\n",
      "Epoch 87/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8248.02543832  7741.44845886 -1010.52081073]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8259.91768286  7563.96513086 -1009.80145861]\n",
      "Train Loss: 0.207505 ---- Test Loss: 0.733585\n",
      "Epoch 88/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8247.92779529  7741.24897928 -1010.50225539]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8259.68821735  7563.94953319 -1009.78525107]\n",
      "Train Loss: 0.205635 ---- Test Loss: 0.730982\n",
      "Epoch 89/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8247.80946004  7741.085444   -1010.48454973]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8259.45568178  7563.98693054 -1009.77206657]\n",
      "Train Loss: 0.203807 ---- Test Loss: 0.728541\n",
      "Epoch 90/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8247.66964407  7740.99140039 -1010.46969325]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8259.23572947  7564.0916588  -1009.76381903]\n",
      "Train Loss: 0.202013 ---- Test Loss: 0.726366\n",
      "Epoch 91/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8247.50966293  7740.98708392 -1010.45900879]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8259.03250852  7564.2677225  -1009.76102835]\n",
      "Train Loss: 0.200229 ---- Test Loss: 0.724478\n",
      "Epoch 92/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8247.33015793  7741.07846572 -1010.45290339]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8258.83701108  7564.51011221 -1009.76279082]\n",
      "Train Loss: 0.198443 ---- Test Loss: 0.722828\n",
      "Epoch 93/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8247.13148675  7741.25658712 -1010.45085299]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8258.60615673  7564.81537133 -1009.76603207]\n",
      "Train Loss: 0.196673 ---- Test Loss: 0.721198\n",
      "Epoch 94/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8246.91462315  7741.49984858 -1010.4516009 ]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8258.33128037  7565.16120568 -1009.7688189 ]\n",
      "Train Loss: 0.194912 ---- Test Loss: 0.719491\n",
      "Epoch 95/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8246.6857676   7741.77792195 -1010.45369709]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8258.02683847  7565.51555409 -1009.77016033]\n",
      "Train Loss: 0.193175 ---- Test Loss: 0.717692\n",
      "Epoch 96/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8246.45673947  7742.05666173 -1010.45582381]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8257.77967795  7565.83258141 -1009.7730383 ]\n",
      "Train Loss: 0.191435 ---- Test Loss: 0.716061\n",
      "Epoch 97/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8246.24311668  7742.30441541 -1010.45706015]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8257.57918963  7566.09650052 -1009.77578534]\n",
      "Train Loss: 0.189710 ---- Test Loss: 0.714497\n",
      "Epoch 98/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8246.05132084  7742.49787323 -1010.45639873]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8257.40629393  7566.30135732 -1009.77676991]\n",
      "Train Loss: 0.187995 ---- Test Loss: 0.712883\n",
      "Epoch 99/100\n",
      "----------\n",
      "[-8255.18942259  7711.56815611 -1009.16351357]\n",
      "[-8245.8809616   7742.62447685 -1010.45304585]\n",
      "[-8158.89281434  7668.78787744 -1009.55199919]\n",
      "[-8257.24087658  7566.450564   -1009.77486239]\n",
      "Train Loss: 0.186285 ---- Test Loss: 0.711125\n"
     ]
    }
   ],
   "source": [
    "bs = 64  # batch_size\n",
    "num_epoch = 100\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "\n",
    "def main(training_names, test_names, bs, num_epoch, y_train, y_test, normalize=True):\n",
    "    best_error = 1e+20  # a dummy and very large number for saving the best discovered model\n",
    "    for epoch in range(num_epoch):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epoch))\n",
    "        print('-' * 10)\n",
    "        running_loss_train = 0\n",
    "        running_loss_test = 0\n",
    "\n",
    "        model.train()\n",
    "        for i in range(0, len(training_names) // bs):\n",
    "            x_train, labels = Drawing_Batch(training_names, y_train, bs, i, f'num{scenario_idx_test}_NAMF_DATA_20_rng30_pulse1_1000_100k/', normalize)\n",
    "            x_train = x_train.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(x_train)\n",
    "            loss = criterion(out, labels[:, 0:2])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss_train += loss.item()\n",
    "            \n",
    "        out = torch.cat((out, torch.unsqueeze(labels[:,2], dim=1)), dim=1)\n",
    "\n",
    "        # Training error display\n",
    "        true_train = Spher2Cart_1D(np.multiply(labels.cpu().data.numpy()[1], [rng_res_tr, az_step_tr, el_step_tr]) + coord_tr)\n",
    "        pred_train = Spher2Cart_1D(np.multiply(out.cpu().data.numpy()[1], [rng_res_tr, az_step_tr, el_step_tr]) + coord_tr)\n",
    "        print(true_train)\n",
    "        print(pred_train)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, len(test_names) // bs):\n",
    "                x_test, labels_test = Drawing_Batch(test_names, y_test, bs, i, f'num{scenario_idx_test}_NAMF_DATA_20_rng30_pulse1_1000_100k/', normalize)\n",
    "                x_test = x_test.to(device)\n",
    "                labels_test = labels_test.to(device)\n",
    "                out_test = model(x_test)\n",
    "                loss_test = criterion(out_test, labels_test[:, 0:2])\n",
    "                running_loss_test += loss_test.item()\n",
    "                \n",
    "        out_test = torch.cat((out_test, torch.unsqueeze(labels_test[:,2], dim=1)), dim=1)\n",
    "\n",
    "        # Test error display\n",
    "        true_test = Spher2Cart_1D(np.multiply(labels_test.cpu().data.numpy()[1], [rng_res_ts, az_step_ts, el_step_ts]) + coord_ts)\n",
    "        pred_test = Spher2Cart_1D(np.multiply(out_test.cpu().data.numpy()[1], [rng_res_ts, az_step_ts, el_step_ts]) + coord_ts)\n",
    "        print(true_test)\n",
    "        print(pred_test)\n",
    "\n",
    "        epoch_loss_train = running_loss_train * x_train.size(0) / len(training_names)\n",
    "        epoch_loss_test = running_loss_test * x_test.size(0) / len(test_names)\n",
    "\n",
    "        print('Train Loss: {:.6f} ---- Test Loss: {:.6f}'.format(epoch_loss_train, epoch_loss_test))\n",
    "        if epoch % 5 == 0:\n",
    "            if epoch_loss_test < best_error:\n",
    "                torch.save(model.state_dict(), PATH)\n",
    "                best_error = epoch_loss_test\n",
    "\n",
    "main(names_FS, test_names, bs, num_epoch, y_FS, y_test, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azimuth Estimation Error (deg) = 0.5053627958966188\n",
      "Localization Error (m) = 47.23125310819853\n"
     ]
    }
   ],
   "source": [
    "def Spher2Cart_2D(spherical):\n",
    "    cartesian = np.zeros((len(spherical), 3))\n",
    "    hypotenuse = np.multiply(np.cos(np.radians(spherical[:, 2])), spherical[:, 0])\n",
    "    cartesian[:, 0] = np.multiply(np.cos(np.radians(spherical[:, 1])), hypotenuse)\n",
    "    cartesian[:, 1] = np.multiply(-np.sin(np.radians(spherical[:, 1])), hypotenuse)\n",
    "    cartesian[:, 2] = np.multiply(np.sin(np.radians(spherical[:, 2])), spherical[:, 0])\n",
    "    return cartesian\n",
    "\n",
    "# Testing: (range, az, el)\n",
    "model.eval()\n",
    "out_test_reg = np.zeros((len(y_test), 3))\n",
    "labels_test_reg = np.zeros((len(y_test), 3))\n",
    "\n",
    "for i in range(0, len(y_test) // bs):\n",
    "    x_test, labels_test = Drawing_Batch(test_names, y_test, bs, i, f'num{scenario_idx_test}_NAMF_DATA_20_rng30_pulse1_1000_100k/', True)\n",
    "    x_test = x_test.to(device)\n",
    "    labels_test = labels_test.cpu().data.numpy()\n",
    "    labels_test_reg[bs * i: bs * i + bs] = (labels_test[:, 0:3])\n",
    "\n",
    "    cur_test_reg = model(x_test)\n",
    "    out_test_reg[bs * i: bs * i + bs, 0:2] = cur_test_reg.cpu().data.numpy()\n",
    "    out_test_reg[bs * i: bs * i + bs, 2] = labels_test_reg[bs * i: bs * i + bs, 2]\n",
    "\n",
    "# Calculate azimuth estimation error\n",
    "azim_tot = 0\n",
    "for i in range(len(out_test_reg)):\n",
    "    azim_tot += np.linalg.norm(out_test_reg[i, 1] - labels_test_reg[i, 1])\n",
    "\n",
    "azim_tot = azim_tot / len(out_test_reg)\n",
    "print(f'Azimuth Estimation Error (deg) = {azim_tot}')\n",
    "\n",
    "# Convert spherical coordinates to Cartesian coordinates\n",
    "new_data = Spher2Cart_2D(np.multiply(out_test_reg, [rng_res_ts, az_step_ts, el_step_ts]) + coord_ts)\n",
    "new_labels_data = Spher2Cart_2D(np.multiply(labels_test_reg, [rng_res_ts, az_step_ts, el_step_ts]) + coord_ts)\n",
    "\n",
    "# Calculate localization error\n",
    "sum_tot = 0\n",
    "for i in range(0, len(new_data) - (len(new_data) % bs), 1):\n",
    "    sum_tot += np.linalg.norm(new_data[i, :] - new_labels_data[i, :])\n",
    "\n",
    "sum_tot = sum_tot / (len(new_data) - (len(new_data) % bs))\n",
    "print(f'Localization Error (m) = {sum_tot}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
