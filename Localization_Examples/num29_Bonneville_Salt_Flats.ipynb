{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Regression Network on Radar Dataset (Bonneville Salt Flats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "import scipy.io as sio\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import itertools\n",
    "import time\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import KFold\n",
    "from itertools import product\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the labels and creating train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "Training labels: \n",
      "[[ 8.3355 13.325  19.525 ]\n",
      " [18.156  17.388  32.775 ]\n",
      " [ 8.777  24.73   18.582 ]\n",
      " ...\n",
      " [15.785  15.992  29.641 ]\n",
      " [ 3.1736 10.716  12.27  ]\n",
      " [ 4.5552 21.035  14.234 ]]\n"
     ]
    }
   ],
   "source": [
    "def index(string):\n",
    "    s = re.findall(\"[0-9]\", string)\n",
    "    return int(''.join(s))\n",
    "\n",
    "scenario_idx = 29 # Bonneville Salt Flats\n",
    "names = os.listdir(f'num{scenario_idx}_NAMF_DATA_20_rng30_pulse1_1000_100k/')\n",
    "names = sorted(names, key = index)\n",
    "print(len(names))\n",
    "y = pd.read_csv(f'num{scenario_idx}_Ground_Truth_20_rng30_1000_100k_m.csv')\n",
    "col_names = y.columns[4:7]\n",
    "y = y[col_names].to_numpy()\n",
    "\n",
    "y_train = y[:int(0.9*len(names))]\n",
    "y_test = y[(int(0.9*len(names))+1):]\n",
    "training_names = names[:int(0.9*len(names))]\n",
    "test_names = names[(int(0.9*len(names))+1):]\n",
    "\n",
    "print('Training labels: ')\n",
    "print(y_train)\n",
    "\n",
    "# Tensor Corners\n",
    "##################################################################################\n",
    "# num29: [10851, 215, -5.45], num60: [11073, 215, -5.3], num62: [11471, 215, -5.6]\n",
    "# num76: [11388, 215, -6.15], num35: [11381, 215, -0.95]\n",
    "##################################################################################\n",
    "\n",
    "# Training dataset global constants\n",
    "coord_tr = [10851, 215, -5.45] # Tensor corner\n",
    "rng_res_tr = 59.9585/2         # Range resolution\n",
    "az_step_tr = 0.4               # Azimuth step size\n",
    "el_step_tr = 0.01              # Elevation step size\n",
    "\n",
    "# Test dataset global constants\n",
    "coord_ts = [10851, 215, -5.45] # Tensor corner\n",
    "rng_res_ts = 59.9585/2         # Range resolution\n",
    "az_step_ts = 0.4               # Azimuth step size\n",
    "el_step_ts = 0.01              # Elevation step size\n",
    "\n",
    "\n",
    "def Drawing_Batch(names, label, bs, ind, normalize = True):\n",
    "    x = []\n",
    "    labels = []\n",
    "    \n",
    "    for j in range(ind*bs, (ind+1)*bs):\n",
    "        try: temp = sio.loadmat(f'num{scenario_idx}_NAMF_DATA_20_rng30_pulse1_1000_100k/'+names[j])['P']\n",
    "        except: break\n",
    "        if normalize:\n",
    "            Anorm = temp - np.min(temp.flatten())\n",
    "            temp = np.divide(Anorm, np.max(Anorm.flatten()))\n",
    "        x.append(temp)\n",
    "        labels.append(label[j,:])\n",
    "        \n",
    "    x = torch.FloatTensor(np.array(x))\n",
    "    labels = torch.FloatTensor(np.array(labels))\n",
    "    return x,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90000\n",
      "9999\n"
     ]
    }
   ],
   "source": [
    "print(len(y_train))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a regression CNN and instantiating it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1               [-1, 32, 24]           2,048\n",
      "       BatchNorm1d-2               [-1, 32, 24]              64\n",
      "            Conv1d-3               [-1, 64, 10]           6,208\n",
      "       BatchNorm1d-4               [-1, 64, 10]             128\n",
      "            Linear-5                   [-1, 20]           6,420\n",
      "            Linear-6                    [-1, 2]              42\n",
      "               Net-7                    [-1, 2]               0\n",
      "================================================================\n",
      "Total params: 14,910\n",
      "Trainable params: 14,910\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.02\n",
      "Params size (MB): 0.06\n",
      "Estimated Total Size (MB): 0.08\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(21, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv1d(32, 64, 3, 1)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(32)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(64)\n",
    "        self.fc1 = nn.Linear(64 * 5, 20)  # Adjust input size based on the output of conv layers and max pooling\n",
    "        self.fc2_reg = nn.Linear(20, 2)  # Adjusted output size\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(self.batchnorm1(x))\n",
    "        x = F.max_pool1d(x, 2)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(self.batchnorm2(x))\n",
    "        x = F.max_pool1d(x, 2)\n",
    "        \n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        output_reg = self.fc2_reg(x)  # (bs, 2)\n",
    "        \n",
    "        return output_reg\n",
    "    \n",
    "from torchsummary import summary\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "model = Net()\n",
    "model = model.to(device)\n",
    "if device == 'cuda:0':\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    cudnn.benchmark = True\n",
    "print(summary(model,(21,26)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 128  # batch_size\n",
    "num_epoch = 50  # number of epochs\n",
    "PATH = './ckpt_model.pth'   # forsaving the model\n",
    "criterion = nn.MSELoss()\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Define a Loss function and optimizer; Using GPU or CPU\n",
    "model = Net()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "model = model.to(device)\n",
    "if device == 'cuda:0':\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    cudnn.benchmark = True\n",
    "    \n",
    "def Spher2Cart_1D(spherical):\n",
    "    cartesian = np.zeros(3)\n",
    "    hypotenuse = np.cos(np.radians(spherical[2]))*spherical[0]\n",
    "    cartesian[0] = np.cos(np.radians(spherical[1]))*hypotenuse\n",
    "    cartesian[1] = -np.sin(np.radians(spherical[1]))*hypotenuse\n",
    "    cartesian[2] = np.sin(np.radians(spherical[2]))*spherical[0]\n",
    "    return cartesian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evaluate the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/50\n",
      "----------\n",
      "[-8186.81883329  7784.2224851  -1018.06044859]\n",
      "[-8207.914792    7736.7067508  -1016.49717137]\n",
      "[-8125.48964839  7398.39800145 -1016.23626902]\n",
      "[-8124.88387367  7412.59946196 -1017.07953133]\n",
      "Train Loss: 9.488018 ---- Test Loss: 0.327968\n",
      "Epoch 1/50\n",
      "----------\n",
      "[-8186.81883329  7784.2224851  -1018.06044859]\n",
      "[-8203.97552521  7735.17391698 -1016.14410011]\n",
      "[-8125.48964839  7398.39800145 -1016.23626902]\n",
      "[-8121.50674041  7412.30993288 -1016.83078776]\n",
      "Train Loss: 0.180326 ---- Test Loss: 0.230180\n",
      "Epoch 2/50\n",
      "----------\n",
      "[-8186.81883329  7784.2224851  -1018.06044859]\n",
      "[-8201.01302579  7740.00513615 -1016.24865271]\n",
      "[-8125.48964839  7398.39800145 -1016.23626902]\n",
      "[-8125.23309003  7410.76971859 -1016.98935532]\n",
      "Train Loss: 0.122232 ---- Test Loss: 0.190446\n",
      "Epoch 3/50\n",
      "----------\n",
      "[-8186.81883329  7784.2224851  -1018.06044859]\n",
      "[-8205.49933034  7730.70986317 -1015.96810851]\n",
      "[-8125.48964839  7398.39800145 -1016.23626902]\n",
      "[-8143.7356327   7387.47861054 -1016.80580849]\n",
      "Train Loss: 0.102905 ---- Test Loss: 0.267881\n",
      "Epoch 4/50\n",
      "----------\n",
      "[-8186.81883329  7784.2224851  -1018.06044859]\n",
      "[-8207.14827428  7724.58788896 -1015.69806755]\n",
      "[-8125.48964839  7398.39800145 -1016.23626902]\n",
      "[-8156.70237072  7369.75119331 -1016.59449435]\n",
      "Train Loss: 0.098493 ---- Test Loss: 0.354013\n",
      "Epoch 5/50\n",
      "----------\n",
      "[-8186.81883329  7784.2224851  -1018.06044859]\n",
      "[-8203.72721455  7728.42046472 -1015.7103902 ]\n",
      "[-8125.48964839  7398.39800145 -1016.23626902]\n",
      "[-8157.81140937  7362.93357585 -1016.2480623 ]\n",
      "Train Loss: 0.101872 ---- Test Loss: 0.352190\n",
      "Epoch 6/50\n",
      "----------\n",
      "[-8186.81883329  7784.2224851  -1018.06044859]\n",
      "[-8200.71195516  7730.51651259 -1015.6421794 ]\n",
      "[-8125.48964839  7398.39800145 -1016.23626902]\n",
      "[-8154.43660259  7357.00723683 -1015.64919957]\n",
      "Train Loss: 0.105283 ---- Test Loss: 0.314123\n",
      "Epoch 7/50\n",
      "----------\n",
      "[-8186.81883329  7784.2224851  -1018.06044859]\n",
      "[-8198.91077616  7734.10123735 -1015.74571837]\n",
      "[-8125.48964839  7398.39800145 -1016.23626902]\n",
      "[-8145.7119856   7362.42312748 -1015.38606028]\n",
      "Train Loss: 0.104954 ---- Test Loss: 0.272446\n",
      "Epoch 8/50\n",
      "----------\n",
      "[-8186.81883329  7784.2224851  -1018.06044859]\n",
      "[-8198.04930417  7740.21642329 -1016.06750058]\n",
      "[-8125.48964839  7398.39800145 -1016.23626902]\n",
      "[-8140.14626792  7367.8247471  -1015.33941897]\n",
      "Train Loss: 0.105184 ---- Test Loss: 0.187576\n",
      "Epoch 9/50\n",
      "----------\n",
      "[-8186.81883329  7784.2224851  -1018.06044859]\n",
      "[-8194.9763819   7752.74419624 -1016.64170969]\n",
      "[-8125.48964839  7398.39800145 -1016.23626902]\n",
      "[-8141.84371898  7366.36176948 -1015.36503273]\n",
      "Train Loss: 0.109858 ---- Test Loss: 0.157764\n",
      "Epoch 10/50\n",
      "----------\n",
      "[-8186.81883329  7784.2224851  -1018.06044859]\n",
      "[-8196.42488892  7756.9484922  -1016.99693908]\n",
      "[-8125.48964839  7398.39800145 -1016.23626902]\n",
      "[-8136.19697769  7382.87377176 -1016.00335339]\n",
      "Train Loss: 0.110577 ---- Test Loss: 0.068388\n",
      "Epoch 11/50\n",
      "----------\n",
      "[-8186.81883329  7784.2224851  -1018.06044859]\n",
      "[-8194.70266488  7759.37139531 -1017.034333  ]\n",
      "[-8125.48964839  7398.39800145 -1016.23626902]\n",
      "[-8139.38658929  7380.51610946 -1016.07534255]\n",
      "Train Loss: 0.097070 ---- Test Loss: 0.072230\n",
      "Epoch 12/50\n",
      "----------\n",
      "[-8186.81883329  7784.2224851  -1018.06044859]\n",
      "[-8194.07131468  7761.42714728 -1017.12041189]\n",
      "[-8125.48964839  7398.39800145 -1016.23626902]\n",
      "[-8143.10091681  7375.08082518 -1015.99234071]\n",
      "Train Loss: 0.087276 ---- Test Loss: 0.086003\n",
      "Epoch 13/50\n",
      "----------\n",
      "[-8186.81883329  7784.2224851  -1018.06044859]\n",
      "[-8192.51434405  7764.1016157  -1017.18432439]\n",
      "[-8125.48964839  7398.39800145 -1016.23626902]\n",
      "[-8143.02993487  7372.53119846 -1015.82921196]\n",
      "Train Loss: 0.085575 ---- Test Loss: 0.082183\n",
      "Epoch 14/50\n",
      "----------\n",
      "[-8186.81883329  7784.2224851  -1018.06044859]\n",
      "[-8190.55007957  7767.00993579 -1017.23617599]\n",
      "[-8125.48964839  7398.39800145 -1016.23626902]\n",
      "[-8140.94146951  7373.09248894 -1015.72089123]\n",
      "Train Loss: 0.085653 ---- Test Loss: 0.070713\n",
      "Epoch 15/50\n",
      "----------\n",
      "[-8186.81883329  7784.2224851  -1018.06044859]\n",
      "[-8190.00489486  7767.90400561 -1017.25597126]\n",
      "[-8125.48964839  7398.39800145 -1016.23626902]\n",
      "[-8135.08539961  7379.65832758 -1015.72741907]\n",
      "Train Loss: 0.083379 ---- Test Loss: 0.056369\n",
      "Epoch 16/50\n",
      "----------\n",
      "[-8186.81883329  7784.2224851  -1018.06044859]\n",
      "[-8190.17064798  7768.5511775  -1017.30694524]\n",
      "[-8125.48964839  7398.39800145 -1016.23626902]\n",
      "[-8137.3802458   7376.16652049 -1015.66771551]\n",
      "Train Loss: 0.080875 ---- Test Loss: 0.060178\n",
      "Epoch 17/50\n",
      "----------\n",
      "[-8186.81883329  7784.2224851  -1018.06044859]\n",
      "[-8189.89602784  7770.33013312 -1017.39932659]\n",
      "[-8125.48964839  7398.39800145 -1016.23626902]\n",
      "[-8138.19155635  7377.09421349 -1015.78092125]\n",
      "Train Loss: 0.079398 ---- Test Loss: 0.056747\n",
      "Epoch 18/50\n",
      "----------\n",
      "[-8186.81883329  7784.2224851  -1018.06044859]\n",
      "[-8191.64815907  7769.22616312 -1017.44541462]\n",
      "[-8125.48964839  7398.39800145 -1016.23626902]\n",
      "[-8139.61367582  7376.54156568 -1015.8440434 ]\n",
      "Train Loss: 0.078280 ---- Test Loss: 0.053622\n",
      "Epoch 19/50\n",
      "----------\n",
      "[-8186.81883329  7784.2224851  -1018.06044859]\n",
      "[-8191.27269503  7770.06416967 -1017.47283648]\n",
      "[-8125.48964839  7398.39800145 -1016.23626902]\n",
      "[-8136.08030827  7383.82937619 -1016.05475071]\n",
      "Train Loss: 0.075815 ---- Test Loss: 0.041290\n",
      "Epoch 20/50\n",
      "----------\n",
      "[-8186.81883329  7784.2224851  -1018.06044859]\n",
      "[-8191.11926123  7770.1444919  -1017.4677863 ]\n",
      "[-8125.48964839  7398.39800145 -1016.23626902]\n",
      "[-8138.53236259  7380.88064946 -1016.03947039]\n",
      "Train Loss: 0.073419 ---- Test Loss: 0.043682\n",
      "Epoch 21/50\n",
      "----------\n",
      "[-8186.81883329  7784.2224851  -1018.06044859]\n",
      "[-8189.80425424  7771.94202903 -1017.49331435]\n",
      "[-8125.48964839  7398.39800145 -1016.23626902]\n",
      "[-8136.90187344  7383.13823697 -1016.06806307]\n",
      "Train Loss: 0.071760 ---- Test Loss: 0.040473\n",
      "Epoch 22/50\n",
      "----------\n",
      "[-8186.81883329  7784.2224851  -1018.06044859]\n",
      "[-8188.8769473   7773.06276489 -1017.50222915]\n",
      "[-8125.48964839  7398.39800145 -1016.23626902]\n",
      "[-8135.78576008  7383.09721074 -1015.98907745]\n",
      "Train Loss: 0.070051 ---- Test Loss: 0.038736\n",
      "Epoch 23/50\n",
      "----------\n",
      "[-8186.81883329  7784.2224851  -1018.06044859]\n",
      "[-8188.61444982  7773.42904486 -1017.50779769]\n",
      "[-8125.48964839  7398.39800145 -1016.23626902]\n",
      "[-8132.4466709   7386.50354037 -1015.97219643]\n",
      "Train Loss: 0.068139 ---- Test Loss: 0.034738\n",
      "Epoch 24/50\n",
      "----------\n",
      "[-8186.81883329  7784.2224851  -1018.06044859]\n",
      "[-8188.49482363  7773.37663666 -1017.49672732]\n",
      "[-8125.48964839  7398.39800145 -1016.23626902]\n",
      "[-8133.58414326  7384.50939014 -1015.92609483]\n",
      "Train Loss: 0.066550 ---- Test Loss: 0.035730\n",
      "Epoch 25/50\n",
      "----------\n",
      "[-8186.81883329  7784.2224851  -1018.06044859]\n",
      "[-8189.17138256  7772.79665971 -1017.50496466]\n",
      "[-8125.48964839  7398.39800145 -1016.23626902]\n",
      "[-8130.79779333  7388.43987237 -1015.97974313]\n",
      "Train Loss: 0.064717 ---- Test Loss: 0.032671\n",
      "Epoch 26/50\n",
      "----------\n",
      "[-8186.81883329  7784.2224851  -1018.06044859]\n",
      "[-8189.35196153  7773.03210964 -1017.53137546]\n",
      "[-8125.48964839  7398.39800145 -1016.23626902]\n",
      "[-8130.85940427  7387.19845473 -1015.90675749]\n",
      "Train Loss: 0.062990 ---- Test Loss: 0.031853\n",
      "Epoch 27/50\n",
      "----------\n",
      "[-8186.81883329  7784.2224851  -1018.06044859]\n",
      "[-8189.41255274  7773.04007802 -1017.5358303 ]\n",
      "[-8125.48964839  7398.39800145 -1016.23626902]\n",
      "[-8130.02826318  7388.17919869 -1015.91086453]\n",
      "Train Loss: 0.061036 ---- Test Loss: 0.030561\n",
      "Epoch 28/50\n",
      "----------\n",
      "[-8186.81883329  7784.2224851  -1018.06044859]\n",
      "[-8189.06917941  7773.70896833 -1017.55488652]\n",
      "[-8125.48964839  7398.39800145 -1016.23626902]\n",
      "[-8132.08115536  7384.07471231 -1015.79616998]\n",
      "Train Loss: 0.059822 ---- Test Loss: 0.033686\n",
      "Epoch 29/50\n",
      "----------\n",
      "[-8186.81883329  7784.2224851  -1018.06044859]\n",
      "[-8189.58603393  7773.22650494 -1017.55873574]\n",
      "[-8125.48964839  7398.39800145 -1016.23626902]\n",
      "[-8130.70984601  7386.06280076 -1015.82590131]\n",
      "Train Loss: 0.058537 ---- Test Loss: 0.030711\n",
      "Epoch 30/50\n",
      "----------\n",
      "[-8186.81883329  7784.2224851  -1018.06044859]\n",
      "[-8189.42992528  7772.85508301 -1017.52548872]\n",
      "[-8125.48964839  7398.39800145 -1016.23626902]\n",
      "[-8130.56682451  7385.70424926 -1015.79381633]\n",
      "Train Loss: 0.056647 ---- Test Loss: 0.029671\n",
      "Epoch 31/50\n",
      "----------\n",
      "[-8186.81883329  7784.2224851  -1018.06044859]\n",
      "[-8189.66528105  7772.64772585 -1017.52800868]\n",
      "[-8125.48964839  7398.39800145 -1016.23626902]\n",
      "[-8131.29948648  7385.53785373 -1015.83362309]\n",
      "Train Loss: 0.055422 ---- Test Loss: 0.029518\n",
      "Epoch 32/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-8186.81883329  7784.2224851  -1018.06044859]\n",
      "[-8189.09224133  7773.00884026 -1017.51295565]\n",
      "[-8125.48964839  7398.39800145 -1016.23626902]\n",
      "[-8130.52802242  7386.23593863 -1015.82422164]\n",
      "Train Loss: 0.054564 ---- Test Loss: 0.027592\n",
      "Epoch 33/50\n",
      "----------\n",
      "[-8186.81883329  7784.2224851  -1018.06044859]\n",
      "[-8188.59529463  7773.60613866 -1017.51753366]\n",
      "[-8125.48964839  7398.39800145 -1016.23626902]\n",
      "[-8130.3389043   7386.02678472 -1015.79827089]\n",
      "Train Loss: 0.053713 ---- Test Loss: 0.027096\n",
      "Epoch 34/50\n",
      "----------\n",
      "[-8186.81883329  7784.2224851  -1018.06044859]\n",
      "[-8189.00022873  7773.10329541 -1017.51280168]\n",
      "[-8125.48964839  7398.39800145 -1016.23626902]\n",
      "[-8129.04414689  7387.97762662 -1015.8309772 ]\n",
      "Train Loss: 0.052637 ---- Test Loss: 0.025390\n",
      "Epoch 35/50\n",
      "----------\n",
      "[-8186.81883329  7784.2224851  -1018.06044859]\n",
      "[-8188.51562626  7773.69427775 -1017.5177954 ]\n",
      "[-8125.48964839  7398.39800145 -1016.23626902]\n",
      "[-8129.72246666  7386.92555066 -1015.81196895]\n",
      "Train Loss: 0.051457 ---- Test Loss: 0.025681\n",
      "Epoch 36/50\n",
      "----------\n",
      "[-8186.81883329  7784.2224851  -1018.06044859]\n",
      "[-8188.56088765  7773.67546901 -1017.51958658]\n",
      "[-8125.48964839  7398.39800145 -1016.23626902]\n",
      "[-8128.88309788  7387.23615858 -1015.77383923]\n",
      "Train Loss: 0.050607 ---- Test Loss: 0.025235\n",
      "Epoch 37/50\n",
      "----------\n",
      "[-8186.81883329  7784.2224851  -1018.06044859]\n",
      "[-8188.18054346  7774.52447027 -1017.54740876]\n",
      "[-8125.48964839  7398.39800145 -1016.23626902]\n",
      "[-8129.32201197  7386.13720863 -1015.73553443]\n",
      "Train Loss: 0.049697 ---- Test Loss: 0.024976\n",
      "Epoch 38/50\n",
      "----------\n",
      "[-8186.81883329  7784.2224851  -1018.06044859]\n",
      "[-8188.25225582  7774.48682313 -1017.54975935]\n",
      "[-8125.48964839  7398.39800145 -1016.23626902]\n",
      "[-8129.30446194  7385.50217746 -1015.69484308]\n",
      "Train Loss: 0.048761 ---- Test Loss: 0.025155\n",
      "Epoch 39/50\n",
      "----------\n",
      "[-8186.81883329  7784.2224851  -1018.06044859]\n",
      "[-8187.91398606  7774.89502016 -1017.55298243]\n",
      "[-8125.48964839  7398.39800145 -1016.23626902]\n",
      "[-8126.68141659  7389.55898476 -1015.76766944]\n",
      "Train Loss: 0.047680 ---- Test Loss: 0.022935\n",
      "Epoch 40/50\n",
      "----------\n",
      "[-8186.81883329  7784.2224851  -1018.06044859]\n",
      "[-8187.81078835  7775.13685347 -1017.56124543]\n",
      "[-8125.48964839  7398.39800145 -1016.23626902]\n",
      "[-8128.24703869  7387.53303951 -1015.7487744 ]\n",
      "Train Loss: 0.046838 ---- Test Loss: 0.023429\n",
      "Epoch 41/50\n",
      "----------\n",
      "[-8186.81883329  7784.2224851  -1018.06044859]\n",
      "[-8187.81307213  7775.01130082 -1017.55360344]\n",
      "[-8125.48964839  7398.39800145 -1016.23626902]\n",
      "[-8127.01073244  7389.10742477 -1015.76210913]\n",
      "Train Loss: 0.046185 ---- Test Loss: 0.022507\n",
      "Epoch 42/50\n",
      "----------\n",
      "[-8186.81883329  7784.2224851  -1018.06044859]\n",
      "[-8187.66905259  7775.3870893  -1017.56751197]\n",
      "[-8125.48964839  7398.39800145 -1016.23626902]\n",
      "[-8128.35676009  7387.62861167 -1015.76222761]\n",
      "Train Loss: 0.045382 ---- Test Loss: 0.022689\n",
      "Epoch 43/50\n",
      "----------\n",
      "[-8186.81883329  7784.2224851  -1018.06044859]\n",
      "[-8187.70727866  7775.4043145  -1017.57107891]\n",
      "[-8125.48964839  7398.39800145 -1016.23626902]\n",
      "[-8125.99903696  7391.00460566 -1015.81092902]\n",
      "Train Loss: 0.044642 ---- Test Loss: 0.021733\n",
      "Epoch 44/50\n",
      "----------\n",
      "[-8186.81883329  7784.2224851  -1018.06044859]\n",
      "[-8188.12525112  7774.92644017 -1017.56873859]\n",
      "[-8125.48964839  7398.39800145 -1016.23626902]\n",
      "[-8126.88870119  7390.40145649 -1015.83426679]\n",
      "Train Loss: 0.043933 ---- Test Loss: 0.021708\n",
      "Epoch 45/50\n",
      "----------\n",
      "[-8186.81883329  7784.2224851  -1018.06044859]\n",
      "[-8188.27883334  7775.07683363 -1017.58810788]\n",
      "[-8125.48964839  7398.39800145 -1016.23626902]\n",
      "[-8126.93690055  7390.63232196 -1015.85192841]\n",
      "Train Loss: 0.043070 ---- Test Loss: 0.021560\n",
      "Epoch 46/50\n",
      "----------\n",
      "[-8186.81883329  7784.2224851  -1018.06044859]\n",
      "[-8188.40285651  7774.90535903 -1017.58557252]\n",
      "[-8125.48964839  7398.39800145 -1016.23626902]\n",
      "[-8126.59137205  7391.58567939 -1015.88760838]\n",
      "Train Loss: 0.042503 ---- Test Loss: 0.021351\n",
      "Epoch 47/50\n",
      "----------\n",
      "[-8186.81883329  7784.2224851  -1018.06044859]\n",
      "[-8188.23133033  7774.68941776 -1017.56096316]\n",
      "[-8125.48964839  7398.39800145 -1016.23626902]\n",
      "[-8126.65634443  7391.74443524 -1015.90193171]\n",
      "Train Loss: 0.042159 ---- Test Loss: 0.021059\n",
      "Epoch 48/50\n",
      "----------\n",
      "[-8186.81883329  7784.2224851  -1018.06044859]\n",
      "[-8188.37223105  7774.58560084 -1017.56372946]\n",
      "[-8125.48964839  7398.39800145 -1016.23626902]\n",
      "[-8126.16681343  7393.32434822 -1015.96676118]\n",
      "Train Loss: 0.041747 ---- Test Loss: 0.020618\n",
      "Epoch 49/50\n",
      "----------\n",
      "[-8186.81883329  7784.2224851  -1018.06044859]\n",
      "[-8188.7139253   7774.28368749 -1017.56732721]\n",
      "[-8125.48964839  7398.39800145 -1016.23626902]\n",
      "[-8126.10996023  7392.8954744  -1015.93618211]\n",
      "Train Loss: 0.041318 ---- Test Loss: 0.020466\n",
      "3187.136983156204\n"
     ]
    }
   ],
   "source": [
    "def main(training_names, test_names, bs, num_epoch, y_train, y_test, normalize=True):\n",
    "    best_error = 1e+20      # a dummy and very large number for saving the best discovered model\n",
    "    for epoch in range(num_epoch):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epoch))\n",
    "        print('-'*10)\n",
    "        running_loss_train = 0\n",
    "        running_loss_test = 0\n",
    "\n",
    "        model.train()\n",
    "        for i in range(0, len(training_names)//bs):\n",
    "            x_train, labels = Drawing_Batch(training_names, y_train, bs, i, normalize)\n",
    "            x_train = x_train.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(x_train)\n",
    "            loss = criterion(out, labels[:,0:2])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss_train += loss.item()\n",
    "            \n",
    "        out = torch.cat((out, torch.unsqueeze(labels[:,2], dim=1)), dim=1)\n",
    "        \n",
    "        true_train = Spher2Cart_1D(np.multiply(labels.cpu().data.numpy()[1,], [rng_res_tr,az_step_tr,el_step_tr]) + coord_tr)\n",
    "        pred_train = Spher2Cart_1D(np.multiply(out.cpu().data.numpy()[1,], [rng_res_tr,az_step_tr,el_step_tr]) + coord_tr)\n",
    "        print(true_train)\n",
    "        print(pred_train)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, len(test_names)//bs):\n",
    "                x_test, labels_test = Drawing_Batch(test_names, y_test, bs, i, normalize)\n",
    "                x_test = x_test.to(device)\n",
    "                labels_test = labels_test.to(device)\n",
    "                out_test = model(x_test)\n",
    "                loss_test = criterion(out_test, labels_test[:,0:2])\n",
    "                running_loss_test += loss_test.item()\n",
    "\n",
    "        out_test = torch.cat((out_test, torch.unsqueeze(labels_test[:,2], dim=1)), dim=1)\n",
    "        \n",
    "        true_test = Spher2Cart_1D(np.multiply(labels_test.cpu().data.numpy()[1,], [rng_res_ts,az_step_ts,el_step_ts]) + coord_ts)\n",
    "        pred_test = Spher2Cart_1D(np.multiply(out_test.cpu().data.numpy()[1,], [rng_res_ts,az_step_ts,el_step_ts]) + coord_ts)\n",
    "        print(true_test)\n",
    "        print(pred_test)\n",
    "        \n",
    "        epoch_loss_train = running_loss_train*x_train.size()[0]/len(training_names)\n",
    "        epoch_loss_test = running_loss_test*x_test.size()[0]/len(test_names)\n",
    "\n",
    "        print('Train Loss: {:.6f} ---- Test Loss: {:.6f}'.format(epoch_loss_train, epoch_loss_test))\n",
    "        if epoch%5==0:\n",
    "            if epoch_loss_test < best_error:\n",
    "                torch.save(model.state_dict(), PATH)\n",
    "                best_accuracy = epoch_loss_test\n",
    "\n",
    "start = time.time()\n",
    "main(training_names, test_names, bs, num_epoch, y_train, y_test, normalize=True)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azimuth Estimation Error (deg) = 0.12086916747170932\n",
      "Localization Error (m) = 10.370532765975286\n"
     ]
    }
   ],
   "source": [
    "def Spher2Cart_2D(spherical):\n",
    "    cartesian = np.zeros((len(spherical),3))\n",
    "    hypotenuse = np.multiply(np.cos(np.radians(spherical[:,2])), spherical[:,0])\n",
    "    cartesian[:,0] = np.multiply(np.cos(np.radians(spherical[:,1])), hypotenuse)\n",
    "    cartesian[:,1] = np.multiply(-np.sin(np.radians(spherical[:,1])), hypotenuse)\n",
    "    cartesian[:,2] = np.multiply(np.sin(np.radians(spherical[:,2])), spherical[:,0])\n",
    "    return cartesian\n",
    "\n",
    "# Testing: (range,az,el)\n",
    "model.eval()\n",
    "out_test_reg = np.zeros((len(y_test),3))\n",
    "labels_test_reg = np.zeros((len(y_test),3))\n",
    "\n",
    "for i in range(0, len(y_test)//bs):  \n",
    "    x_test, labels_test = Drawing_Batch(test_names, y_test, bs, i, True)\n",
    "    labels_test = labels_test.cpu().data.numpy()\n",
    "    labels_test_reg[bs*i : bs*i + bs] = (labels_test[:,0:3])\n",
    "\n",
    "    cur_test_reg = model(x_test)\n",
    "    out_test_reg[bs*i : bs*i + bs, 0:2] = cur_test_reg.cpu().data.numpy()\n",
    "    out_test_reg[bs*i : bs*i + bs, 2] = labels_test_reg[bs*i : bs*i + bs, 2]\n",
    "    \n",
    "azim_tot = 0\n",
    "for i in np.arange(0,len(out_test_reg),1):\n",
    "    azim_tot += np.linalg.norm(out_test_reg[i,1] - labels_test_reg[i,1])\n",
    "    \n",
    "azim_tot = azim_tot / len(out_test_reg)\n",
    "print(f'Azimuth Estimation Error (deg) = {azim_tot}')\n",
    "\n",
    "new_data = Spher2Cart_2D(np.multiply(out_test_reg, [rng_res_ts,az_step_ts,el_step_ts]) + coord_ts)\n",
    "new_labels_data = Spher2Cart_2D(np.multiply(labels_test_reg, [rng_res_ts,az_step_ts,el_step_ts]) + coord_ts)\n",
    "\n",
    "sum_tot = 0\n",
    "for i in np.arange(0,len(new_data) - (len(new_data) % bs),1):\n",
    "    sum_tot += np.linalg.norm(new_data[i,:] - new_labels_data[i,:])\n",
    "    \n",
    "# def reject_outliers(data, m=2):\n",
    "#     return data[abs(data - np.mean(data)) < m * np.std(data)]\n",
    "# \n",
    "# azims = (np.multiply(out_test_reg, [rng_res_ts,az_step_ts,el_step_ts]) - np.multiply(labels_test_reg, [rng_res_ts,az_step_ts,el_step_ts]))[:,1]\n",
    "# azims = reject_outliers(azims)\n",
    "# mse = np.mean(azims**2)\n",
    "# bias_sq = np.mean(azims)**2\n",
    "# var = np.var(azims)\n",
    "# print(mse, bias_sq, var)\n",
    "\n",
    "sum_tot = sum_tot / (len(new_data) - (len(new_data) % bs))\n",
    "print(f'Localization Error (m) = {sum_tot}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
