{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Regression Network on Radar Dataset (Bonneville Salt Flats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "import scipy.io as sio\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import itertools\n",
    "import time\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import KFold\n",
    "from itertools import product\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the labels and creating train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "Training labels: \n",
      "[[ 8.7792 13.519  19.533 ]\n",
      " [18.639  17.584  32.958 ]\n",
      " [ 9.2892 24.927  20.785 ]\n",
      " ...\n",
      " [ 3.8109 22.379  14.451 ]\n",
      " [ 4.4263 16.635  13.001 ]\n",
      " [11.102  21.151  21.626 ]]\n"
     ]
    }
   ],
   "source": [
    "def index(string):\n",
    "    s = re.findall(\"[0-9]\", string)\n",
    "    return int(''.join(s))\n",
    "\n",
    "scenario_idx = 29 # Bonneville Salt Flats\n",
    "names = os.listdir(f'num{scenario_idx}_NAMF_DATA_20_rng30_pulse1_1000_100k/')\n",
    "names = sorted(names, key = index)\n",
    "print(len(names))\n",
    "y = pd.read_csv(f'num{scenario_idx}_Ground_Truth_20_rng30_1000_100k_m.csv')\n",
    "col_names = y.columns[4:7]\n",
    "y = y[col_names].to_numpy()\n",
    "\n",
    "y_train = y[:int(0.9*len(names))]\n",
    "y_test = y[(int(0.9*len(names))+1):]\n",
    "training_names = names[:int(0.9*len(names))]\n",
    "test_names = names[(int(0.9*len(names))+1):]\n",
    "\n",
    "print('Training labels: ')\n",
    "print(y_train)\n",
    "\n",
    "# Tensor Corners\n",
    "##################################################################################\n",
    "# num29: [10851, 215, -5.45], num60: [11073, 215, -5.3], num62: [11471, 215, -5.6]\n",
    "# num76: [11388, 215, -6.15], num35: [11381, 215, -0.95]\n",
    "##################################################################################\n",
    "\n",
    "# Training dataset global constants\n",
    "coord_tr = [10851, 215, -5.45] # Tensor corner\n",
    "rng_res_tr = 59.9585/2         # Range resolution\n",
    "az_step_tr = 0.4               # Azimuth step size\n",
    "el_step_tr = 0.01              # Elevation step size\n",
    "\n",
    "# Test dataset global constants\n",
    "coord_ts = [10851, 215, -5.45] # Tensor corner\n",
    "rng_res_ts = 59.9585/2         # Range resolution\n",
    "az_step_ts = 0.4               # Azimuth step size\n",
    "el_step_ts = 0.01              # Elevation step size\n",
    "\n",
    "\n",
    "def Drawing_Batch(names, label, bs, ind, normalize = True):\n",
    "    x = []\n",
    "    labels = []\n",
    "    \n",
    "    for j in range(ind*bs, (ind+1)*bs):\n",
    "        try: temp = sio.loadmat(f'num{scenario_idx}_NAMF_DATA_20_rng30_pulse1_1000_100k/'+names[j])['P']\n",
    "        except: break\n",
    "        if normalize:\n",
    "            Anorm = temp - np.min(temp.flatten())\n",
    "            temp = np.divide(Anorm, np.max(Anorm.flatten()))\n",
    "        x.append(temp)\n",
    "        labels.append(label[j,:])\n",
    "        \n",
    "    x = torch.FloatTensor(np.array(x))\n",
    "    labels = torch.FloatTensor(np.array(labels))\n",
    "    return x,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90000\n",
      "9999\n"
     ]
    }
   ],
   "source": [
    "print(len(y_train))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a regression CNN and instantiating it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1               [-1, 32, 24]           2,048\n",
      "       BatchNorm1d-2               [-1, 32, 24]              64\n",
      "            Conv1d-3               [-1, 64, 10]           6,208\n",
      "       BatchNorm1d-4               [-1, 64, 10]             128\n",
      "            Linear-5                   [-1, 20]           6,420\n",
      "            Linear-6                    [-1, 2]              42\n",
      "               Net-7                    [-1, 2]               0\n",
      "================================================================\n",
      "Total params: 14,910\n",
      "Trainable params: 14,910\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.02\n",
      "Params size (MB): 0.06\n",
      "Estimated Total Size (MB): 0.08\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(21, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv1d(32, 64, 3, 1)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(32)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(64)\n",
    "        self.fc1 = nn.Linear(64 * 5, 20)  # Adjust input size based on the output of conv layers and max pooling\n",
    "        self.fc2_reg = nn.Linear(20, 2)  # Adjusted output size\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(self.batchnorm1(x))\n",
    "        x = F.max_pool1d(x, 2)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(self.batchnorm2(x))\n",
    "        x = F.max_pool1d(x, 2)\n",
    "        \n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        output_reg = self.fc2_reg(x)  # (bs, 2)\n",
    "        \n",
    "        return output_reg\n",
    "    \n",
    "from torchsummary import summary\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "model = Net()\n",
    "model = model.to(device)\n",
    "if device == 'cuda:0':\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    cudnn.benchmark = True\n",
    "print(summary(model,(21,26)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring Inference Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy_input = torch.randn(1,5,26,dtype=torch.float).to(device)\n",
    "# starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
    "# repetitions = 10000\n",
    "# timings=np.zeros((repetitions,1))\n",
    "# #GPU-WARM-UP\n",
    "# for _ in range(10):\n",
    "#    _ = model(dummy_input)\n",
    "# # MEASURE PERFORMANCE\n",
    "# with torch.no_grad():\n",
    "#     for rep in range(repetitions):\n",
    "#         starter.record()\n",
    "#         _ = model(dummy_input)\n",
    "#         ender.record()\n",
    "#         # WAIT FOR GPU SYNC\n",
    "#         torch.cuda.synchronize()\n",
    "#         curr_time = starter.elapsed_time(ender)\n",
    "#         timings[rep] = curr_time\n",
    "# mean_syn = np.sum(timings) / repetitions\n",
    "# std_syn = np.std(timings)\n",
    "# print(mean_syn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 128  # batch_size\n",
    "num_epoch = 50  # number of epochs\n",
    "PATH = './ckpt_model.pth'   # forsaving the model\n",
    "criterion = nn.MSELoss()\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Define a Loss function and optimizer; Using GPU or CPU\n",
    "model = Net()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "model = model.to(device)\n",
    "if device == 'cuda:0':\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    cudnn.benchmark = True\n",
    "    \n",
    "def Spher2Cart_1D(spherical):\n",
    "    cartesian = np.zeros(3)\n",
    "    hypotenuse = np.cos(np.radians(spherical[2]))*spherical[0]\n",
    "    cartesian[0] = np.cos(np.radians(spherical[1]))*hypotenuse\n",
    "    cartesian[1] = -np.sin(np.radians(spherical[1]))*hypotenuse\n",
    "    cartesian[2] = np.sin(np.radians(spherical[2]))*spherical[0]\n",
    "    return cartesian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evaluate the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/50\n",
      "----------\n",
      "[-7751.39291536  7690.05343776 -1018.01716678]\n",
      "[-7819.40048854  7635.01211478 -1018.93647734]\n",
      "[-8045.58658391  7667.8158024  -1020.81920307]\n",
      "[-8106.9641795   7597.01112818 -1020.44967021]\n",
      "Train Loss: 8.953535 ---- Test Loss: 0.596890\n",
      "Epoch 1/50\n",
      "----------\n",
      "[-7751.39291536  7690.05343776 -1018.01716678]\n",
      "[-7793.95821351  7659.72997086 -1018.85463365]\n",
      "[-8045.58658391  7667.8158024  -1020.81920307]\n",
      "[-8095.16396661  7588.56078964 -1019.12812246]\n",
      "Train Loss: 0.307652 ---- Test Loss: 0.520247\n",
      "Epoch 2/50\n",
      "----------\n",
      "[-7751.39291536  7690.05343776 -1018.01716678]\n",
      "[-7784.77475367  7663.44612445 -1018.4871698 ]\n",
      "[-8045.58658391  7667.8158024  -1020.81920307]\n",
      "[-8074.10427483  7610.6317611  -1019.10718449]\n",
      "Train Loss: 0.212777 ---- Test Loss: 0.297095\n",
      "Epoch 3/50\n",
      "----------\n",
      "[-7751.39291536  7690.05343776 -1018.01716678]\n",
      "[-7779.03957787  7668.71356979 -1018.45089598]\n",
      "[-8045.58658391  7667.8158024  -1020.81920307]\n",
      "[-8058.33812524  7632.9729978  -1019.46395636]\n",
      "Train Loss: 0.174324 ---- Test Loss: 0.197149\n",
      "Epoch 4/50\n",
      "----------\n",
      "[-7751.39291536  7690.05343776 -1018.01716678]\n",
      "[-7771.83252595  7676.43734628 -1018.47840723]\n",
      "[-8045.58658391  7667.8158024  -1020.81920307]\n",
      "[-8065.85470178  7625.09601833 -1019.46814029]\n",
      "Train Loss: 0.154269 ---- Test Loss: 0.240957\n",
      "Epoch 5/50\n",
      "----------\n",
      "[-7751.39291536  7690.05343776 -1018.01716678]\n",
      "[-7764.05187283  7686.90070184 -1018.64855074]\n",
      "[-8045.58658391  7667.8158024  -1020.81920307]\n",
      "[-8057.45545045  7635.92128062 -1019.59134929]\n",
      "Train Loss: 0.140840 ---- Test Loss: 0.177990\n",
      "Epoch 6/50\n",
      "----------\n",
      "[-7751.39291536  7690.05343776 -1018.01716678]\n",
      "[-7760.21545635  7692.40362013 -1018.75552891]\n",
      "[-8045.58658391  7667.8158024  -1020.81920307]\n",
      "[-8054.05110432  7644.97524807 -1019.93674086]\n",
      "Train Loss: 0.133408 ---- Test Loss: 0.154253\n",
      "Epoch 7/50\n",
      "----------\n",
      "[-7751.39291536  7690.05343776 -1018.01716678]\n",
      "[-7761.14347708  7691.00182081 -1018.72498003]\n",
      "[-8045.58658391  7667.8158024  -1020.81920307]\n",
      "[-8043.58982937  7656.05183161 -1019.94121244]\n",
      "Train Loss: 0.131039 ---- Test Loss: 0.146455\n",
      "Epoch 8/50\n",
      "----------\n",
      "[-7751.39291536  7690.05343776 -1018.01716678]\n",
      "[-7766.49565429  7684.78401023 -1018.67166014]\n",
      "[-8045.58658391  7667.8158024  -1020.81920307]\n",
      "[-8050.59226628  7644.71359542 -1019.68980248]\n",
      "Train Loss: 0.134575 ---- Test Loss: 0.152578\n",
      "Epoch 9/50\n",
      "----------\n",
      "[-7751.39291536  7690.05343776 -1018.01716678]\n",
      "[-7786.40463994  7656.73011111 -1018.15633807]\n",
      "[-8045.58658391  7667.8158024  -1020.81920307]\n",
      "[-8077.91039409  7611.65971541 -1019.42634541]\n",
      "Train Loss: 0.148435 ---- Test Loss: 0.347912\n",
      "Epoch 10/50\n",
      "----------\n",
      "[-7751.39291536  7690.05343776 -1018.01716678]\n",
      "[-7827.18216752  7586.04968781 -1016.27337993]\n",
      "[-8045.58658391  7667.8158024  -1020.81920307]\n",
      "[-8125.03521386  7534.7045208  -1017.76153729]\n",
      "Train Loss: 0.189752 ---- Test Loss: 1.595370\n",
      "Epoch 11/50\n",
      "----------\n",
      "[-7751.39291536  7690.05343776 -1018.01716678]\n",
      "[-7796.10690356  7605.64990497 -1015.47015184]\n",
      "[-8045.58658391  7667.8158024  -1020.81920307]\n",
      "[-8111.6232823   7528.02346628 -1016.44110874]\n",
      "Train Loss: 0.215247 ---- Test Loss: 1.732750\n",
      "Epoch 12/50\n",
      "----------\n",
      "[-7751.39291536  7690.05343776 -1018.01716678]\n",
      "[-7781.82359789  7627.20698623 -1015.92319836]\n",
      "[-8045.58658391  7667.8158024  -1020.81920307]\n",
      "[-8084.71556681  7569.28477371 -1017.21735134]\n",
      "Train Loss: 0.177133 ---- Test Loss: 0.895241\n",
      "Epoch 13/50\n",
      "----------\n",
      "[-7751.39291536  7690.05343776 -1018.01716678]\n",
      "[-7783.06354712  7625.31155146 -1015.88208144]\n",
      "[-8045.58658391  7667.8158024  -1020.81920307]\n",
      "[-8082.71123802  7575.35215845 -1017.46397593]\n",
      "Train Loss: 0.145914 ---- Test Loss: 0.859134\n",
      "Epoch 14/50\n",
      "----------\n",
      "[-7751.39291536  7690.05343776 -1018.01716678]\n",
      "[-7789.25655305  7618.37356408 -1015.84220134]\n",
      "[-8045.58658391  7667.8158024  -1020.81920307]\n",
      "[-8085.68700218  7581.28660998 -1018.036155  ]\n",
      "Train Loss: 0.136343 ---- Test Loss: 0.836884\n",
      "Epoch 15/50\n",
      "----------\n",
      "[-7751.39291536  7690.05343776 -1018.01716678]\n",
      "[-7791.09821805  7615.64465095 -1015.78709789]\n",
      "[-8045.58658391  7667.8158024  -1020.81920307]\n",
      "[-8082.64607632  7582.12294211 -1017.8849764 ]\n",
      "Train Loss: 0.138383 ---- Test Loss: 0.855976\n",
      "Epoch 16/50\n",
      "----------\n",
      "[-7751.39291536  7690.05343776 -1018.01716678]\n",
      "[-7787.23556287  7618.6261446  -1015.72397104]\n",
      "[-8045.58658391  7667.8158024  -1020.81920307]\n",
      "[-8084.03655712  7578.41328875 -1017.74506566]\n",
      "Train Loss: 0.142465 ---- Test Loss: 0.932421\n",
      "Epoch 17/50\n",
      "----------\n",
      "[-7751.39291536  7690.05343776 -1018.01716678]\n",
      "[-7780.77449525  7625.80618138 -1015.76192425]\n",
      "[-8045.58658391  7667.8158024  -1020.81920307]\n",
      "[-8082.70337167  7578.92252919 -1017.68772747]\n",
      "Train Loss: 0.141521 ---- Test Loss: 0.897145\n",
      "Epoch 18/50\n",
      "----------\n",
      "[-7751.39291536  7690.05343776 -1018.01716678]\n",
      "[-7777.68705944  7629.67128602 -1015.80868449]\n",
      "[-8045.58658391  7667.8158024  -1020.81920307]\n",
      "[-8074.54288589  7587.64239098 -1017.68938274]\n",
      "Train Loss: 0.136323 ---- Test Loss: 0.745937\n",
      "Epoch 19/50\n",
      "----------\n",
      "[-7751.39291536  7690.05343776 -1018.01716678]\n",
      "[-7776.90751632  7630.98973484 -1015.84289208]\n",
      "[-8045.58658391  7667.8158024  -1020.81920307]\n",
      "[-8071.70977467  7594.32606641 -1017.92032803]\n",
      "Train Loss: 0.131017 ---- Test Loss: 0.657334\n",
      "Epoch 20/50\n",
      "----------\n",
      "[-7751.39291536  7690.05343776 -1018.01716678]\n",
      "[-7776.39551737  7631.94253552 -1015.87104164]\n",
      "[-8045.58658391  7667.8158024  -1020.81920307]\n",
      "[-8068.09863374  7598.77970987 -1017.959202  ]\n",
      "Train Loss: 0.127244 ---- Test Loss: 0.574003\n",
      "Epoch 21/50\n",
      "----------\n",
      "[-7751.39291536  7690.05343776 -1018.01716678]\n",
      "[-7775.37956359  7633.61105709 -1015.912418  ]\n",
      "[-8045.58658391  7667.8158024  -1020.81920307]\n",
      "[-8063.08621696  7601.37480979 -1017.78760058]\n",
      "Train Loss: 0.125042 ---- Test Loss: 0.591034\n",
      "Epoch 22/50\n",
      "----------\n",
      "[-7751.39291536  7690.05343776 -1018.01716678]\n",
      "[-7774.1796972   7635.16872575 -1015.93434964]\n",
      "[-8045.58658391  7667.8158024  -1020.81920307]\n",
      "[-8063.1063131   7603.25638791 -1017.90749904]\n",
      "Train Loss: 0.122790 ---- Test Loss: 0.578241\n",
      "Epoch 23/50\n",
      "----------\n",
      "[-7751.39291536  7690.05343776 -1018.01716678]\n",
      "[-7772.54249637  7637.50553327 -1015.97814124]\n",
      "[-8045.58658391  7667.8158024  -1020.81920307]\n",
      "[-8057.92415108  7609.78287715 -1017.97274487]\n",
      "Train Loss: 0.119703 ---- Test Loss: 0.505223\n",
      "Epoch 24/50\n",
      "----------\n",
      "[-7751.39291536  7690.05343776 -1018.01716678]\n",
      "[-7772.61384687  7637.7845718  -1016.00112059]\n",
      "[-8045.58658391  7667.8158024  -1020.81920307]\n",
      "[-8058.14026178  7606.89772611 -1017.80525155]\n",
      "Train Loss: 0.116219 ---- Test Loss: 0.543142\n",
      "Epoch 25/50\n",
      "----------\n",
      "[-7751.39291536  7690.05343776 -1018.01716678]\n",
      "[-7772.57889469  7638.44906253 -1016.04222026]\n",
      "[-8045.58658391  7667.8158024  -1020.81920307]\n",
      "[-8056.46416399  7611.7431991  -1017.99889969]\n",
      "Train Loss: 0.113282 ---- Test Loss: 0.495706\n",
      "Epoch 26/50\n",
      "----------\n",
      "[-7751.39291536  7690.05343776 -1018.01716678]\n",
      "[-7773.0407957   7638.36870632 -1016.06768519]\n",
      "[-8045.58658391  7667.8158024  -1020.81920307]\n",
      "[-8058.25243119  7610.23418985 -1018.02312728]\n",
      "Train Loss: 0.110964 ---- Test Loss: 0.511814\n",
      "Epoch 27/50\n",
      "----------\n",
      "[-7751.39291536  7690.05343776 -1018.01716678]\n",
      "[-7773.25247163  7638.26726037 -1016.07513264]\n",
      "[-8045.58658391  7667.8158024  -1020.81920307]\n",
      "[-8051.8689549   7621.68878613 -1018.31989892]\n",
      "Train Loss: 0.108765 ---- Test Loss: 0.399973\n",
      "Epoch 28/50\n",
      "----------\n",
      "[-7751.39291536  7690.05343776 -1018.01716678]\n",
      "[-7772.43808157  7639.24620495 -1016.08495221]\n",
      "[-8045.58658391  7667.8158024  -1020.81920307]\n",
      "[-8053.94336979  7619.55659418 -1018.32368015]\n",
      "Train Loss: 0.106909 ---- Test Loss: 0.426267\n",
      "Epoch 29/50\n",
      "----------\n",
      "[-7751.39291536  7690.05343776 -1018.01716678]\n",
      "[-7772.12140414  7639.49064394 -1016.0798709 ]\n",
      "[-8045.58658391  7667.8158024  -1020.81920307]\n",
      "[-8057.34312591  7617.54450626 -1018.42356634]\n",
      "Train Loss: 0.105115 ---- Test Loss: 0.429917\n",
      "Epoch 30/50\n",
      "----------\n",
      "[-7751.39291536  7690.05343776 -1018.01716678]\n",
      "[-7772.2920199   7640.18559967 -1016.1366365 ]\n",
      "[-8045.58658391  7667.8158024  -1020.81920307]\n",
      "[-8057.58413086  7619.32754382 -1018.55216477]\n",
      "Train Loss: 0.103195 ---- Test Loss: 0.420115\n",
      "Epoch 31/50\n",
      "----------\n",
      "[-7751.39291536  7690.05343776 -1018.01716678]\n",
      "[-7772.66201094  7640.06455615 -1016.15332625]\n",
      "[-8045.58658391  7667.8158024  -1020.81920307]\n",
      "[-8055.29083103  7624.25044672 -1018.70989384]\n",
      "Train Loss: 0.100774 ---- Test Loss: 0.365477\n",
      "Epoch 32/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-7751.39291536  7690.05343776 -1018.01716678]\n",
      "[-7773.54805785  7639.62370481 -1016.1834319 ]\n",
      "[-8045.58658391  7667.8158024  -1020.81920307]\n",
      "[-8055.84727424  7625.16453844 -1018.80472531]\n",
      "Train Loss: 0.099075 ---- Test Loss: 0.362227\n",
      "Epoch 33/50\n",
      "----------\n",
      "[-7751.39291536  7690.05343776 -1018.01716678]\n",
      "[-7773.55135395  7639.94805212 -1016.20484797]\n",
      "[-8045.58658391  7667.8158024  -1020.81920307]\n",
      "[-8057.50298026  7622.63855467 -1018.75571837]\n",
      "Train Loss: 0.097775 ---- Test Loss: 0.374753\n",
      "Epoch 34/50\n",
      "----------\n",
      "[-7751.39291536  7690.05343776 -1018.01716678]\n",
      "[-7773.70629451  7640.26943903 -1016.23615461]\n",
      "[-8045.58658391  7667.8158024  -1020.81920307]\n",
      "[-8056.23452938  7622.54612761 -1018.66525388]\n",
      "Train Loss: 0.096397 ---- Test Loss: 0.389741\n",
      "Epoch 35/50\n",
      "----------\n",
      "[-7751.39291536  7690.05343776 -1018.01716678]\n",
      "[-7774.00800378  7640.74567179 -1016.28734059]\n",
      "[-8045.58658391  7667.8158024  -1020.81920307]\n",
      "[-8056.94636759  7622.46431185 -1018.70758222]\n",
      "Train Loss: 0.095052 ---- Test Loss: 0.368131\n",
      "Epoch 36/50\n",
      "----------\n",
      "[-7751.39291536  7690.05343776 -1018.01716678]\n",
      "[-7774.7072402   7640.4206092  -1016.31259385]\n",
      "[-8045.58658391  7667.8158024  -1020.81920307]\n",
      "[-8056.32939273  7625.46081615 -1018.85559148]\n",
      "Train Loss: 0.093667 ---- Test Loss: 0.347979\n",
      "Epoch 37/50\n",
      "----------\n",
      "[-7751.39291536  7690.05343776 -1018.01716678]\n",
      "[-7775.89931241  7639.74051611 -1016.34742848]\n",
      "[-8045.58658391  7667.8158024  -1020.81920307]\n",
      "[-8055.38099408  7625.03698528 -1018.76556892]\n",
      "Train Loss: 0.092644 ---- Test Loss: 0.350933\n",
      "Epoch 38/50\n",
      "----------\n",
      "[-7751.39291536  7690.05343776 -1018.01716678]\n",
      "[-7776.35450658  7640.10613568 -1016.40159237]\n",
      "[-8045.58658391  7667.8158024  -1020.81920307]\n",
      "[-8055.21416523  7626.24175595 -1018.83051403]\n",
      "Train Loss: 0.091155 ---- Test Loss: 0.367716\n",
      "Epoch 39/50\n",
      "----------\n",
      "[-7751.39291536  7690.05343776 -1018.01716678]\n",
      "[-7776.72903186  7640.16497354 -1016.43034575]\n",
      "[-8045.58658391  7667.8158024  -1020.81920307]\n",
      "[-8052.78409085  7628.39367995 -1018.80436183]\n",
      "Train Loss: 0.089541 ---- Test Loss: 0.356667\n",
      "Epoch 40/50\n",
      "----------\n",
      "[-7751.39291536  7690.05343776 -1018.01716678]\n",
      "[-7777.12008597  7639.94882307 -1016.44223155]\n",
      "[-8045.58658391  7667.8158024  -1020.81920307]\n",
      "[-8054.18976622  7627.62655105 -1018.84964507]\n",
      "Train Loss: 0.088378 ---- Test Loss: 0.341739\n",
      "Epoch 41/50\n",
      "----------\n",
      "[-7751.39291536  7690.05343776 -1018.01716678]\n",
      "[-7778.59699995  7639.1987678  -1016.49146609]\n",
      "[-8045.58658391  7667.8158024  -1020.81920307]\n",
      "[-8054.82651036  7625.05490768 -1018.72971523]\n",
      "Train Loss: 0.086877 ---- Test Loss: 0.363375\n",
      "Epoch 42/50\n",
      "----------\n",
      "[-7751.39291536  7690.05343776 -1018.01716678]\n",
      "[-7778.59256094  7639.55253666 -1016.51428221]\n",
      "[-8045.58658391  7667.8158024  -1020.81920307]\n",
      "[-8056.08071651  7624.04897862 -1018.7498661 ]\n",
      "Train Loss: 0.085664 ---- Test Loss: 0.348101\n",
      "Epoch 43/50\n",
      "----------\n",
      "[-7751.39291536  7690.05343776 -1018.01716678]\n",
      "[-7779.22879978  7638.89136818 -1016.51341365]\n",
      "[-8045.58658391  7667.8158024  -1020.81920307]\n",
      "[-8054.55456437  7625.43911674 -1018.73583684]\n",
      "Train Loss: 0.084292 ---- Test Loss: 0.316130\n",
      "Epoch 44/50\n",
      "----------\n",
      "[-7751.39291536  7690.05343776 -1018.01716678]\n",
      "[-7779.49118034  7639.229796   -1016.55297592]\n",
      "[-8045.58658391  7667.8158024  -1020.81920307]\n",
      "[-8058.04514337  7622.28674381 -1018.76968748]\n",
      "Train Loss: 0.083259 ---- Test Loss: 0.354719\n",
      "Epoch 45/50\n",
      "----------\n",
      "[-7751.39291536  7690.05343776 -1018.01716678]\n",
      "[-7779.16787878  7639.46354378 -1016.54673874]\n",
      "[-8045.58658391  7667.8158024  -1020.81920307]\n",
      "[-8056.06938871  7624.66724109 -1018.78814386]\n",
      "Train Loss: 0.082268 ---- Test Loss: 0.336039\n",
      "Epoch 46/50\n",
      "----------\n",
      "[-7751.39291536  7690.05343776 -1018.01716678]\n",
      "[-7780.00582423  7639.12185994 -1016.58016204]\n",
      "[-8045.58658391  7667.8158024  -1020.81920307]\n",
      "[-8057.99529302  7622.43212261 -1018.77553714]\n",
      "Train Loss: 0.081334 ---- Test Loss: 0.339247\n",
      "Epoch 47/50\n",
      "----------\n",
      "[-7751.39291536  7690.05343776 -1018.01716678]\n",
      "[-7779.96967939  7638.65867662 -1016.5475018 ]\n",
      "[-8045.58658391  7667.8158024  -1020.81920307]\n",
      "[-8054.11230195  7630.41683977 -1019.02072089]\n",
      "Train Loss: 0.080812 ---- Test Loss: 0.286238\n",
      "Epoch 48/50\n",
      "----------\n",
      "[-7751.39291536  7690.05343776 -1018.01716678]\n",
      "[-7780.18642937  7638.90913165 -1016.5782816 ]\n",
      "[-8045.58658391  7667.8158024  -1020.81920307]\n",
      "[-8057.70756789  7625.01402807 -1018.91932064]\n",
      "Train Loss: 0.079967 ---- Test Loss: 0.322586\n",
      "Epoch 49/50\n",
      "----------\n",
      "[-7751.39291536  7690.05343776 -1018.01716678]\n",
      "[-7780.27452894  7639.55011492 -1016.62601258]\n",
      "[-8045.58658391  7667.8158024  -1020.81920307]\n",
      "[-8056.6287769   7626.60417886 -1018.94775308]\n",
      "Train Loss: 0.079212 ---- Test Loss: 0.309061\n",
      "4259.6605768203735\n"
     ]
    }
   ],
   "source": [
    "def main(training_names, test_names, bs, num_epoch, y_train, y_test, normalize=True):\n",
    "    best_error = 1e+20      # a dummy and very large number for saving the best discovered model\n",
    "    for epoch in range(num_epoch):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epoch))\n",
    "        print('-'*10)\n",
    "        running_loss_train = 0\n",
    "        running_loss_test = 0\n",
    "\n",
    "        model.train()\n",
    "        for i in range(0, len(training_names)//bs):\n",
    "            x_train, labels = Drawing_Batch(training_names, y_train, bs, i, normalize)\n",
    "            x_train = x_train.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(x_train)\n",
    "            loss = criterion(out, labels[:,0:2])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss_train += loss.item()\n",
    "            \n",
    "        out = torch.cat((out, torch.unsqueeze(labels[:,2], dim=1)), dim=1)\n",
    "        \n",
    "        true_train = Spher2Cart_1D(np.multiply(labels.cpu().data.numpy()[1,], [rng_res_tr,az_step_tr,el_step_tr]) + coord_tr)\n",
    "        pred_train = Spher2Cart_1D(np.multiply(out.cpu().data.numpy()[1,], [rng_res_tr,az_step_tr,el_step_tr]) + coord_tr)\n",
    "        print(true_train)\n",
    "        print(pred_train)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, len(test_names)//bs):\n",
    "                x_test, labels_test = Drawing_Batch(test_names, y_test, bs, i, normalize)\n",
    "                x_test = x_test.to(device)\n",
    "                labels_test = labels_test.to(device)\n",
    "                out_test = model(x_test)\n",
    "                loss_test = criterion(out_test, labels_test[:,0:2])\n",
    "                running_loss_test += loss_test.item()\n",
    "\n",
    "        out_test = torch.cat((out_test, torch.unsqueeze(labels_test[:,2], dim=1)), dim=1)\n",
    "        \n",
    "        true_test = Spher2Cart_1D(np.multiply(labels_test.cpu().data.numpy()[1,], [rng_res_ts,az_step_ts,el_step_ts]) + coord_ts)\n",
    "        pred_test = Spher2Cart_1D(np.multiply(out_test.cpu().data.numpy()[1,], [rng_res_ts,az_step_ts,el_step_ts]) + coord_ts)\n",
    "        print(true_test)\n",
    "        print(pred_test)\n",
    "        \n",
    "        epoch_loss_train = running_loss_train*x_train.size()[0]/len(training_names)\n",
    "        epoch_loss_test = running_loss_test*x_test.size()[0]/len(test_names)\n",
    "\n",
    "        print('Train Loss: {:.6f} ---- Test Loss: {:.6f}'.format(epoch_loss_train, epoch_loss_test))\n",
    "        if epoch%5==0:\n",
    "            if epoch_loss_test < best_error:\n",
    "                torch.save(model.state_dict(), PATH)\n",
    "                best_accuracy = epoch_loss_test\n",
    "\n",
    "start = time.time()\n",
    "main(training_names, test_names, bs, num_epoch, y_train, y_test, normalize=True)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azimuth Estimation Error (deg) = 0.4803797014687694\n",
      "Localization Error (m) = 40.67093223755961\n"
     ]
    }
   ],
   "source": [
    "def Spher2Cart_2D(spherical):\n",
    "    cartesian = np.zeros((len(spherical),3))\n",
    "    hypotenuse = np.multiply(np.cos(np.radians(spherical[:,2])), spherical[:,0])\n",
    "    cartesian[:,0] = np.multiply(np.cos(np.radians(spherical[:,1])), hypotenuse)\n",
    "    cartesian[:,1] = np.multiply(-np.sin(np.radians(spherical[:,1])), hypotenuse)\n",
    "    cartesian[:,2] = np.multiply(np.sin(np.radians(spherical[:,2])), spherical[:,0])\n",
    "    return cartesian\n",
    "\n",
    "# Testing: (range,az,el)\n",
    "model.eval()\n",
    "out_test_reg = np.zeros((len(y_test),3))\n",
    "labels_test_reg = np.zeros((len(y_test),3))\n",
    "\n",
    "for i in range(0, len(y_test)//bs):  \n",
    "    x_test, labels_test = Drawing_Batch(test_names, y_test, bs, i, True)\n",
    "    labels_test = labels_test.cpu().data.numpy()\n",
    "    labels_test_reg[bs*i : bs*i + bs] = (labels_test[:,0:3])\n",
    "\n",
    "    cur_test_reg = model(x_test)\n",
    "    out_test_reg[bs*i : bs*i + bs, 0:2] = cur_test_reg.cpu().data.numpy()\n",
    "    out_test_reg[bs*i : bs*i + bs, 2] = labels_test_reg[bs*i : bs*i + bs, 2]\n",
    "    \n",
    "azim_tot = 0\n",
    "for i in np.arange(0,len(out_test_reg),1):\n",
    "    azim_tot += np.linalg.norm(out_test_reg[i,1] - labels_test_reg[i,1])\n",
    "    \n",
    "azim_tot = azim_tot / len(out_test_reg)\n",
    "print(f'Azimuth Estimation Error (deg) = {azim_tot}')\n",
    "\n",
    "new_data = Spher2Cart_2D(np.multiply(out_test_reg, [rng_res_ts,az_step_ts,el_step_ts]) + coord_ts)\n",
    "new_labels_data = Spher2Cart_2D(np.multiply(labels_test_reg, [rng_res_ts,az_step_ts,el_step_ts]) + coord_ts)\n",
    "\n",
    "sum_tot = 0\n",
    "for i in np.arange(0,len(new_data) - (len(new_data) % bs),1):\n",
    "    sum_tot += np.linalg.norm(new_data[i,:] - new_labels_data[i,:])\n",
    "    \n",
    "# def reject_outliers(data, m=2):\n",
    "#     return data[abs(data - np.mean(data)) < m * np.std(data)]\n",
    "# \n",
    "# azims = (np.multiply(out_test_reg, [rng_res_ts,az_step_ts,el_step_ts]) - np.multiply(labels_test_reg, [rng_res_ts,az_step_ts,el_step_ts]))[:,1]\n",
    "# azims = reject_outliers(azims)\n",
    "# mse = np.mean(azims**2)\n",
    "# bias_sq = np.mean(azims)**2\n",
    "# var = np.var(azims)\n",
    "# print(mse, bias_sq, var)\n",
    "\n",
    "sum_tot = sum_tot / (len(new_data) - (len(new_data) % bs))\n",
    "print(f'Localization Error (m) = {sum_tot}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
