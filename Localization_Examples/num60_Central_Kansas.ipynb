{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Regression Network on Radar Dataset (Central Kansas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "import scipy.io as sio\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import itertools\n",
    "import time\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import KFold\n",
    "from itertools import product\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the labels and creating train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n",
      "Training labels: \n",
      "[[ 5.9595  16.043   18.872  ]\n",
      " [16.369   20.125   29.519  ]\n",
      " [ 5.4378  17.074   17.305  ]\n",
      " ...\n",
      " [ 0.38467 14.803    7.8498 ]\n",
      " [13.44    21.64    27.856  ]\n",
      " [17.917   21.429   32.766  ]]\n"
     ]
    }
   ],
   "source": [
    "def index(string):\n",
    "    s = re.findall(\"[0-9]\", string)\n",
    "    return int(''.join(s))\n",
    "\n",
    "scenario_idx = 60 # Central Kansas\n",
    "names = os.listdir(f'data/EXAMPLES/num{scenario_idx}_NAMF_DATA_25k/')\n",
    "names = sorted(names, key = index)\n",
    "print(len(names))\n",
    "y = pd.read_csv(f'data/EXAMPLES/num{scenario_idx}_Ground_Truth_25k.csv')\n",
    "col_names = y.columns[4:7]\n",
    "y = y[col_names].to_numpy()\n",
    "\n",
    "y_train = y[:int(0.8*len(names))]\n",
    "y_test = y[(int(0.8*len(names))+1):]\n",
    "training_names = names[:int(0.8*len(names))]\n",
    "test_names = names[(int(0.8*len(names))+1):]\n",
    "\n",
    "print('Training labels: ')\n",
    "print(y_train)\n",
    "\n",
    "# Tensor Corners\n",
    "##################################################################################\n",
    "# num29: [10851, 215, -5.45], num60: [11073, 215, -5.3], num62: [11471, 215, -5.6]\n",
    "# num76: [11388, 215, -6.15], num35: [11381, 215, -0.95]\n",
    "##################################################################################\n",
    "\n",
    "# Training dataset global constants\n",
    "coord_tr = [11073, 215, -5.3] # Tensor corner\n",
    "rng_res_tr = 59.9585/2        # Range resolution\n",
    "az_step_tr = 0.4              # Azimuth step size\n",
    "el_step_tr = 0.01             # Elevation step size\n",
    "\n",
    "# Test dataset global constants\n",
    "coord_ts = [11073, 215, -5.3] # Tensor corner\n",
    "rng_res_ts = 59.9585/2        # Range resolution\n",
    "az_step_ts = 0.4              # Azimuth step size\n",
    "el_step_ts = 0.01             # Elevation step size\n",
    "\n",
    "\n",
    "def Drawing_Batch(names, label, bs, ind, normalize = True):\n",
    "    x = []\n",
    "    labels = []\n",
    "    \n",
    "    for j in range(ind*bs, (ind+1)*bs):\n",
    "        try: temp = sio.loadmat(f'data/EXAMPLES/num{scenario_idx}_NAMF_DATA_25k/'+names[j])['P']\n",
    "        except: break\n",
    "        if normalize:\n",
    "            Anorm = temp - np.min(temp.flatten())\n",
    "            temp = np.divide(Anorm, np.max(Anorm.flatten()))\n",
    "        x.append(temp)\n",
    "        labels.append(label[j,:])\n",
    "        \n",
    "    x = torch.FloatTensor(np.array(x))\n",
    "    labels = torch.FloatTensor(np.array(labels))\n",
    "    return x,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n",
      "4999\n"
     ]
    }
   ],
   "source": [
    "print(len(y_train))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Regression CNN and instantiating it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Net(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Net, self).__init__()\n",
    "#         self.conv1 = nn.Conv1d(21, 32, 3, 1) # 5, 32, 3, 1\n",
    "#         self.conv2 = nn.Conv1d(32, 64, 3, 1)\n",
    "#         self.batchnorm1 = nn.BatchNorm1d(32)\n",
    "#         self.batchnorm2 = nn.BatchNorm1d(64)\n",
    "#         self.fc1 = nn.Linear(64 * 5, 20)  # Adjust input size based on the output of conv layers and max pooling\n",
    "#         self.fc2_reg = nn.Linear(20, 2)  # Adjusted output size\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.conv1(x)\n",
    "#         x = F.relu(self.batchnorm1(x))\n",
    "#         x = F.max_pool1d(x, 2)\n",
    "        \n",
    "#         x = self.conv2(x)\n",
    "#         x = F.relu(self.batchnorm2(x))\n",
    "#         x = F.max_pool1d(x, 2)\n",
    "        \n",
    "#         x = torch.flatten(x, 1)\n",
    "#         x = self.fc1(x)\n",
    "#         x = F.relu(x)\n",
    "#         output_reg = self.fc2_reg(x)  # (bs, 2)\n",
    "        \n",
    "#         return output_reg\n",
    "    \n",
    "# from torchsummary import summary\n",
    "# device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "# model = Net()\n",
    "# model = model.to(device)\n",
    "# if device == 'cuda:0':\n",
    "#     model = torch.nn.DataParallel(model)\n",
    "#     cudnn.benchmark = True\n",
    "# print(summary(model,(21,26)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a CART (Convolutional Adaptive Radar Transformer) and instantiating it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int = 21,\n",
    "        seq_len: int = 26,\n",
    "        conv_channels: list = [32, 64],\n",
    "        kernel_size: int = 3,\n",
    "        pool_size: int = 2,\n",
    "        d_model: int = 64,\n",
    "        nhead: int = 4,\n",
    "        num_layers: int = 2,\n",
    "        dim_feedforward: int = 128,\n",
    "        dropout: float = 0.1,\n",
    "        num_outputs: int = 2\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # --- Local feature extractor (1D CNN) ---\n",
    "        self.conv1 = nn.Conv1d(in_channels, conv_channels[0], kernel_size, padding=kernel_size//2)\n",
    "        self.bn1 = nn.BatchNorm1d(conv_channels[0])\n",
    "        self.conv2 = nn.Conv1d(conv_channels[0], conv_channels[1], kernel_size, padding=kernel_size//2)\n",
    "        self.bn2 = nn.BatchNorm1d(conv_channels[1])\n",
    "        self.pool = nn.MaxPool1d(pool_size)\n",
    "\n",
    "        # compute reduced length after two poolings\n",
    "        reduced_len = seq_len // (pool_size**2)\n",
    "\n",
    "        # --- Token projection to transformer dimension ---\n",
    "        self.token_proj = nn.Linear(conv_channels[1], d_model)\n",
    "\n",
    "        # CLS token & positional embeddings\n",
    "        self.cls_token = nn.Parameter(torch.zeros(1, 1, d_model))\n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, reduced_len + 1, d_model))\n",
    "\n",
    "        # Transformer encoder\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        # Head\n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.LayerNorm(d_model),\n",
    "            nn.Linear(d_model, d_model // 2),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(d_model // 2, num_outputs)\n",
    "        )\n",
    "\n",
    "        # Initialize\n",
    "        nn.init.trunc_normal_(self.pos_embed, std=0.02)\n",
    "        nn.init.trunc_normal_(self.cls_token, std=0.02)\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            if m.bias is not None:\n",
    "                nn.init.zeros_(m.bias)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            nn.init.ones_(m.weight)\n",
    "            nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        # x: (batch, channels=in_channels, length=seq_len)\n",
    "        # 1) CNN blocks\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool(x)\n",
    "        # x: (batch, conv_channels[1], reduced_len)\n",
    "\n",
    "        # 2) prepare transformer tokens\n",
    "        x = x.permute(0, 2, 1)  # -> (batch, seq', channels)\n",
    "        x = self.token_proj(x)  # -> (batch, seq', d_model)\n",
    "\n",
    "        # prepend CLS token\n",
    "        bs = x.size(0)\n",
    "        cls_tokens = self.cls_token.expand(bs, -1, -1)\n",
    "        x = torch.cat([cls_tokens, x], dim=1)  # (batch, seq'+1, d_model)\n",
    "\n",
    "        # add positional embeddings\n",
    "        x = x + self.pos_embed\n",
    "\n",
    "        # 3) Transformer\n",
    "        x = self.transformer(x)\n",
    "\n",
    "        # 4) classification head on CLS\n",
    "        cls_rep = x[:, 0]\n",
    "        out = self.mlp_head(cls_rep)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 128  # batch_size\n",
    "num_epoch = 50  # number of epochs\n",
    "PATH = './ckpt_model.pth'   # forsaving the model\n",
    "criterion = nn.L1Loss()\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Define a Loss function and optimizer; Using GPU or CPU\n",
    "model = Net()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "model = model.to(device)\n",
    "if device == 'cuda:0':\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    cudnn.benchmark = True\n",
    "    \n",
    "def Spher2Cart_1D(spherical):\n",
    "    cartesian = np.zeros(3)\n",
    "    hypotenuse = np.cos(np.radians(spherical[2]))*spherical[0]\n",
    "    cartesian[0] = np.cos(np.radians(spherical[1]))*hypotenuse\n",
    "    cartesian[1] = -np.sin(np.radians(spherical[1]))*hypotenuse\n",
    "    cartesian[2] = np.sin(np.radians(spherical[2]))*spherical[0]\n",
    "    return cartesian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evaluate the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/50\n",
      "----------\n",
      "[-8199.14685846  7987.03203798 -1003.58499574]\n",
      "[-8144.53986354  8017.2234131  -1002.01622059]\n",
      "[-8064.28876734  7966.69563188 -1008.68844829]\n",
      "[-8010.14187314  8001.33434469 -1007.44245464]\n",
      "Train Loss: 3.114995 ---- Test Loss: 0.563160\n",
      "Epoch 1/50\n",
      "----------\n",
      "[-8199.14685846  7987.03203798 -1003.58499574]\n",
      "[-8190.4748196   8006.25580613 -1004.21795958]\n",
      "[-8064.28876734  7966.69563188 -1008.68844829]\n",
      "[-8042.89567105  8002.34679482 -1009.57009882]\n",
      "Train Loss: 0.477930 ---- Test Loss: 0.331935\n",
      "Epoch 2/50\n",
      "----------\n",
      "[-8199.14685846  7987.03203798 -1003.58499574]\n",
      "[-8232.19446923  7973.15516578 -1004.81571355]\n",
      "[-8064.28876734  7966.69563188 -1008.68844829]\n",
      "[-8062.08609085  7962.86585298 -1008.30952182]\n",
      "Train Loss: 0.371182 ---- Test Loss: 0.214920\n",
      "Epoch 3/50\n",
      "----------\n",
      "[-8199.14685846  7987.03203798 -1003.58499574]\n",
      "[-8208.06562238  7981.41216904 -1003.80171382]\n",
      "[-8064.28876734  7966.69563188 -1008.68844829]\n",
      "[-8044.45962621  7974.37908859 -1007.91519604]\n",
      "Train Loss: 0.335539 ---- Test Loss: 0.326337\n",
      "Epoch 4/50\n",
      "----------\n",
      "[-8199.14685846  7987.03203798 -1003.58499574]\n",
      "[-8196.01341953  8028.62320579 -1005.93663894]\n",
      "[-8064.28876734  7966.69563188 -1008.68844829]\n",
      "[-8039.02608561  7986.12811596 -1008.30841445]\n",
      "Train Loss: 0.300289 ---- Test Loss: 0.265592\n",
      "Epoch 5/50\n",
      "----------\n",
      "[-8199.14685846  7987.03203798 -1003.58499574]\n",
      "[-8189.88846451  8003.92663636 -1004.0384516 ]\n",
      "[-8064.28876734  7966.69563188 -1008.68844829]\n",
      "[-8049.59413947  7994.99716665 -1009.53174878]\n",
      "Train Loss: 0.280933 ---- Test Loss: 0.335374\n",
      "Epoch 6/50\n",
      "----------\n",
      "[-8199.14685846  7987.03203798 -1003.58499574]\n",
      "[-8201.71753866  8011.42523228 -1005.23975043]\n",
      "[-8064.28876734  7966.69563188 -1008.68844829]\n",
      "[-8044.59477714  7994.61464997 -1009.19217583]\n",
      "Train Loss: 0.274955 ---- Test Loss: 0.307342\n",
      "Epoch 7/50\n",
      "----------\n",
      "[-8199.14685846  7987.03203798 -1003.58499574]\n",
      "[-8184.91202126  8008.17462121 -1003.98688785]\n",
      "[-8064.28876734  7966.69563188 -1008.68844829]\n",
      "[-8054.56729033  7977.40548399 -1008.74362937]\n",
      "Train Loss: 0.249511 ---- Test Loss: 0.255688\n",
      "Epoch 8/50\n",
      "----------\n",
      "[-8199.14685846  7987.03203798 -1003.58499574]\n",
      "[-8213.40511142  7980.89859941 -1004.10602212]\n",
      "[-8064.28876734  7966.69563188 -1008.68844829]\n",
      "[-8056.28681147  7969.6545732  -1008.36718372]\n",
      "Train Loss: 0.230074 ---- Test Loss: 0.174407\n",
      "Epoch 9/50\n",
      "----------\n",
      "[-8199.14685846  7987.03203798 -1003.58499574]\n",
      "[-8211.59982547  7982.11115325 -1004.06660952]\n",
      "[-8064.28876734  7966.69563188 -1008.68844829]\n",
      "[-8052.06560983  7974.10435592 -1008.37876424]\n",
      "Train Loss: 0.215717 ---- Test Loss: 0.199494\n",
      "Epoch 10/50\n",
      "----------\n",
      "[-8199.14685846  7987.03203798 -1003.58499574]\n",
      "[-8209.42382297  7984.83799295 -1004.09649547]\n",
      "[-8064.28876734  7966.69563188 -1008.68844829]\n",
      "[-8056.36630455  7982.71844056 -1009.19007005]\n",
      "Train Loss: 0.205372 ---- Test Loss: 0.187765\n",
      "Epoch 11/50\n",
      "----------\n",
      "[-8199.14685846  7987.03203798 -1003.58499574]\n",
      "[-8208.06059833  7986.58545039 -1004.11765886]\n",
      "[-8064.28876734  7966.69563188 -1008.68844829]\n",
      "[-8057.6469135   7968.38969334 -1008.37408135]\n",
      "Train Loss: 0.203021 ---- Test Loss: 0.182075\n",
      "Epoch 12/50\n",
      "----------\n",
      "[-8199.14685846  7987.03203798 -1003.58499574]\n",
      "[-8194.84413931  7991.24451026 -1003.57262233]\n",
      "[-8064.28876734  7966.69563188 -1008.68844829]\n",
      "[-8053.31650502  7979.06174539 -1008.7682779 ]\n",
      "Train Loss: 0.201294 ---- Test Loss: 0.199917\n",
      "Epoch 13/50\n",
      "----------\n",
      "[-8199.14685846  7987.03203798 -1003.58499574]\n",
      "[-8184.42234187  8010.65485456 -1004.10829702]\n",
      "[-8064.28876734  7966.69563188 -1008.68844829]\n",
      "[-8053.5134715   7974.21434722 -1008.47719618]\n",
      "Train Loss: 0.208081 ---- Test Loss: 0.173488\n",
      "Epoch 14/50\n",
      "----------\n",
      "[-8199.14685846  7987.03203798 -1003.58499574]\n",
      "[-8189.55677165  7992.84950305 -1003.33905844]\n",
      "[-8064.28876734  7966.69563188 -1008.68844829]\n",
      "[-8048.08060053  7984.50752035 -1008.77859394]\n",
      "Train Loss: 0.179787 ---- Test Loss: 0.209855\n",
      "Epoch 15/50\n",
      "----------\n",
      "[-8199.14685846  7987.03203798 -1003.58499574]\n",
      "[-8209.76575116  7983.61579917 -1004.0432761 ]\n",
      "[-8064.28876734  7966.69563188 -1008.68844829]\n",
      "[-8049.34555787  7979.45898023 -1008.5421865 ]\n",
      "Train Loss: 0.180666 ---- Test Loss: 0.214715\n",
      "Epoch 16/50\n",
      "----------\n",
      "[-8199.14685846  7987.03203798 -1003.58499574]\n",
      "[-8196.48433514  7998.06899821 -1004.09337902]\n",
      "[-8064.28876734  7966.69563188 -1008.68844829]\n",
      "[-8057.71375946  7979.77432773 -1009.0908855 ]\n",
      "Train Loss: 0.174653 ---- Test Loss: 0.166024\n",
      "Epoch 17/50\n",
      "----------\n",
      "[-8199.14685846  7987.03203798 -1003.58499574]\n",
      "[-8196.58148387  7986.89790064 -1003.41568364]\n",
      "[-8064.28876734  7966.69563188 -1008.68844829]\n",
      "[-8045.924108    7978.8383544  -1008.28710831]\n",
      "Train Loss: 0.170238 ---- Test Loss: 0.196054\n",
      "Epoch 18/50\n",
      "----------\n",
      "[-8199.14685846  7987.03203798 -1003.58499574]\n",
      "[-8197.99811768  7993.80433381 -1003.92729824]\n",
      "[-8064.28876734  7966.69563188 -1008.68844829]\n",
      "[-8051.0179259   7987.49694817 -1009.15148941]\n",
      "Train Loss: 0.165694 ---- Test Loss: 0.197965\n",
      "Epoch 19/50\n",
      "----------\n",
      "[-8199.14685846  7987.03203798 -1003.58499574]\n",
      "[-8195.28607797  8000.61739946 -1004.17425937]\n",
      "[-8064.28876734  7966.69563188 -1008.68844829]\n",
      "[-8050.58030148  7982.65546429 -1008.82046628]\n",
      "Train Loss: 0.158646 ---- Test Loss: 0.192502\n",
      "Epoch 20/50\n",
      "----------\n",
      "[-8199.14685846  7987.03203798 -1003.58499574]\n",
      "[-8209.39399304  7990.4987153  -1004.44073327]\n",
      "[-8064.28876734  7966.69563188 -1008.68844829]\n",
      "[-8047.91105881  7986.27481001 -1008.87864766]\n",
      "Train Loss: 0.159291 ---- Test Loss: 0.157868\n",
      "Epoch 21/50\n",
      "----------\n",
      "[-8199.14685846  7987.03203798 -1003.58499574]\n",
      "[-8203.39816818  7989.0896401  -1003.9778881 ]\n",
      "[-8064.28876734  7966.69563188 -1008.68844829]\n",
      "[-8054.33222841  7977.05221296 -1008.7066477 ]\n",
      "Train Loss: 0.155687 ---- Test Loss: 0.154095\n",
      "Epoch 22/50\n",
      "----------\n",
      "[-8199.14685846  7987.03203798 -1003.58499574]\n",
      "[-8200.42091669  7990.68764938 -1003.88867225]\n",
      "[-8064.28876734  7966.69563188 -1008.68844829]\n",
      "[-8061.71928307  7972.96053883 -1008.91773003]\n",
      "Train Loss: 0.155726 ---- Test Loss: 0.180035\n",
      "Epoch 23/50\n",
      "----------\n",
      "[-8199.14685846  7987.03203798 -1003.58499574]\n",
      "[-8203.1657719   7986.95784885 -1003.8328933 ]\n",
      "[-8064.28876734  7966.69563188 -1008.68844829]\n",
      "[-8057.74252208  7981.97128437 -1009.23027247]\n",
      "Train Loss: 0.151527 ---- Test Loss: 0.141720\n",
      "Epoch 24/50\n",
      "----------\n",
      "[-8199.14685846  7987.03203798 -1003.58499574]\n",
      "[-8213.55747924  7980.60438347 -1004.09762668]\n",
      "[-8064.28876734  7966.69563188 -1008.68844829]\n",
      "[-8062.84688717  7968.99348546 -1008.74090021]\n",
      "Train Loss: 0.152754 ---- Test Loss: 0.134829\n",
      "Epoch 25/50\n",
      "----------\n",
      "[-8199.14685846  7987.03203798 -1003.58499574]\n",
      "[-8209.97236184  7982.90490336 -1004.01281081]\n",
      "[-8064.28876734  7966.69563188 -1008.68844829]\n",
      "[-8068.84732844  7961.02239891 -1008.62243929]\n",
      "Train Loss: 0.149474 ---- Test Loss: 0.112641\n",
      "Epoch 26/50\n",
      "----------\n",
      "[-8199.14685846  7987.03203798 -1003.58499574]\n",
      "[-8220.86169745  7985.42826777 -1004.85168007]\n",
      "[-8064.28876734  7966.69563188 -1008.68844829]\n",
      "[-8070.05546986  7977.5672835  -1009.73341211]\n",
      "Train Loss: 0.157494 ---- Test Loss: 0.189217\n",
      "Epoch 27/50\n",
      "----------\n",
      "[-8199.14685846  7987.03203798 -1003.58499574]\n",
      "[-8196.59894094  7991.20878777 -1003.68059432]\n",
      "[-8064.28876734  7966.69563188 -1008.68844829]\n",
      "[-8049.43244008  7981.91926437 -1008.70181277]\n",
      "Train Loss: 0.175325 ---- Test Loss: 0.159008\n",
      "Epoch 28/50\n",
      "----------\n",
      "[-8199.14685846  7987.03203798 -1003.58499574]\n",
      "[-8201.15285869  7988.77395085 -1003.81755078]\n",
      "[-8064.28876734  7966.69563188 -1008.68844829]\n",
      "[-8049.70014756  7981.39479577 -1008.68586864]\n",
      "Train Loss: 0.152815 ---- Test Loss: 0.201764\n",
      "Epoch 29/50\n",
      "----------\n",
      "[-8199.14685846  7987.03203798 -1003.58499574]\n",
      "[-8197.08197784  7990.66744449 -1003.67778752]\n",
      "[-8064.28876734  7966.69563188 -1008.68844829]\n",
      "[-8050.50123002  7981.56771498 -1008.74732145]\n",
      "Train Loss: 0.155372 ---- Test Loss: 0.138438\n",
      "Epoch 30/50\n",
      "----------\n",
      "[-8199.14685846  7987.03203798 -1003.58499574]\n",
      "[-8195.86138047  7994.63764241 -1003.84419043]\n",
      "[-8064.28876734  7966.69563188 -1008.68844829]\n",
      "[-8057.32184072  7975.45203972 -1008.79550354]\n",
      "Train Loss: 0.138732 ---- Test Loss: 0.130655\n",
      "Epoch 31/50\n",
      "----------\n",
      "[-8199.14685846  7987.03203798 -1003.58499574]\n",
      "[-8197.5953414   7987.48576438 -1003.51532012]\n",
      "[-8064.28876734  7966.69563188 -1008.68844829]\n",
      "[-8062.73373305  7970.09701889 -1008.8027686 ]\n",
      "Train Loss: 0.139563 ---- Test Loss: 0.105309\n",
      "Epoch 32/50\n",
      "----------\n",
      "[-8199.14685846  7987.03203798 -1003.58499574]\n",
      "[-8197.40573414  7987.36761929 -1003.49618442]\n",
      "[-8064.28876734  7966.69563188 -1008.68844829]\n",
      "[-8051.05631231  7976.1523697  -1008.44320214]\n",
      "Train Loss: 0.150870 ---- Test Loss: 0.197018\n",
      "Epoch 33/50\n",
      "----------\n",
      "[-8199.14685846  7987.03203798 -1003.58499574]\n",
      "[-8191.38314722  7979.00491704 -1002.60630579]\n",
      "[-8064.28876734  7966.69563188 -1008.68844829]\n",
      "[-8049.992141    7979.16295492 -1008.56450372]\n",
      "Train Loss: 0.146407 ---- Test Loss: 0.165727\n",
      "Epoch 34/50\n",
      "----------\n",
      "[-8199.14685846  7987.03203798 -1003.58499574]\n",
      "[-8199.81223675  7998.44888218 -1004.32548957]\n",
      "[-8064.28876734  7966.69563188 -1008.68844829]\n",
      "[-8067.30341866  7973.97153156 -1009.33432235]\n",
      "Train Loss: 0.152420 ---- Test Loss: 0.170104\n",
      "Epoch 35/50\n",
      "----------\n",
      "[-8199.14685846  7987.03203798 -1003.58499574]\n",
      "[-8200.00726442  7989.44188512 -1003.78647119]\n",
      "[-8064.28876734  7966.69563188 -1008.68844829]\n",
      "[-8053.5754465   7978.7007654  -1008.76203911]\n",
      "Train Loss: 0.135084 ---- Test Loss: 0.144323\n",
      "Epoch 36/50\n",
      "----------\n",
      "[-8199.14685846  7987.03203798 -1003.58499574]\n",
      "[-8198.52673097  7992.60151092 -1003.88686181]\n",
      "[-8064.28876734  7966.69563188 -1008.68844829]\n",
      "[-8056.60824804  7975.15902207 -1008.73203364]\n",
      "Train Loss: 0.128137 ---- Test Loss: 0.128731\n",
      "Epoch 37/50\n",
      "----------\n",
      "[-8199.14685846  7987.03203798 -1003.58499574]\n",
      "[-8196.72400144  7985.16644474 -1003.31869414]\n",
      "[-8064.28876734  7966.69563188 -1008.68844829]\n",
      "[-8056.12216128  7971.87352209 -1008.49563886]\n",
      "Train Loss: 0.129223 ---- Test Loss: 0.135346\n",
      "Epoch 38/50\n",
      "----------\n",
      "[-8199.14685846  7987.03203798 -1003.58499574]\n",
      "[-8198.35424849  7995.33363437 -1004.04326612]\n",
      "[-8064.28876734  7966.69563188 -1008.68844829]\n",
      "[-8052.7506249   7974.19571024 -1008.42779523]\n",
      "Train Loss: 0.129127 ---- Test Loss: 0.123423\n",
      "Epoch 39/50\n",
      "----------\n",
      "[-8199.14685846  7987.03203798 -1003.58499574]\n",
      "[-8193.64007482  7997.76423751 -1003.89624612]\n",
      "[-8064.28876734  7966.69563188 -1008.68844829]\n",
      "[-8055.48002563  7977.22948613 -1008.79031637]\n",
      "Train Loss: 0.127806 ---- Test Loss: 0.128023\n",
      "Epoch 40/50\n",
      "----------\n",
      "[-8199.14685846  7987.03203798 -1003.58499574]\n",
      "[-8187.54171462  7976.96894722 -1002.24049007]\n",
      "[-8064.28876734  7966.69563188 -1008.68844829]\n",
      "[-8050.44624586  7974.18314188 -1008.28131804]\n",
      "Train Loss: 0.130530 ---- Test Loss: 0.148548\n",
      "Epoch 41/50\n",
      "----------\n",
      "[-8199.14685846  7987.03203798 -1003.58499574]\n",
      "[-8207.02003605  7980.1058797  -1003.65614467]\n",
      "[-8064.28876734  7966.69563188 -1008.68844829]\n",
      "[-8056.76521323  7973.97337777 -1008.66774271]\n",
      "Train Loss: 0.125456 ---- Test Loss: 0.114692\n",
      "Epoch 42/50\n",
      "----------\n",
      "[-8199.14685846  7987.03203798 -1003.58499574]\n",
      "[-8201.8270296   7992.72807658 -1004.1018219 ]\n",
      "[-8064.28876734  7966.69563188 -1008.68844829]\n",
      "[-8054.74842177  7969.2318712  -1008.24341653]\n",
      "Train Loss: 0.126047 ---- Test Loss: 0.122490\n",
      "Epoch 43/50\n",
      "----------\n",
      "[-8199.14685846  7987.03203798 -1003.58499574]\n",
      "[-8195.98803888  7986.07581775 -1003.32811591]\n",
      "[-8064.28876734  7966.69563188 -1008.68844829]\n",
      "[-8058.19555947  7973.15203443 -1008.70680228]\n",
      "Train Loss: 0.118834 ---- Test Loss: 0.115806\n",
      "Epoch 44/50\n",
      "----------\n",
      "[-8199.14685846  7987.03203798 -1003.58499574]\n",
      "[-8193.97984802  7992.83850276 -1003.61595297]\n",
      "[-8064.28876734  7966.69563188 -1008.68844829]\n",
      "[-8061.48355199  7970.76626093 -1008.76552594]\n",
      "Train Loss: 0.119864 ---- Test Loss: 0.142635\n",
      "Epoch 45/50\n",
      "----------\n",
      "[-8199.14685846  7987.03203798 -1003.58499574]\n",
      "[-8206.15931899  7987.89740141 -1004.07842106]\n",
      "[-8064.28876734  7966.69563188 -1008.68844829]\n",
      "[-8058.66708701  7976.0481637  -1008.91789474]\n",
      "Train Loss: 0.120836 ---- Test Loss: 0.124996\n",
      "Epoch 46/50\n",
      "----------\n",
      "[-8199.14685846  7987.03203798 -1003.58499574]\n",
      "[-8199.48798235  7985.11567341 -1003.48918739]\n",
      "[-8064.28876734  7966.69563188 -1008.68844829]\n",
      "[-8056.62088212  7969.62166035 -1008.38625737]\n",
      "Train Loss: 0.120715 ---- Test Loss: 0.112988\n",
      "Epoch 47/50\n",
      "----------\n",
      "[-8199.14685846  7987.03203798 -1003.58499574]\n",
      "[-8206.18129008  7984.05892487 -1003.84508441]\n",
      "[-8064.28876734  7966.69563188 -1008.68844829]\n",
      "[-8061.88885958  7969.53905383 -1008.71439931]\n",
      "Train Loss: 0.119332 ---- Test Loss: 0.106337\n",
      "Epoch 48/50\n",
      "----------\n",
      "[-8199.14685846  7987.03203798 -1003.58499574]\n",
      "[-8203.96134943  7979.02283601 -1003.39768415]\n",
      "[-8064.28876734  7966.69563188 -1008.68844829]\n",
      "[-8062.06652179  7966.83482129 -1008.55649111]\n",
      "Train Loss: 0.118266 ---- Test Loss: 0.100035\n",
      "Epoch 49/50\n",
      "----------\n",
      "[-8199.14685846  7987.03203798 -1003.58499574]\n",
      "[-8189.95845544  7990.17902947 -1003.20074353]\n",
      "[-8064.28876734  7966.69563188 -1008.68844829]\n",
      "[-8062.88517706  7961.47309057 -1008.27303176]\n",
      "Train Loss: 0.117385 ---- Test Loss: 0.095310\n",
      "4060.6497325897217\n"
     ]
    }
   ],
   "source": [
    "def main(training_names, test_names, bs, num_epoch, y_train, y_test, normalize=True):\n",
    "    best_error = 1e+20      # a dummy and very large number for saving the best discovered model\n",
    "    for epoch in range(num_epoch):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epoch))\n",
    "        print('-'*10)\n",
    "        running_loss_train = 0\n",
    "        running_loss_test = 0\n",
    "\n",
    "        model.train()\n",
    "        for i in range(0, len(training_names)//bs):\n",
    "            x_train, labels = Drawing_Batch(training_names, y_train, bs, i, normalize)\n",
    "            x_train = x_train.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(x_train)\n",
    "            loss = criterion(out, labels[:,0:2])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss_train += loss.item()\n",
    "            \n",
    "        out = torch.cat((out, torch.unsqueeze(labels[:,2], dim=1)), dim=1)\n",
    "        \n",
    "        true_train = Spher2Cart_1D(np.multiply(labels.cpu().data.numpy()[1,], [rng_res_tr,az_step_tr,el_step_tr]) + coord_tr)\n",
    "        pred_train = Spher2Cart_1D(np.multiply(out.cpu().data.numpy()[1,], [rng_res_tr,az_step_tr,el_step_tr]) + coord_tr)\n",
    "        print(true_train)\n",
    "        print(pred_train)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, len(test_names)//bs):\n",
    "                x_test, labels_test = Drawing_Batch(test_names, y_test, bs, i, normalize)\n",
    "                x_test = x_test.to(device)\n",
    "                labels_test = labels_test.to(device)\n",
    "                out_test = model(x_test)\n",
    "                loss_test = criterion(out_test, labels_test[:,0:2])\n",
    "                running_loss_test += loss_test.item()\n",
    "\n",
    "        out_test = torch.cat((out_test, torch.unsqueeze(labels_test[:,2], dim=1)), dim=1)\n",
    "        \n",
    "        true_test = Spher2Cart_1D(np.multiply(labels_test.cpu().data.numpy()[1,], [rng_res_ts,az_step_ts,el_step_ts]) + coord_ts)\n",
    "        pred_test = Spher2Cart_1D(np.multiply(out_test.cpu().data.numpy()[1,], [rng_res_ts,az_step_ts,el_step_ts]) + coord_ts)\n",
    "        print(true_test)\n",
    "        print(pred_test)\n",
    "        \n",
    "        epoch_loss_train = running_loss_train*x_train.size()[0]/len(training_names)\n",
    "        epoch_loss_test = running_loss_test*x_test.size()[0]/len(test_names)\n",
    "\n",
    "        print('Train Loss: {:.6f} ---- Test Loss: {:.6f}'.format(epoch_loss_train, epoch_loss_test))\n",
    "        if epoch%5==0:\n",
    "            if epoch_loss_test < best_error:\n",
    "                torch.save(model.state_dict(), PATH)\n",
    "                best_error = epoch_loss_test\n",
    "\n",
    "start = time.time()\n",
    "main(training_names, test_names, bs, num_epoch, y_train, y_test, normalize=True)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azimuth Estimation Error (deg) = 0.08580762093045226\n",
      "Localization Error (m) = 8.181763920919526\n"
     ]
    }
   ],
   "source": [
    "def Spher2Cart_2D(spherical):\n",
    "    cartesian = np.zeros((len(spherical),3))\n",
    "    hypotenuse = np.multiply(np.cos(np.radians(spherical[:,2])), spherical[:,0])\n",
    "    cartesian[:,0] = np.multiply(np.cos(np.radians(spherical[:,1])), hypotenuse)\n",
    "    cartesian[:,1] = np.multiply(-np.sin(np.radians(spherical[:,1])), hypotenuse)\n",
    "    cartesian[:,2] = np.multiply(np.sin(np.radians(spherical[:,2])), spherical[:,0])\n",
    "    return cartesian\n",
    "\n",
    "# Testing: (range,az,el)\n",
    "model.eval()\n",
    "out_test_reg = np.zeros((len(y_test),3))\n",
    "labels_test_reg = np.zeros((len(y_test),3))\n",
    "\n",
    "for i in range(0, len(y_test)//bs):  \n",
    "    x_test, labels_test = Drawing_Batch(test_names, y_test, bs, i, True)\n",
    "    labels_test = labels_test.cpu().data.numpy()\n",
    "    labels_test_reg[bs*i : bs*i + bs] = (labels_test[:,0:3])\n",
    "\n",
    "    cur_test_reg = model(x_test)\n",
    "    out_test_reg[bs*i : bs*i + bs, 0:2] = cur_test_reg.cpu().data.numpy()\n",
    "    out_test_reg[bs*i : bs*i + bs, 2] = labels_test_reg[bs*i : bs*i + bs, 2]\n",
    "    \n",
    "azim_tot = 0\n",
    "for i in np.arange(0,len(out_test_reg),1):\n",
    "    azim_tot += np.linalg.norm(out_test_reg[i,1] - labels_test_reg[i,1])\n",
    "    \n",
    "azim_tot = azim_tot / len(out_test_reg)\n",
    "print(f'Azimuth Estimation Error (deg) = {azim_tot}')   \n",
    "\n",
    "new_data = Spher2Cart_2D(np.multiply(out_test_reg, [rng_res_ts,az_step_ts,el_step_ts]) + coord_ts)\n",
    "new_labels_data = Spher2Cart_2D(np.multiply(labels_test_reg, [rng_res_ts,az_step_ts,el_step_ts]) + coord_ts)\n",
    "\n",
    "sum_tot = 0\n",
    "for i in np.arange(0,len(new_data) - (len(new_data) % bs),1):\n",
    "    sum_tot += np.linalg.norm(new_data[i,:] - new_labels_data[i,:])\n",
    "    \n",
    "# def reject_outliers(data, m=2):\n",
    "#     return data[abs(data - np.mean(data)) < m * np.std(data)]\n",
    "# \n",
    "# azims = (np.multiply(out_test_reg, [rng_res_ts,az_step_ts,el_step_ts]) - np.multiply(labels_test_reg, [rng_res_ts,az_step_ts,el_step_ts]))[:,1]\n",
    "# azims = reject_outliers(azims)\n",
    "# mse = np.mean(azims**2)\n",
    "# bias_sq = np.mean(azims)**2\n",
    "# var = np.var(azims)\n",
    "# print(mse, bias_sq, var)\n",
    "\n",
    "sum_tot = sum_tot / (len(new_data) - (len(new_data) % bs))\n",
    "print(f'Localization Error (m) = {sum_tot}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
