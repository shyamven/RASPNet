{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Regression Network on Radar Dataset (Central Kansas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "import scipy.io as sio\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import itertools\n",
    "import time\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import KFold\n",
    "from itertools import product\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the labels and creating train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "Training labels: \n",
      "[[ 5.9595  16.043   18.872  ]\n",
      " [16.369   20.125   29.519  ]\n",
      " [ 5.4378  17.074   17.305  ]\n",
      " ...\n",
      " [ 0.38467 14.803    7.8498 ]\n",
      " [13.44    21.64    27.856  ]\n",
      " [17.917   21.429   32.766  ]]\n"
     ]
    }
   ],
   "source": [
    "def index(string):\n",
    "    s = re.findall(\"[0-9]\", string)\n",
    "    return int(''.join(s))\n",
    "\n",
    "scenario_idx = 60 # Central Kansas\n",
    "names = os.listdir(f'num{scenario_idx}_NAMF_DATA_20_rng30_pulse1_1000_100k/')\n",
    "names = sorted(names, key = index)\n",
    "print(len(names))\n",
    "y = pd.read_csv(f'num{scenario_idx}_Ground_Truth_20_rng30_1000_100k_m.csv')\n",
    "col_names = y.columns[4:7]\n",
    "y = y[col_names].to_numpy()\n",
    "\n",
    "y_train = y[:int(0.9*len(names))]\n",
    "y_test = y[(int(0.9*len(names))+1):]\n",
    "training_names = names[:int(0.9*len(names))]\n",
    "test_names = names[(int(0.9*len(names))+1):]\n",
    "\n",
    "print('Training labels: ')\n",
    "print(y_train)\n",
    "\n",
    "# Tensor Corners\n",
    "##################################################################################\n",
    "# num29: [10851, 215, -5.45], num60: [11073, 215, -5.3], num62: [11471, 215, -5.6]\n",
    "# num76: [11388, 215, -6.15], num35: [11381, 215, -0.95]\n",
    "##################################################################################\n",
    "\n",
    "# Training dataset global constants\n",
    "coord_tr = [11073, 215, -5.3] # Tensor corner\n",
    "rng_res_tr = 59.9585/2        # Range resolution\n",
    "az_step_tr = 0.4              # Azimuth step size\n",
    "el_step_tr = 0.01             # Elevation step size\n",
    "\n",
    "# Test dataset global constants\n",
    "coord_ts = [11073, 215, -5.3] # Tensor corner\n",
    "rng_res_ts = 59.9585/2        # Range resolution\n",
    "az_step_ts = 0.4              # Azimuth step size\n",
    "el_step_ts = 0.01             # Elevation step size\n",
    "\n",
    "\n",
    "def Drawing_Batch(names, label, bs, ind, normalize = True):\n",
    "    x = []\n",
    "    labels = []\n",
    "    \n",
    "    for j in range(ind*bs, (ind+1)*bs):\n",
    "        try: temp = sio.loadmat(f'num{scenario_idx}_NAMF_DATA_20_rng30_pulse1_1000_100k/'+names[j])['P']\n",
    "        except: break\n",
    "        if normalize:\n",
    "            Anorm = temp - np.min(temp.flatten())\n",
    "            temp = np.divide(Anorm, np.max(Anorm.flatten()))\n",
    "        x.append(temp)\n",
    "        labels.append(label[j,:])\n",
    "        \n",
    "    x = torch.FloatTensor(np.array(x))\n",
    "    labels = torch.FloatTensor(np.array(labels))\n",
    "    return x,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90000\n",
      "9999\n"
     ]
    }
   ],
   "source": [
    "print(len(y_train))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining regression CNN and instantiating it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1               [-1, 32, 24]           2,048\n",
      "       BatchNorm1d-2               [-1, 32, 24]              64\n",
      "            Conv1d-3               [-1, 64, 10]           6,208\n",
      "       BatchNorm1d-4               [-1, 64, 10]             128\n",
      "            Linear-5                   [-1, 20]           6,420\n",
      "            Linear-6                    [-1, 2]              42\n",
      "               Net-7                    [-1, 2]               0\n",
      "================================================================\n",
      "Total params: 14,910\n",
      "Trainable params: 14,910\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.02\n",
      "Params size (MB): 0.06\n",
      "Estimated Total Size (MB): 0.08\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(21, 32, 3, 1) # 5, 32, 3, 1\n",
    "        self.conv2 = nn.Conv1d(32, 64, 3, 1)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(32)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(64)\n",
    "        self.fc1 = nn.Linear(64 * 5, 20)  # Adjust input size based on the output of conv layers and max pooling\n",
    "        self.fc2_reg = nn.Linear(20, 2)  # Adjusted output size\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(self.batchnorm1(x))\n",
    "        x = F.max_pool1d(x, 2)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(self.batchnorm2(x))\n",
    "        x = F.max_pool1d(x, 2)\n",
    "        \n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        output_reg = self.fc2_reg(x)  # (bs, 2)\n",
    "        \n",
    "        return output_reg\n",
    "    \n",
    "from torchsummary import summary\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "model = Net()\n",
    "model = model.to(device)\n",
    "if device == 'cuda:0':\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    cudnn.benchmark = True\n",
    "print(summary(model,(21,26)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 128  # batch_size\n",
    "num_epoch = 50  # number of epochs\n",
    "PATH = './ckpt_model.pth'   # forsaving the model\n",
    "criterion = nn.L1Loss()\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Define a Loss function and optimizer; Using GPU or CPU\n",
    "model = Net()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "model = model.to(device)\n",
    "if device == 'cuda:0':\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    cudnn.benchmark = True\n",
    "    \n",
    "def Spher2Cart_1D(spherical):\n",
    "    cartesian = np.zeros(3)\n",
    "    hypotenuse = np.cos(np.radians(spherical[2]))*spherical[0]\n",
    "    cartesian[0] = np.cos(np.radians(spherical[1]))*hypotenuse\n",
    "    cartesian[1] = -np.sin(np.radians(spherical[1]))*hypotenuse\n",
    "    cartesian[2] = np.sin(np.radians(spherical[2]))*spherical[0]\n",
    "    return cartesian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evaluate the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/50\n",
      "----------\n",
      "[-8158.64542481  8067.79238144 -1001.08078603]\n",
      "[-8149.52050515  8048.74508463  -999.34639264]\n",
      "[-8159.84303434  7879.09822665 -1009.81186838]\n",
      "[-8124.60028599  7888.42161911 -1008.13520964]\n",
      "Train Loss: 1.409022 ---- Test Loss: 0.476916\n",
      "Epoch 1/50\n",
      "----------\n",
      "[-8158.64542481  8067.79238144 -1001.08078603]\n",
      "[-8143.6838431   8063.45197042  -999.88653955]\n",
      "[-8159.84303434  7879.09822665 -1009.81186838]\n",
      "[-8136.89993734  7887.33571299 -1008.85381208]\n",
      "Train Loss: 0.401921 ---- Test Loss: 0.404351\n",
      "Epoch 2/50\n",
      "----------\n",
      "[-8158.64542481  8067.79238144 -1001.08078603]\n",
      "[-8140.28658939  8066.80971841  -999.88212617]\n",
      "[-8159.84303434  7879.09822665 -1009.81186838]\n",
      "[-8152.3479636   7869.06403109 -1008.71137696]\n",
      "Train Loss: 0.343216 ---- Test Loss: 0.398631\n",
      "Epoch 3/50\n",
      "----------\n",
      "[-8158.64542481  8067.79238144 -1001.08078603]\n",
      "[-8148.80793913  8062.64535155 -1000.1547741 ]\n",
      "[-8159.84303434  7879.09822665 -1009.81186838]\n",
      "[-8163.32230881  7857.52625079 -1008.7019636 ]\n",
      "Train Loss: 0.322130 ---- Test Loss: 0.377649\n",
      "Epoch 4/50\n",
      "----------\n",
      "[-8158.64542481  8067.79238144 -1001.08078603]\n",
      "[-8154.60103612  8053.75614118  -999.96899221]\n",
      "[-8159.84303434  7879.09822665 -1009.81186838]\n",
      "[-8164.12986571  7865.66106747 -1009.25609457]\n",
      "Train Loss: 0.310533 ---- Test Loss: 0.348622\n",
      "Epoch 5/50\n",
      "----------\n",
      "[-8158.64542481  8067.79238144 -1001.08078603]\n",
      "[-8152.37718837  8056.8367905  -1000.01986784]\n",
      "[-8159.84303434  7879.09822665 -1009.81186838]\n",
      "[-8162.44307293  7868.02705685 -1009.29412577]\n",
      "Train Loss: 0.296301 ---- Test Loss: 0.302869\n",
      "Epoch 6/50\n",
      "----------\n",
      "[-8158.64542481  8067.79238144 -1001.08078603]\n",
      "[-8152.40487704  8053.20163046  -999.79867206]\n",
      "[-8159.84303434  7879.09822665 -1009.81186838]\n",
      "[-8164.9803968   7863.81449819 -1009.1965797 ]\n",
      "Train Loss: 0.283251 ---- Test Loss: 0.308122\n",
      "Epoch 7/50\n",
      "----------\n",
      "[-8158.64542481  8067.79238144 -1001.08078603]\n",
      "[-8150.31122549  8051.29814015  -999.5520074 ]\n",
      "[-8159.84303434  7879.09822665 -1009.81186838]\n",
      "[-8162.43568245  7862.3257662  -1008.9414707 ]\n",
      "Train Loss: 0.271665 ---- Test Loss: 0.328405\n",
      "Epoch 8/50\n",
      "----------\n",
      "[-8158.64542481  8067.79238144 -1001.08078603]\n",
      "[-8151.18793902  8053.08642513  -999.71607527]\n",
      "[-8159.84303434  7879.09822665 -1009.81186838]\n",
      "[-8164.41240618  7861.2827525  -1009.0038149 ]\n",
      "Train Loss: 0.264656 ---- Test Loss: 0.299658\n",
      "Epoch 9/50\n",
      "----------\n",
      "[-8158.64542481  8067.79238144 -1001.08078603]\n",
      "[-8148.06158128  8050.1925859   -999.34458852]\n",
      "[-8159.84303434  7879.09822665 -1009.81186838]\n",
      "[-8159.64812273  7864.99231373 -1008.92748375]\n",
      "Train Loss: 0.260690 ---- Test Loss: 0.309229\n",
      "Epoch 10/50\n",
      "----------\n",
      "[-8158.64542481  8067.79238144 -1001.08078603]\n",
      "[-8146.51819869  8052.98425918  -999.42001854]\n",
      "[-8159.84303434  7879.09822665 -1009.81186838]\n",
      "[-8160.73811906  7862.82077757 -1008.86320769]\n",
      "Train Loss: 0.256940 ---- Test Loss: 0.303451\n",
      "Epoch 11/50\n",
      "----------\n",
      "[-8158.64542481  8067.79238144 -1001.08078603]\n",
      "[-8143.66194771  8053.10444466  -999.25018048]\n",
      "[-8159.84303434  7879.09822665 -1009.81186838]\n",
      "[-8160.61041334  7853.55428902 -1008.28280652]\n",
      "Train Loss: 0.249023 ---- Test Loss: 0.366071\n",
      "Epoch 12/50\n",
      "----------\n",
      "[-8158.64542481  8067.79238144 -1001.08078603]\n",
      "[-8147.02548658  8047.96036262  -999.14340702]\n",
      "[-8159.84303434  7879.09822665 -1009.81186838]\n",
      "[-8159.34478226  7859.20189329 -1008.55035596]\n",
      "Train Loss: 0.244989 ---- Test Loss: 0.351959\n",
      "Epoch 13/50\n",
      "----------\n",
      "[-8158.64542481  8067.79238144 -1001.08078603]\n",
      "[-8148.54570465  8046.7874235   -999.16586158]\n",
      "[-8159.84303434  7879.09822665 -1009.81186838]\n",
      "[-8160.49611511  7858.09760129 -1008.55598674]\n",
      "Train Loss: 0.238253 ---- Test Loss: 0.345567\n",
      "Epoch 14/50\n",
      "----------\n",
      "[-8158.64542481  8067.79238144 -1001.08078603]\n",
      "[-8149.09908323  8046.35296039  -999.17358251]\n",
      "[-8159.84303434  7879.09822665 -1009.81186838]\n",
      "[-8160.02506387  7858.8178381  -1008.57025763]\n",
      "Train Loss: 0.234823 ---- Test Loss: 0.345997\n",
      "Epoch 15/50\n",
      "----------\n",
      "[-8158.64542481  8067.79238144 -1001.08078603]\n",
      "[-8149.20792347  8045.06540622  -999.10141531]\n",
      "[-8159.84303434  7879.09822665 -1009.81186838]\n",
      "[-8158.42037073  7860.16239812 -1008.55041174]\n",
      "Train Loss: 0.231476 ---- Test Loss: 0.343242\n",
      "Epoch 16/50\n",
      "----------\n",
      "[-8158.64542481  8067.79238144 -1001.08078603]\n",
      "[-8149.84939696  8045.17090865  -999.14771106]\n",
      "[-8159.84303434  7879.09822665 -1009.81186838]\n",
      "[-8157.37844626  7860.49033874 -1008.50387225]\n",
      "Train Loss: 0.227025 ---- Test Loss: 0.343285\n",
      "Epoch 17/50\n",
      "----------\n",
      "[-8158.64542481  8067.79238144 -1001.08078603]\n",
      "[-8149.14768527  8046.26850969  -999.17142303]\n",
      "[-8159.84303434  7879.09822665 -1009.81186838]\n",
      "[-8156.86897313  7863.6411985  -1008.66587692]\n",
      "Train Loss: 0.222286 ---- Test Loss: 0.324023\n",
      "Epoch 18/50\n",
      "----------\n",
      "[-8158.64542481  8067.79238144 -1001.08078603]\n",
      "[-8150.69181047  8047.05304827  -999.31538219]\n",
      "[-8159.84303434  7879.09822665 -1009.81186838]\n",
      "[-8157.25382132  7862.44246141 -1008.61648021]\n",
      "Train Loss: 0.219129 ---- Test Loss: 0.318261\n",
      "Epoch 19/50\n",
      "----------\n",
      "[-8158.64542481  8067.79238144 -1001.08078603]\n",
      "[-8152.49104622  8047.8467894   -999.47574739]\n",
      "[-8159.84303434  7879.09822665 -1009.81186838]\n",
      "[-8159.31017068  7863.56356571 -1008.81755301]\n",
      "Train Loss: 0.218644 ---- Test Loss: 0.301050\n",
      "Epoch 20/50\n",
      "----------\n",
      "[-8158.64542481  8067.79238144 -1001.08078603]\n",
      "[-8151.75959577  8048.59899375  -999.47644071]\n",
      "[-8159.84303434  7879.09822665 -1009.81186838]\n",
      "[-8160.39457229  7861.00974715 -1008.72932142]\n",
      "Train Loss: 0.211402 ---- Test Loss: 0.290993\n",
      "Epoch 21/50\n",
      "----------\n",
      "[-8158.64542481  8067.79238144 -1001.08078603]\n",
      "[-8151.81515359  8047.86866364  -999.43512244]\n",
      "[-8159.84303434  7879.09822665 -1009.81186838]\n",
      "[-8163.649156    7857.57343004 -1008.72584053]\n",
      "Train Loss: 0.206941 ---- Test Loss: 0.290966\n",
      "Epoch 22/50\n",
      "----------\n",
      "[-8158.64542481  8067.79238144 -1001.08078603]\n",
      "[-8151.49822036  8047.46575067  -999.3907476 ]\n",
      "[-8159.84303434  7879.09822665 -1009.81186838]\n",
      "[-8164.6038827   7854.58205898 -1008.60243242]\n",
      "Train Loss: 0.202945 ---- Test Loss: 0.312189\n",
      "Epoch 23/50\n",
      "----------\n",
      "[-8158.64542481  8067.79238144 -1001.08078603]\n",
      "[-8150.92241801  8049.55143322  -999.48285452]\n",
      "[-8159.84303434  7879.09822665 -1009.81186838]\n",
      "[-8164.27102626  7859.03089664 -1008.85570844]\n",
      "Train Loss: 0.202312 ---- Test Loss: 0.287177\n",
      "Epoch 24/50\n",
      "----------\n",
      "[-8158.64542481  8067.79238144 -1001.08078603]\n",
      "[-8155.9695083   8049.82556635  -999.81301802]\n",
      "[-8159.84303434  7879.09822665 -1009.81186838]\n",
      "[-8164.73768626  7867.19092266 -1009.38955999]\n",
      "Train Loss: 0.199314 ---- Test Loss: 0.233148\n",
      "Epoch 25/50\n",
      "----------\n",
      "[-8158.64542481  8067.79238144 -1001.08078603]\n",
      "[-8154.24853778  8048.64724427  -999.63393572]\n",
      "[-8159.84303434  7879.09822665 -1009.81186838]\n",
      "[-8164.9597594   7864.12952722 -1009.21471177]\n",
      "Train Loss: 0.196833 ---- Test Loss: 0.258024\n",
      "Epoch 26/50\n",
      "----------\n",
      "[-8158.64542481  8067.79238144 -1001.08078603]\n",
      "[-8157.57859455  8050.84589281  -999.97547063]\n",
      "[-8159.84303434  7879.09822665 -1009.81186838]\n",
      "[-8171.56822626  7863.98494331 -1009.6296071 ]\n",
      "Train Loss: 0.193903 ---- Test Loss: 0.217187\n",
      "Epoch 27/50\n",
      "----------\n",
      "[-8158.64542481  8067.79238144 -1001.08078603]\n",
      "[-8157.89159298  8049.73901236  -999.92707505]\n",
      "[-8159.84303434  7879.09822665 -1009.81186838]\n",
      "[-8168.73744793  7864.90976673 -1009.5051418 ]\n",
      "Train Loss: 0.191630 ---- Test Loss: 0.225023\n",
      "Epoch 28/50\n",
      "----------\n",
      "[-8158.64542481  8067.79238144 -1001.08078603]\n",
      "[-8161.18708909  8050.87435825 -1000.20132084]\n",
      "[-8159.84303434  7879.09822665 -1009.81186838]\n",
      "[-8167.98208655  7869.0335571  -1009.71137635]\n",
      "Train Loss: 0.193787 ---- Test Loss: 0.202883\n",
      "Epoch 29/50\n",
      "----------\n",
      "[-8158.64542481  8067.79238144 -1001.08078603]\n",
      "[-8161.30306744  8052.67629821 -1000.31893888]\n",
      "[-8159.84303434  7879.09822665 -1009.81186838]\n",
      "[-8169.4231095   7869.92328339 -1009.8587197 ]\n",
      "Train Loss: 0.194413 ---- Test Loss: 0.197649\n",
      "Epoch 30/50\n",
      "----------\n",
      "[-8158.64542481  8067.79238144 -1001.08078603]\n",
      "[-8162.07131868  8052.62099883 -1000.36326402]\n",
      "[-8159.84303434  7879.09822665 -1009.81186838]\n",
      "[-8168.31731265  7871.42649617 -1009.88067999]\n",
      "Train Loss: 0.191894 ---- Test Loss: 0.190704\n",
      "Epoch 31/50\n",
      "----------\n",
      "[-8158.64542481  8067.79238144 -1001.08078603]\n",
      "[-8160.80045673  8053.12106084 -1000.31498026]\n",
      "[-8159.84303434  7879.09822665 -1009.81186838]\n",
      "[-8167.11198381  7872.75079181 -1009.88523329]\n",
      "Train Loss: 0.188631 ---- Test Loss: 0.191232\n",
      "Epoch 32/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-8158.64542481  8067.79238144 -1001.08078603]\n",
      "[-8162.32953708  8053.43728414 -1000.42932058]\n",
      "[-8159.84303434  7879.09822665 -1009.81186838]\n",
      "[-8171.42064129  7866.96836297 -1009.8043311 ]\n",
      "Train Loss: 0.184632 ---- Test Loss: 0.202540\n",
      "Epoch 33/50\n",
      "----------\n",
      "[-8158.64542481  8067.79238144 -1001.08078603]\n",
      "[-8163.95503994  8052.95455629 -1000.50070251]\n",
      "[-8159.84303434  7879.09822665 -1009.81186838]\n",
      "[-8173.887513    7866.62595667 -1009.94141431]\n",
      "Train Loss: 0.185152 ---- Test Loss: 0.199062\n",
      "Epoch 34/50\n",
      "----------\n",
      "[-8158.64542481  8067.79238144 -1001.08078603]\n",
      "[-8162.18425469  8050.82980417 -1000.2605287 ]\n",
      "[-8159.84303434  7879.09822665 -1009.81186838]\n",
      "[-8171.30504106  7865.7604217  -1009.72233621]\n",
      "Train Loss: 0.190177 ---- Test Loss: 0.220498\n",
      "Epoch 35/50\n",
      "----------\n",
      "[-8158.64542481  8067.79238144 -1001.08078603]\n",
      "[-8163.81579457  8054.39485396 -1000.58030486]\n",
      "[-8159.84303434  7879.09822665 -1009.81186838]\n",
      "[-8172.64328378  7869.32128214 -1010.02802588]\n",
      "Train Loss: 0.183616 ---- Test Loss: 0.196697\n",
      "Epoch 36/50\n",
      "----------\n",
      "[-8158.64542481  8067.79238144 -1001.08078603]\n",
      "[-8162.96519472  8055.49924428 -1000.59515528]\n",
      "[-8159.84303434  7879.09822665 -1009.81186838]\n",
      "[-8172.89685181  7867.61896518 -1009.93917823]\n",
      "Train Loss: 0.182705 ---- Test Loss: 0.205917\n",
      "Epoch 37/50\n",
      "----------\n",
      "[-8158.64542481  8067.79238144 -1001.08078603]\n",
      "[-8164.06317882  8055.50201239 -1000.66351296]\n",
      "[-8159.84303434  7879.09822665 -1009.81186838]\n",
      "[-8173.11203885  7867.77579027 -1009.9626622 ]\n",
      "Train Loss: 0.180783 ---- Test Loss: 0.205200\n",
      "Epoch 38/50\n",
      "----------\n",
      "[-8158.64542481  8067.79238144 -1001.08078603]\n",
      "[-8162.96749609  8055.02973393 -1000.56652548]\n",
      "[-8159.84303434  7879.09822665 -1009.81186838]\n",
      "[-8172.61222631  7867.75321253 -1009.92921218]\n",
      "Train Loss: 0.181114 ---- Test Loss: 0.206508\n",
      "Epoch 39/50\n",
      "----------\n",
      "[-8158.64542481  8067.79238144 -1001.08078603]\n",
      "[-8162.95466464  8057.17560057 -1000.69723953]\n",
      "[-8159.84303434  7879.09822665 -1009.81186838]\n",
      "[-8171.71156487  7870.27976793 -1010.02746812]\n",
      "Train Loss: 0.182347 ---- Test Loss: 0.194199\n",
      "Epoch 40/50\n",
      "----------\n",
      "[-8158.64542481  8067.79238144 -1001.08078603]\n",
      "[-8163.67452648  8057.44726287 -1000.75858947]\n",
      "[-8159.84303434  7879.09822665 -1009.81186838]\n",
      "[-8170.55667687  7870.15467638 -1009.94569127]\n",
      "Train Loss: 0.173885 ---- Test Loss: 0.192616\n",
      "Epoch 41/50\n",
      "----------\n",
      "[-8158.64542481  8067.79238144 -1001.08078603]\n",
      "[-8164.00825667  8054.25265681 -1000.58354531]\n",
      "[-8159.84303434  7879.09822665 -1009.81186838]\n",
      "[-8171.52096446  7866.04353071 -1009.75366423]\n",
      "Train Loss: 0.173094 ---- Test Loss: 0.224490\n",
      "Epoch 42/50\n",
      "----------\n",
      "[-8158.64542481  8067.79238144 -1001.08078603]\n",
      "[-8163.5311581   8056.19164615 -1000.67273484]\n",
      "[-8159.84303434  7879.09822665 -1009.81186838]\n",
      "[-8171.10555671  7867.6586238  -1009.82674519]\n",
      "Train Loss: 0.173253 ---- Test Loss: 0.210189\n",
      "Epoch 43/50\n",
      "----------\n",
      "[-8158.64542481  8067.79238144 -1001.08078603]\n",
      "[-8164.02899518  8054.88837709 -1000.62378758]\n",
      "[-8159.84303434  7879.09822665 -1009.81186838]\n",
      "[-8172.01554959  7864.8899687  -1009.71417019]\n",
      "Train Loss: 0.174817 ---- Test Loss: 0.213694\n",
      "Epoch 44/50\n",
      "----------\n",
      "[-8158.64542481  8067.79238144 -1001.08078603]\n",
      "[-8164.2249217   8052.02442916 -1000.46048013]\n",
      "[-8159.84303434  7879.09822665 -1009.81186838]\n",
      "[-8170.73372959  7864.88368913 -1009.63156431]\n",
      "Train Loss: 0.171840 ---- Test Loss: 0.221887\n",
      "Epoch 45/50\n",
      "----------\n",
      "[-8158.64542481  8067.79238144 -1001.08078603]\n",
      "[-8164.57768179  8050.84096763 -1000.40989276]\n",
      "[-8159.84303434  7879.09822665 -1009.81186838]\n",
      "[-8167.65636658  7869.37992823 -1009.71188847]\n",
      "Train Loss: 0.168673 ---- Test Loss: 0.211341\n",
      "Epoch 46/50\n",
      "----------\n",
      "[-8158.64542481  8067.79238144 -1001.08078603]\n",
      "[-8166.42014225  8049.91271128 -1000.46750525]\n",
      "[-8159.84303434  7879.09822665 -1009.81186838]\n",
      "[-8169.12129483  7868.88447089 -1009.77520874]\n",
      "Train Loss: 0.165942 ---- Test Loss: 0.206623\n",
      "Epoch 47/50\n",
      "----------\n",
      "[-8158.64542481  8067.79238144 -1001.08078603]\n",
      "[-8166.89612245  8049.76869188 -1000.48826006]\n",
      "[-8159.84303434  7879.09822665 -1009.81186838]\n",
      "[-8169.86715125  7866.08696641 -1009.65027949]\n",
      "Train Loss: 0.168999 ---- Test Loss: 0.211474\n",
      "Epoch 48/50\n",
      "----------\n",
      "[-8158.64542481  8067.79238144 -1001.08078603]\n",
      "[-8168.31708748  8051.0020179  -1000.65209185]\n",
      "[-8159.84303434  7879.09822665 -1009.81186838]\n",
      "[-8171.27710008  7865.00425773 -1009.6738598 ]\n",
      "Train Loss: 0.170033 ---- Test Loss: 0.202155\n",
      "Epoch 49/50\n",
      "----------\n",
      "[-8158.64542481  8067.79238144 -1001.08078603]\n",
      "[-8168.25296832  8050.85819364 -1000.63929902]\n",
      "[-8159.84303434  7879.09822665 -1009.81186838]\n",
      "[-8172.20545535  7863.69443668 -1009.65255106]\n",
      "Train Loss: 0.171042 ---- Test Loss: 0.194882\n",
      "4272.695242881775\n"
     ]
    }
   ],
   "source": [
    "def main(training_names, test_names, bs, num_epoch, y_train, y_test, normalize=True):\n",
    "    best_error = 1e+20      # a dummy and very large number for saving the best discovered model\n",
    "    for epoch in range(num_epoch):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epoch))\n",
    "        print('-'*10)\n",
    "        running_loss_train = 0\n",
    "        running_loss_test = 0\n",
    "\n",
    "        model.train()\n",
    "        for i in range(0, len(training_names)//bs):\n",
    "            x_train, labels = Drawing_Batch(training_names, y_train, bs, i, normalize)\n",
    "            x_train = x_train.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(x_train)\n",
    "            loss = criterion(out, labels[:,0:2])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss_train += loss.item()\n",
    "            \n",
    "        out = torch.cat((out, torch.unsqueeze(labels[:,2], dim=1)), dim=1)\n",
    "        \n",
    "        true_train = Spher2Cart_1D(np.multiply(labels.cpu().data.numpy()[1,], [rng_res_tr,az_step_tr,el_step_tr]) + coord_tr)\n",
    "        pred_train = Spher2Cart_1D(np.multiply(out.cpu().data.numpy()[1,], [rng_res_tr,az_step_tr,el_step_tr]) + coord_tr)\n",
    "        print(true_train)\n",
    "        print(pred_train)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, len(test_names)//bs):\n",
    "                x_test, labels_test = Drawing_Batch(test_names, y_test, bs, i, normalize)\n",
    "                x_test = x_test.to(device)\n",
    "                labels_test = labels_test.to(device)\n",
    "                out_test = model(x_test)\n",
    "                loss_test = criterion(out_test, labels_test[:,0:2])\n",
    "                running_loss_test += loss_test.item()\n",
    "\n",
    "        out_test = torch.cat((out_test, torch.unsqueeze(labels_test[:,2], dim=1)), dim=1)\n",
    "        \n",
    "        true_test = Spher2Cart_1D(np.multiply(labels_test.cpu().data.numpy()[1,], [rng_res_ts,az_step_ts,el_step_ts]) + coord_ts)\n",
    "        pred_test = Spher2Cart_1D(np.multiply(out_test.cpu().data.numpy()[1,], [rng_res_ts,az_step_ts,el_step_ts]) + coord_ts)\n",
    "        print(true_test)\n",
    "        print(pred_test)\n",
    "        \n",
    "        epoch_loss_train = running_loss_train*x_train.size()[0]/len(training_names)\n",
    "        epoch_loss_test = running_loss_test*x_test.size()[0]/len(test_names)\n",
    "\n",
    "        print('Train Loss: {:.6f} ---- Test Loss: {:.6f}'.format(epoch_loss_train, epoch_loss_test))\n",
    "        if epoch%5==0:\n",
    "            if epoch_loss_test < best_error:\n",
    "                torch.save(model.state_dict(), PATH)\n",
    "                best_accuracy = epoch_loss_test\n",
    "\n",
    "start = time.time()\n",
    "main(training_names, test_names, bs, num_epoch, y_train, y_test, normalize=True)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azimuth Estimation Error (deg) = 0.1776179441784154\n",
      "Localization Error (m) = 16.59589142413758\n"
     ]
    }
   ],
   "source": [
    "def Spher2Cart_2D(spherical):\n",
    "    cartesian = np.zeros((len(spherical),3))\n",
    "    hypotenuse = np.multiply(np.cos(np.radians(spherical[:,2])), spherical[:,0])\n",
    "    cartesian[:,0] = np.multiply(np.cos(np.radians(spherical[:,1])), hypotenuse)\n",
    "    cartesian[:,1] = np.multiply(-np.sin(np.radians(spherical[:,1])), hypotenuse)\n",
    "    cartesian[:,2] = np.multiply(np.sin(np.radians(spherical[:,2])), spherical[:,0])\n",
    "    return cartesian\n",
    "\n",
    "# Testing: (range,az,el)\n",
    "model.eval()\n",
    "out_test_reg = np.zeros((len(y_test),3))\n",
    "labels_test_reg = np.zeros((len(y_test),3))\n",
    "\n",
    "for i in range(0, len(y_test)//bs):  \n",
    "    x_test, labels_test = Drawing_Batch(test_names, y_test, bs, i, True)\n",
    "    labels_test = labels_test.cpu().data.numpy()\n",
    "    labels_test_reg[bs*i : bs*i + bs] = (labels_test[:,0:3])\n",
    "\n",
    "    cur_test_reg = model(x_test)\n",
    "    out_test_reg[bs*i : bs*i + bs, 0:2] = cur_test_reg.cpu().data.numpy()\n",
    "    out_test_reg[bs*i : bs*i + bs, 2] = labels_test_reg[bs*i : bs*i + bs, 2]\n",
    "    \n",
    "azim_tot = 0\n",
    "for i in np.arange(0,len(out_test_reg),1):\n",
    "    azim_tot += np.linalg.norm(out_test_reg[i,1] - labels_test_reg[i,1])\n",
    "    \n",
    "azim_tot = azim_tot / len(out_test_reg)\n",
    "print(f'Azimuth Estimation Error (deg) = {azim_tot}')   \n",
    "\n",
    "new_data = Spher2Cart_2D(np.multiply(out_test_reg, [rng_res_ts,az_step_ts,el_step_ts]) + coord_ts)\n",
    "new_labels_data = Spher2Cart_2D(np.multiply(labels_test_reg, [rng_res_ts,az_step_ts,el_step_ts]) + coord_ts)\n",
    "\n",
    "sum_tot = 0\n",
    "for i in np.arange(0,len(new_data) - (len(new_data) % bs),1):\n",
    "    sum_tot += np.linalg.norm(new_data[i,:] - new_labels_data[i,:])\n",
    "    \n",
    "# def reject_outliers(data, m=2):\n",
    "#     return data[abs(data - np.mean(data)) < m * np.std(data)]\n",
    "# \n",
    "# azims = (np.multiply(out_test_reg, [rng_res_ts,az_step_ts,el_step_ts]) - np.multiply(labels_test_reg, [rng_res_ts,az_step_ts,el_step_ts]))[:,1]\n",
    "# azims = reject_outliers(azims)\n",
    "# mse = np.mean(azims**2)\n",
    "# bias_sq = np.mean(azims)**2\n",
    "# var = np.var(azims)\n",
    "# print(mse, bias_sq, var)\n",
    "\n",
    "sum_tot = sum_tot / (len(new_data) - (len(new_data) % bs))\n",
    "print(f'Localization Error (m) = {sum_tot}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
