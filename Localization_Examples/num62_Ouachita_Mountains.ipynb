{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Regression Network on Radar Dataset (Ouachita Mountains)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "import scipy.io as sio\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import itertools\n",
    "import time\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import KFold\n",
    "from itertools import product\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the labels and creating train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "Training labels: \n",
      "[[ 0.19278 19.175    5.3732 ]\n",
      " [11.244   23.269   24.522  ]\n",
      " [-0.2566  20.21     9.9473 ]\n",
      " ...\n",
      " [ 7.7966  22.974   29.859  ]\n",
      " [15.579   24.133   17.291  ]\n",
      " [ 6.6286  23.169   29.05   ]]\n"
     ]
    }
   ],
   "source": [
    "def index(string):\n",
    "    s = re.findall(\"[0-9]\", string)\n",
    "    return int(''.join(s))\n",
    "\n",
    "scenario_idx = 62 # Ouachita Mountains\n",
    "names = os.listdir(f'num{scenario_idx}_NAMF_DATA_20_rng30_pulse1_1000_100k/')\n",
    "names = sorted(names, key = index)\n",
    "print(len(names))\n",
    "y = pd.read_csv(f'num{scenario_idx}_Ground_Truth_20_rng30_1000_100k_m.csv')\n",
    "col_names = y.columns[4:7]\n",
    "y = y[col_names].to_numpy()\n",
    "\n",
    "y_train = y[:int(0.9*len(names))]\n",
    "y_test = y[(int(0.9*len(names))+1):]\n",
    "training_names = names[:int(0.9*len(names))]\n",
    "test_names = names[(int(0.9*len(names))+1):]\n",
    "\n",
    "print('Training labels: ')\n",
    "print(y_train)\n",
    "\n",
    "# Tensor Corners\n",
    "##################################################################################\n",
    "# num29: [10851, 215, -5.45], num60: [11073, 215, -5.3], num62: [11471, 215, -5.6]\n",
    "# num76: [11388, 215, -6.15], num35: [11381, 215, -0.95]\n",
    "##################################################################################\n",
    "\n",
    "# Training dataset global constants\n",
    "coord_tr = [11471, 215, -5.6] # Tensor corner\n",
    "rng_res_tr = 59.9585/2         # Range resolution\n",
    "az_step_tr = 0.4               # Azimuth step size\n",
    "el_step_tr = 0.01              # Elevation step size\n",
    "\n",
    "# Test dataset global constants\n",
    "coord_ts = [11471, 215, -5.6] # Tensor corner\n",
    "rng_res_ts = 59.9585/2         # Range resolution\n",
    "az_step_ts = 0.4               # Azimuth step size\n",
    "el_step_ts = 0.01              # Elevation step size\n",
    "\n",
    "\n",
    "def Drawing_Batch(names, label, bs, ind, normalize = True):\n",
    "    x = []\n",
    "    labels = []\n",
    "    \n",
    "    for j in range(ind*bs, (ind+1)*bs):\n",
    "        try: temp = sio.loadmat(f'num{scenario_idx}_NAMF_DATA_20_rng30_pulse1_1000_100k/'+names[j])['P']\n",
    "        except: break\n",
    "        if normalize:\n",
    "            Anorm = temp - np.min(temp.flatten())\n",
    "            temp = np.divide(Anorm, np.max(Anorm.flatten()))\n",
    "        x.append(temp)\n",
    "        labels.append(label[j,:])\n",
    "        \n",
    "    x = torch.FloatTensor(np.array(x))\n",
    "    labels = torch.FloatTensor(np.array(labels))\n",
    "    return x,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90000\n",
      "9999\n"
     ]
    }
   ],
   "source": [
    "print(len(y_train))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a regression CNN and instantiating it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1               [-1, 32, 24]           2,048\n",
      "       BatchNorm1d-2               [-1, 32, 24]              64\n",
      "            Conv1d-3               [-1, 64, 10]           6,208\n",
      "       BatchNorm1d-4               [-1, 64, 10]             128\n",
      "            Linear-5                   [-1, 20]           6,420\n",
      "            Linear-6                    [-1, 2]              42\n",
      "               Net-7                    [-1, 2]               0\n",
      "================================================================\n",
      "Total params: 14,910\n",
      "Trainable params: 14,910\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.02\n",
      "Params size (MB): 0.06\n",
      "Estimated Total Size (MB): 0.08\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(21, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv1d(32, 64, 3, 1)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(32)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(64)\n",
    "        self.fc1 = nn.Linear(64 * 5, 20)  # Adjust input size based on the output of conv layers and max pooling\n",
    "        self.fc2_reg = nn.Linear(20, 2)  # Adjusted output size\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(self.batchnorm1(x))\n",
    "        x = F.max_pool1d(x, 2)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(self.batchnorm2(x))\n",
    "        x = F.max_pool1d(x, 2)\n",
    "        \n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        output_reg = self.fc2_reg(x)  # (bs, 2)\n",
    "        \n",
    "        return output_reg\n",
    "    \n",
    "from torchsummary import summary\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "model = Net()\n",
    "model = model.to(device)\n",
    "if device == 'cuda:0':\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    cudnn.benchmark = True\n",
    "print(summary(model,(21,26)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 128  # batch_size\n",
    "num_epoch = 50  # number of epochs\n",
    "PATH = './ckpt_model.pth'   # forsaving the model\n",
    "criterion = nn.MSELoss()\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Define a Loss function and optimizer; Using GPU or CPU\n",
    "model = Net()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "model = model.to(device)\n",
    "if device == 'cuda:0':\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    cudnn.benchmark = True\n",
    "    \n",
    "def Spher2Cart_1D(spherical):\n",
    "    cartesian = np.zeros(3)\n",
    "    hypotenuse = np.cos(np.radians(spherical[2]))*spherical[0]\n",
    "    cartesian[0] = np.cos(np.radians(spherical[1]))*hypotenuse\n",
    "    cartesian[1] = -np.sin(np.radians(spherical[1]))*hypotenuse\n",
    "    cartesian[2] = np.sin(np.radians(spherical[2]))*spherical[0]\n",
    "    return cartesian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evaluate the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/50\n",
      "----------\n",
      "[-8421.63922973  7801.90963099 -1096.1574508 ]\n",
      "[-8438.09755764  7782.44005031 -1096.04958087]\n",
      "[-8443.49210233  8155.83627122 -1085.60648848]\n",
      "[-8294.314676    8223.14936929 -1080.10036779]\n",
      "Train Loss: 13.659371 ---- Test Loss: 3.913199\n",
      "Epoch 1/50\n",
      "----------\n",
      "[-8421.63922973  7801.90963099 -1096.1574508 ]\n",
      "[-8433.84037299  7782.90691995 -1095.78104197]\n",
      "[-8443.49210233  8155.83627122 -1085.60648848]\n",
      "[-8303.72121139  8223.17797002 -1080.72014779]\n",
      "Train Loss: 3.602420 ---- Test Loss: 3.663542\n",
      "Epoch 2/50\n",
      "----------\n",
      "[-8421.63922973  7801.90963099 -1096.1574508 ]\n",
      "[-8434.04400169  7783.11541896 -1095.80883185]\n",
      "[-8443.49210233  8155.83627122 -1085.60648848]\n",
      "[-8323.63756614  8205.65731184 -1080.89150315]\n",
      "Train Loss: 3.522377 ---- Test Loss: 3.913097\n",
      "Epoch 3/50\n",
      "----------\n",
      "[-8421.63922973  7801.90963099 -1096.1574508 ]\n",
      "[-8428.9360065   7787.54880392 -1095.73767279]\n",
      "[-8443.49210233  8155.83627122 -1085.60648848]\n",
      "[-8332.6674182   8190.10949616 -1080.47796984]\n",
      "Train Loss: 3.494644 ---- Test Loss: 3.973007\n",
      "Epoch 4/50\n",
      "----------\n",
      "[-8421.63922973  7801.90963099 -1096.1574508 ]\n",
      "[-8424.39804587  7786.58867097 -1095.35722705]\n",
      "[-8443.49210233  8155.83627122 -1085.60648848]\n",
      "[-8331.25268664  8191.18704443 -1080.45452817]\n",
      "Train Loss: 3.484982 ---- Test Loss: 3.886007\n",
      "Epoch 5/50\n",
      "----------\n",
      "[-8421.63922973  7801.90963099 -1096.1574508 ]\n",
      "[-8431.02331571  7782.53138139 -1095.55906196]\n",
      "[-8443.49210233  8155.83627122 -1085.60648848]\n",
      "[-8329.16599749  8195.53713627 -1080.59904302]\n",
      "Train Loss: 3.488050 ---- Test Loss: 3.898866\n",
      "Epoch 6/50\n",
      "----------\n",
      "[-8421.63922973  7801.90963099 -1096.1574508 ]\n",
      "[-8432.33625713  7781.43386147 -1095.58011099]\n",
      "[-8443.49210233  8155.83627122 -1085.60648848]\n",
      "[-8319.63243757  8212.5940737  -1081.07833096]\n",
      "Train Loss: 3.489246 ---- Test Loss: 3.776304\n",
      "Epoch 7/50\n",
      "----------\n",
      "[-8421.63922973  7801.90963099 -1096.1574508 ]\n",
      "[-8432.85201876  7779.8450622  -1095.51343077]\n",
      "[-8443.49210233  8155.83627122 -1085.60648848]\n",
      "[-8340.79947371  8176.26630598 -1080.11788585]\n",
      "Train Loss: 3.488454 ---- Test Loss: 3.933390\n",
      "Epoch 8/50\n",
      "----------\n",
      "[-8421.63922973  7801.90963099 -1096.1574508 ]\n",
      "[-8436.48426587  7776.90635596 -1095.57816183]\n",
      "[-8443.49210233  8155.83627122 -1085.60648848]\n",
      "[-8351.97430104  8170.37079039 -1080.47477899]\n",
      "Train Loss: 3.498614 ---- Test Loss: 4.020998\n",
      "Epoch 9/50\n",
      "----------\n",
      "[-8421.63922973  7801.90963099 -1096.1574508 ]\n",
      "[-8436.71690763  7773.64974094 -1095.38376517]\n",
      "[-8443.49210233  8155.83627122 -1085.60648848]\n",
      "[-8339.48893877  8185.68641299 -1080.64139283]\n",
      "Train Loss: 3.516502 ---- Test Loss: 3.930319\n",
      "Epoch 10/50\n",
      "----------\n",
      "[-8421.63922973  7801.90963099 -1096.1574508 ]\n",
      "[-8437.06875671  7778.43917637 -1095.71839696]\n",
      "[-8443.49210233  8155.83627122 -1085.60648848]\n",
      "[-8340.95139693  8189.1489257  -1080.96221781]\n",
      "Train Loss: 3.522545 ---- Test Loss: 3.998910\n",
      "Epoch 11/50\n",
      "----------\n",
      "[-8421.63922973  7801.90963099 -1096.1574508 ]\n",
      "[-8439.91731052  7778.48832825 -1095.92156447]\n",
      "[-8443.49210233  8155.83627122 -1085.60648848]\n",
      "[-8341.2795603   8194.3474358  -1081.32071953]\n",
      "Train Loss: 3.511502 ---- Test Loss: 3.999153\n",
      "Epoch 12/50\n",
      "----------\n",
      "[-8421.63922973  7801.90963099 -1096.1574508 ]\n",
      "[-8436.52255444  7780.89283481 -1095.83887558]\n",
      "[-8443.49210233  8155.83627122 -1085.60648848]\n",
      "[-8348.65522233  8191.33204426 -1081.61207919]\n",
      "Train Loss: 3.494708 ---- Test Loss: 3.950250\n",
      "Epoch 13/50\n",
      "----------\n",
      "[-8421.63922973  7801.90963099 -1096.1574508 ]\n",
      "[-8439.33128543  7777.2715637  -1095.8016837 ]\n",
      "[-8443.49210233  8155.83627122 -1085.60648848]\n",
      "[-8347.85442469  8190.04434998 -1081.47582052]\n",
      "Train Loss: 3.485309 ---- Test Loss: 3.863601\n",
      "Epoch 14/50\n",
      "----------\n",
      "[-8421.63922973  7801.90963099 -1096.1574508 ]\n",
      "[-8435.44610449  7779.07629201 -1095.64573   ]\n",
      "[-8443.49210233  8155.83627122 -1085.60648848]\n",
      "[-8349.36490637  8190.04073125 -1081.5753002 ]\n",
      "Train Loss: 3.486350 ---- Test Loss: 3.883305\n",
      "Epoch 15/50\n",
      "----------\n",
      "[-8421.63922973  7801.90963099 -1096.1574508 ]\n",
      "[-8434.28725663  7782.59692044 -1095.79232722]\n",
      "[-8443.49210233  8155.83627122 -1085.60648848]\n",
      "[-8353.88111578  8185.18668189 -1081.55928541]\n",
      "Train Loss: 3.490075 ---- Test Loss: 3.890918\n",
      "Epoch 16/50\n",
      "----------\n",
      "[-8421.63922973  7801.90963099 -1096.1574508 ]\n",
      "[-8435.35168237  7782.64312594 -1095.87001517]\n",
      "[-8443.49210233  8155.83627122 -1085.60648848]\n",
      "[-8344.34091227  8199.73645306 -1081.87193318]\n",
      "Train Loss: 3.484833 ---- Test Loss: 3.823202\n",
      "Epoch 17/50\n",
      "----------\n",
      "[-8421.63922973  7801.90963099 -1096.1574508 ]\n",
      "[-8436.86892522  7780.6245618  -1095.84582127]\n",
      "[-8443.49210233  8155.83627122 -1085.60648848]\n",
      "[-8349.14514412  8195.74039629 -1081.92996079]\n",
      "Train Loss: 3.475485 ---- Test Loss: 3.798168\n",
      "Epoch 18/50\n",
      "----------\n",
      "[-8421.63922973  7801.90963099 -1096.1574508 ]\n",
      "[-8432.25294879  7783.59344217 -1095.71411785]\n",
      "[-8443.49210233  8155.83627122 -1085.60648848]\n",
      "[-8352.54830878  8189.62628592 -1081.75864756]\n",
      "Train Loss: 3.473292 ---- Test Loss: 3.769275\n",
      "Epoch 19/50\n",
      "----------\n",
      "[-8421.63922973  7801.90963099 -1096.1574508 ]\n",
      "[-8429.78843431  7785.49487295 -1095.66438794]\n",
      "[-8443.49210233  8155.83627122 -1085.60648848]\n",
      "[-8356.59446231  8186.96415522 -1081.85355421]\n",
      "Train Loss: 3.472758 ---- Test Loss: 3.788772\n",
      "Epoch 20/50\n",
      "----------\n",
      "[-8421.63922973  7801.90963099 -1096.1574508 ]\n",
      "[-8433.0646395   7783.1309145  -1095.74111523]\n",
      "[-8443.49210233  8155.83627122 -1085.60648848]\n",
      "[-8354.9519258   8188.56941502 -1081.84896013]\n",
      "Train Loss: 3.474090 ---- Test Loss: 3.776832\n",
      "Epoch 21/50\n",
      "----------\n",
      "[-8421.63922973  7801.90963099 -1096.1574508 ]\n",
      "[-8430.90572353  7785.31220477 -1095.73092854]\n",
      "[-8443.49210233  8155.83627122 -1085.60648848]\n",
      "[-8354.5565312   8187.12348042 -1081.72925332]\n",
      "Train Loss: 3.474066 ---- Test Loss: 3.744683\n",
      "Epoch 22/50\n",
      "----------\n",
      "[-8421.63922973  7801.90963099 -1096.1574508 ]\n",
      "[-8432.30598542  7785.95746702 -1095.87095475]\n",
      "[-8443.49210233  8155.83627122 -1085.60648848]\n",
      "[-8347.57280025  8201.46343262 -1082.19704947]\n",
      "Train Loss: 3.464677 ---- Test Loss: 3.734472\n",
      "Epoch 23/50\n",
      "----------\n",
      "[-8421.63922973  7801.90963099 -1096.1574508 ]\n",
      "[-8431.13485275  7786.90917757 -1095.85045365]\n",
      "[-8443.49210233  8155.83627122 -1085.60648848]\n",
      "[-8349.17792382  8198.42757429 -1082.10621826]\n",
      "Train Loss: 3.462087 ---- Test Loss: 3.731358\n",
      "Epoch 24/50\n",
      "----------\n",
      "[-8421.63922973  7801.90963099 -1096.1574508 ]\n",
      "[-8429.87476439  7789.58908924 -1095.93571435]\n",
      "[-8443.49210233  8155.83627122 -1085.60648848]\n",
      "[-8350.82615843  8196.53683    -1082.09249393]\n",
      "Train Loss: 3.461927 ---- Test Loss: 3.705351\n",
      "Epoch 25/50\n",
      "----------\n",
      "[-8421.63922973  7801.90963099 -1096.1574508 ]\n",
      "[-8429.84582976  7790.39831596 -1095.98612535]\n",
      "[-8443.49210233  8155.83627122 -1085.60648848]\n",
      "[-8352.19159518  8195.16805954 -1082.09395772]\n",
      "Train Loss: 3.463130 ---- Test Loss: 3.708446\n",
      "Epoch 26/50\n",
      "----------\n",
      "[-8421.63922973  7801.90963099 -1096.1574508 ]\n",
      "[-8428.81290397  7790.85388681 -1095.94322019]\n",
      "[-8443.49210233  8155.83627122 -1085.60648848]\n",
      "[-8351.59726579  8199.08081788 -1082.3081868 ]\n",
      "Train Loss: 3.461066 ---- Test Loss: 3.712567\n",
      "Epoch 27/50\n",
      "----------\n",
      "[-8421.63922973  7801.90963099 -1096.1574508 ]\n",
      "[-8427.79958235  7791.48440663 -1095.9130382 ]\n",
      "[-8443.49210233  8155.83627122 -1085.60648848]\n",
      "[-8350.95613185  8198.4725747  -1082.22647267]\n",
      "Train Loss: 3.457526 ---- Test Loss: 3.699033\n",
      "Epoch 28/50\n",
      "----------\n",
      "[-8421.63922973  7801.90963099 -1096.1574508 ]\n",
      "[-8426.47714234  7794.91282421 -1096.04259136]\n",
      "[-8443.49210233  8155.83627122 -1085.60648848]\n",
      "[-8353.51234659  8194.12299806 -1082.11346348]\n",
      "Train Loss: 3.456611 ---- Test Loss: 3.699649\n",
      "Epoch 29/50\n",
      "----------\n",
      "[-8421.63922973  7801.90963099 -1096.1574508 ]\n",
      "[-8427.44652351  7793.44671229 -1096.01548902]\n",
      "[-8443.49210233  8155.83627122 -1085.60648848]\n",
      "[-8352.67706395  8197.43860416 -1082.27306641]\n",
      "Train Loss: 3.452197 ---- Test Loss: 3.702906\n",
      "Epoch 30/50\n",
      "----------\n",
      "[-8421.63922973  7801.90963099 -1096.1574508 ]\n",
      "[-8424.41982121  7793.66733566 -1095.81763429]\n",
      "[-8443.49210233  8155.83627122 -1085.60648848]\n",
      "[-8354.97958931  8193.11500667 -1082.14506393]\n",
      "Train Loss: 3.449876 ---- Test Loss: 3.691597\n",
      "Epoch 31/50\n",
      "----------\n",
      "[-8421.63922973  7801.90963099 -1096.1574508 ]\n",
      "[-8427.7721126   7792.96378045 -1096.00700725]\n",
      "[-8443.49210233  8155.83627122 -1085.60648848]\n",
      "[-8351.27081148  8192.81586428 -1081.88083701]\n",
      "Train Loss: 3.449503 ---- Test Loss: 3.674098\n",
      "Epoch 32/50\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-8421.63922973  7801.90963099 -1096.1574508 ]\n",
      "[-8425.97754445  7795.11238546 -1096.02051375]\n",
      "[-8443.49210233  8155.83627122 -1085.60648848]\n",
      "[-8351.46138263  8198.12850036 -1082.23752479]\n",
      "Train Loss: 3.448464 ---- Test Loss: 3.697425\n",
      "Epoch 33/50\n",
      "----------\n",
      "[-8421.63922973  7801.90963099 -1096.1574508 ]\n",
      "[-8424.20934043  7796.93642414 -1096.01488199]\n",
      "[-8443.49210233  8155.83627122 -1085.60648848]\n",
      "[-8354.19787443  8197.26194958 -1082.36200471]\n",
      "Train Loss: 3.447379 ---- Test Loss: 3.699110\n",
      "Epoch 34/50\n",
      "----------\n",
      "[-8421.63922973  7801.90963099 -1096.1574508 ]\n",
      "[-8426.30498869  7794.55431201 -1096.00727934]\n",
      "[-8443.49210233  8155.83627122 -1085.60648848]\n",
      "[-8350.82731125  8197.05846446 -1082.12636114]\n",
      "Train Loss: 3.445119 ---- Test Loss: 3.661107\n",
      "Epoch 35/50\n",
      "----------\n",
      "[-8421.63922973  7801.90963099 -1096.1574508 ]\n",
      "[-8424.17765425  7796.52889449 -1095.98623066]\n",
      "[-8443.49210233  8155.83627122 -1085.60648848]\n",
      "[-8350.69991333  8201.38361503 -1082.39817817]\n",
      "Train Loss: 3.443345 ---- Test Loss: 3.663257\n",
      "Epoch 36/50\n",
      "----------\n",
      "[-8421.63922973  7801.90963099 -1096.1574508 ]\n",
      "[-8424.17194954  7797.27233074 -1096.03404811]\n",
      "[-8443.49210233  8155.83627122 -1085.60648848]\n",
      "[-8348.49742746  8205.8428769  -1082.54190321]\n",
      "Train Loss: 3.441848 ---- Test Loss: 3.645662\n",
      "Epoch 37/50\n",
      "----------\n",
      "[-8421.63922973  7801.90963099 -1096.1574508 ]\n",
      "[-8423.86169041  7797.81223065 -1096.04732599]\n",
      "[-8443.49210233  8155.83627122 -1085.60648848]\n",
      "[-8349.39160444  8200.89268454 -1082.28004837]\n",
      "Train Loss: 3.440480 ---- Test Loss: 3.659744\n",
      "Epoch 38/50\n",
      "----------\n",
      "[-8421.63922973  7801.90963099 -1096.1574508 ]\n",
      "[-8424.2938265   7797.50198286 -1096.05748347]\n",
      "[-8443.49210233  8155.83627122 -1085.60648848]\n",
      "[-8347.73229702  8206.08701834 -1082.50726988]\n",
      "Train Loss: 3.441456 ---- Test Loss: 3.635182\n",
      "Epoch 39/50\n",
      "----------\n",
      "[-8421.63922973  7801.90963099 -1096.1574508 ]\n",
      "[-8425.38851872  7797.13425702 -1096.11034569]\n",
      "[-8443.49210233  8155.83627122 -1085.60648848]\n",
      "[-8348.84780419  8209.75607103 -1082.81870924]\n",
      "Train Loss: 3.440457 ---- Test Loss: 3.653718\n",
      "Epoch 40/50\n",
      "----------\n",
      "[-8421.63922973  7801.90963099 -1096.1574508 ]\n",
      "[-8423.84368291  7798.08550247 -1096.06378952]\n",
      "[-8443.49210233  8155.83627122 -1085.60648848]\n",
      "[-8347.55560477  8212.74836017 -1082.92755873]\n",
      "Train Loss: 3.437497 ---- Test Loss: 3.658797\n",
      "Epoch 41/50\n",
      "----------\n",
      "[-8421.63922973  7801.90963099 -1096.1574508 ]\n",
      "[-8423.60224319  7798.60145472 -1096.08034   ]\n",
      "[-8443.49210233  8155.83627122 -1085.60648848]\n",
      "[-8346.81973648  8209.40135905 -1082.66198913]\n",
      "Train Loss: 3.435196 ---- Test Loss: 3.671572\n",
      "Epoch 42/50\n",
      "----------\n",
      "[-8421.63922973  7801.90963099 -1096.1574508 ]\n",
      "[-8423.83184538  7798.89318037 -1096.11535071]\n",
      "[-8443.49210233  8155.83627122 -1085.60648848]\n",
      "[-8348.28479971  8211.11349215 -1082.86960747]\n",
      "Train Loss: 3.435479 ---- Test Loss: 3.675746\n",
      "Epoch 43/50\n",
      "----------\n",
      "[-8421.63922973  7801.90963099 -1096.1574508 ]\n",
      "[-8425.44073736  7798.53460527 -1096.20482631]\n",
      "[-8443.49210233  8155.83627122 -1085.60648848]\n",
      "[-8347.30961295  8207.44707641 -1082.56757216]\n",
      "Train Loss: 3.433996 ---- Test Loss: 3.645672\n",
      "Epoch 44/50\n",
      "----------\n",
      "[-8421.63922973  7801.90963099 -1096.1574508 ]\n",
      "[-8422.23436378  7798.64270601 -1095.98717806]\n",
      "[-8443.49210233  8155.83627122 -1085.60648848]\n",
      "[-8343.74381468  8210.50321651 -1082.5306747 ]\n",
      "Train Loss: 3.436414 ---- Test Loss: 3.621047\n",
      "Epoch 45/50\n",
      "----------\n",
      "[-8421.63922973  7801.90963099 -1096.1574508 ]\n",
      "[-8418.47159204  7802.07109191 -1095.9460736 ]\n",
      "[-8443.49210233  8155.83627122 -1085.60648848]\n",
      "[-8344.65313252  8213.37670861 -1082.77700181]\n",
      "Train Loss: 3.435479 ---- Test Loss: 3.615667\n",
      "Epoch 46/50\n",
      "----------\n",
      "[-8421.63922973  7801.90963099 -1096.1574508 ]\n",
      "[-8421.44831766  7799.54735309 -1095.99080053]\n",
      "[-8443.49210233  8155.83627122 -1085.60648848]\n",
      "[-8344.82835552  8208.39922611 -1082.46571252]\n",
      "Train Loss: 3.431976 ---- Test Loss: 3.621485\n",
      "Epoch 47/50\n",
      "----------\n",
      "[-8421.63922973  7801.90963099 -1096.1574508 ]\n",
      "[-8421.98117806  7802.49358034 -1096.21929516]\n",
      "[-8443.49210233  8155.83627122 -1085.60648848]\n",
      "[-8340.99745408  8223.65816799 -1083.20341435]\n",
      "Train Loss: 3.429078 ---- Test Loss: 3.687684\n",
      "Epoch 48/50\n",
      "----------\n",
      "[-8421.63922973  7801.90963099 -1096.1574508 ]\n",
      "[-8420.68333552  7802.4112522  -1096.12305018]\n",
      "[-8443.49210233  8155.83627122 -1085.60648848]\n",
      "[-8349.98556654  8202.03993069 -1082.39357883]\n",
      "Train Loss: 3.430754 ---- Test Loss: 3.638845\n",
      "Epoch 49/50\n",
      "----------\n",
      "[-8421.63922973  7801.90963099 -1096.1574508 ]\n",
      "[-8419.09271839  7802.45647408 -1096.0145851 ]\n",
      "[-8443.49210233  8155.83627122 -1085.60648848]\n",
      "[-8347.77891704  8200.6792269  -1082.15982292]\n",
      "Train Loss: 3.430437 ---- Test Loss: 3.609382\n",
      "3244.737071752548\n"
     ]
    }
   ],
   "source": [
    "def main(training_names, test_names, bs, num_epoch, y_train, y_test, normalize=True):\n",
    "    best_error = 1e+20      # a dummy and very large number for saving the best discovered model\n",
    "    for epoch in range(num_epoch):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epoch))\n",
    "        print('-'*10)\n",
    "        running_loss_train = 0\n",
    "        running_loss_test = 0\n",
    "\n",
    "        model.train()\n",
    "        for i in range(0, len(training_names)//bs):\n",
    "            x_train, labels = Drawing_Batch(training_names, y_train, bs, i, normalize)\n",
    "            x_train = x_train.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(x_train)\n",
    "            loss = criterion(out, labels[:,0:2])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss_train += loss.item()\n",
    "            \n",
    "        out = torch.cat((out, torch.unsqueeze(labels[:,2], dim=1)), dim=1)\n",
    "        \n",
    "        true_train = Spher2Cart_1D(np.multiply(labels.cpu().data.numpy()[1,], [rng_res_tr,az_step_tr,el_step_tr]) + coord_tr)\n",
    "        pred_train = Spher2Cart_1D(np.multiply(out.cpu().data.numpy()[1,], [rng_res_tr,az_step_tr,el_step_tr]) + coord_tr)\n",
    "        print(true_train)\n",
    "        print(pred_train)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, len(test_names)//bs):\n",
    "                x_test, labels_test = Drawing_Batch(test_names, y_test, bs, i, normalize)\n",
    "                x_test = x_test.to(device)\n",
    "                labels_test = labels_test.to(device)\n",
    "                out_test = model(x_test)\n",
    "                loss_test = criterion(out_test, labels_test[:,0:2])\n",
    "                running_loss_test += loss_test.item()\n",
    "\n",
    "        out_test = torch.cat((out_test, torch.unsqueeze(labels_test[:,2], dim=1)), dim=1)\n",
    "        \n",
    "        true_test = Spher2Cart_1D(np.multiply(labels_test.cpu().data.numpy()[1,], [rng_res_ts,az_step_ts,el_step_ts]) + coord_ts)\n",
    "        pred_test = Spher2Cart_1D(np.multiply(out_test.cpu().data.numpy()[1,], [rng_res_ts,az_step_ts,el_step_ts]) + coord_ts)\n",
    "        print(true_test)\n",
    "        print(pred_test)\n",
    "        \n",
    "        epoch_loss_train = running_loss_train*x_train.size()[0]/len(training_names)\n",
    "        epoch_loss_test = running_loss_test*x_test.size()[0]/len(test_names)\n",
    "\n",
    "        print('Train Loss: {:.6f} ---- Test Loss: {:.6f}'.format(epoch_loss_train, epoch_loss_test))\n",
    "        if epoch%5==0:\n",
    "            if epoch_loss_test < best_error:\n",
    "                torch.save(model.state_dict(), PATH)\n",
    "                best_accuracy = epoch_loss_test\n",
    "\n",
    "start = time.time()\n",
    "main(training_names, test_names, bs, num_epoch, y_train, y_test, normalize=True)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azimuth Estimation Error (deg) = 0.4839181860813446\n",
      "Localization Error (m) = 68.31161613254166\n"
     ]
    }
   ],
   "source": [
    "def Spher2Cart_2D(spherical):\n",
    "    cartesian = np.zeros((len(spherical),3))\n",
    "    hypotenuse = np.multiply(np.cos(np.radians(spherical[:,2])), spherical[:,0])\n",
    "    cartesian[:,0] = np.multiply(np.cos(np.radians(spherical[:,1])), hypotenuse)\n",
    "    cartesian[:,1] = np.multiply(-np.sin(np.radians(spherical[:,1])), hypotenuse)\n",
    "    cartesian[:,2] = np.multiply(np.sin(np.radians(spherical[:,2])), spherical[:,0])\n",
    "    return cartesian\n",
    "\n",
    "# Testing: (range,az,el)\n",
    "model.eval()\n",
    "out_test_reg = np.zeros((len(y_test),3))\n",
    "labels_test_reg = np.zeros((len(y_test),3))\n",
    "\n",
    "for i in range(0, len(y_test)//bs):  \n",
    "    x_test, labels_test = Drawing_Batch(test_names, y_test, bs, i, True)\n",
    "    labels_test = labels_test.cpu().data.numpy()\n",
    "    labels_test_reg[bs*i : bs*i + bs] = (labels_test[:,0:3])\n",
    "\n",
    "    cur_test_reg = model(x_test)\n",
    "    out_test_reg[bs*i : bs*i + bs, 0:2] = cur_test_reg.cpu().data.numpy()\n",
    "    out_test_reg[bs*i : bs*i + bs, 2] = labels_test_reg[bs*i : bs*i + bs, 2]\n",
    "    \n",
    "azim_tot = 0\n",
    "for i in np.arange(0,len(out_test_reg),1):\n",
    "    azim_tot += np.linalg.norm(out_test_reg[i,1] - labels_test_reg[i,1])\n",
    "    \n",
    "azim_tot = azim_tot / len(out_test_reg)\n",
    "print(f'Azimuth Estimation Error (deg) = {azim_tot}')\n",
    "\n",
    "new_data = Spher2Cart_2D(np.multiply(out_test_reg, [rng_res_ts,az_step_ts,el_step_ts]) + coord_ts)\n",
    "new_labels_data = Spher2Cart_2D(np.multiply(labels_test_reg, [rng_res_ts,az_step_ts,el_step_ts]) + coord_ts)\n",
    "\n",
    "sum_tot = 0\n",
    "for i in np.arange(0,len(new_data) - (len(new_data) % bs),1):\n",
    "    sum_tot += np.linalg.norm(new_data[i,:] - new_labels_data[i,:])\n",
    "    \n",
    "# def reject_outliers(data, m=2):\n",
    "#     return data[abs(data - np.mean(data)) < m * np.std(data)]\n",
    "# \n",
    "# azims = (np.multiply(out_test_reg, [rng_res_ts,az_step_ts,el_step_ts]) - np.multiply(labels_test_reg, [rng_res_ts,az_step_ts,el_step_ts]))[:,1]\n",
    "# azims = reject_outliers(azims)\n",
    "# mse = np.mean(azims**2)\n",
    "# bias_sq = np.mean(azims)**2\n",
    "# var = np.var(azims)\n",
    "# print(mse, bias_sq, var)\n",
    "\n",
    "sum_tot = sum_tot / (len(new_data) - (len(new_data) % bs))\n",
    "print(f'Localization Error (m) = {sum_tot}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
